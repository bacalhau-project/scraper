URL: https://docs.bacalhau.org/setting-up/workload-onboarding/container/index-1

Bacalhau Docsv.1.4.0v.1.3.0v.1.3.1v.1.3.2v.1.4.0GitHubSlackContactMoreGitHubSlackContactAsk or SearchCtrl+ KWelcomeGetting StartedHow Bacalhau WorksInstallationCreate NetworkHardware SetupContainer OnboardingDocker WorkloadsWebAssembly (Wasm) WorkloadsSetting UpRunning NodesNode OnboardingGPU InstallationJob selection policyAccess ManagementNode persistenceConnect StorageConfiguration ManagementConfiguring Transport Level SecurityLimits and TimeoutsTest Network LocallyBacalhau WebUIWorkload OnboardingContainerDocker Workload OnboardingWebAssembly (Wasm) WorkloadsBacalhau Docker ImageHow To Work With Custom Containers in BacalhauPythonBuilding and Running Custom Python ContainerRunning Pandas on BacalhauRunning a Python ScriptRunning Jupyter Notebooks on BacalhauScripting Bacalhau with PythonR (language)Building and Running your Custom R Containers on BacalhauRunning a Simple R Script on BacalhauRun CUDA programs on BacalhauRunning a Prolog ScriptReading Data from Multiple S3 Buckets using BacalhauRunning Rust programs as WebAssembly (WASM)Generate Synthetic Data using Sparkov Data Generation techniqueData IngestionCopy Data from URL to Public StoragePinning DataRunning a Job over S3 dataNetworking InstructionsAccessing the Internet from JobsUtilizing NATS.io within BacalhauGPU Workloads SetupAutomatic Update CheckingMarketplace DeploymentsGoogle Cloud MarketplaceGuidesWrite a config.yamlWrite a SpecConfigExamplesData EngineeringUsing Bacalhau with DuckDBEthereum Blockchain Analysis with Ethereum-ETL and BacalhauConvert CSV To Parquet Or AvroSimple Image ProcessingOceanography - Data ConversionVideo ProcessingModel InferenceEasyOCR (Optical Character Recognition) on BacalhauRunning Inference on Dolly 2.0 Model with Hugging FaceSpeech Recognition using WhisperStable Diffusion on a GPUStable Diffusion on a CPUObject Detection with YOLOv5 on BacalhauGenerate Realistic Images using StyleGAN3 and BacalhauStable Diffusion Checkpoint InferenceRunning Inference on a Model stored on S3Model TrainingTraining Pytorch Model with BacalhauTraining Tensorflow ModelStable Diffusion Dreambooth (Finetuning)Molecular DynamicsRunning BIDS Apps on BacalhauCoresets On BacalhauGenomics Data GenerationGromacs for AnalysisMolecular Simulation with OpenMM and BacalhauReferencesJobs GuideJob SpecificationJob TypesTask SpecificationEnginesDocker Engine SpecificationWebAssembly (WASM) Engine SpecificationPublishersIPFS Publisher SpecificationLocal Publisher SpecificationS3 Publisher SpecificationSourcesIPFS Source SpecificationLocal Source SpecificationS3 Source SpecificationURL Source SpecificationNetwork SpecificationInput Source SpecificationResources SpecificationResultPath SpecificationConstraint SpecificationLabels SpecificationMeta SpecificationJob TemplatesQueuing & TimeoutsJob QueuingTimeouts SpecificationJob ResultsStateCLI GuideSingle CLI commandsAgentAgent OverviewAgent AliveAgent NodeAgent VersionConfigConfig OverviewConfig Auto-ResourcesConfig DefaultConfig ListConfig SetJobJob OverviewJob DescribeJob ExecJob ExecutionsJob HistoryJob ListJob LogsJob RunJob StopNodeNode OverviewNode ApproveNode DeleteNode ListNode DescribeNode RejectCLI Commands OverviewCommand MigrationAPI GuideBacalhau API overviewBest PracticesAgent EndpointOrchestrator EndpointMigration APINode ManagementAuthentication & AuthorizationDatabase IntegrationDebuggingDebugging Failed JobsDebugging LocallyOpen Telemetry in BacalhauRunning locally in 'devstack'Setting up Dev EnvironmentHelp & FAQBacalhau FAQsRelease NotesGlossaryIntegrationsApache Airflow Provider for BacalhauLilypadBacalhau Python SDKObservability for WebAssembly WorkloadsCommunitySocial MediaStyle GuideWays to ContributePowered by GitBookHow To Work With Custom Containers in BacalhauBacalhau operates by executing jobs within containers. This example shows you how to build and use a custom docker container.PrerequisiteTo get started, you need to install the Bacalhau client, see more informationhereThis example requires Docker. If you don't have Docker installed, you can install it fromhere. Docker commands will not work on hosted notebooks like Google Colab, but the Bacalhau commands will.1. Running ContainersDocker CommandYou're likely familiar with executing Docker commands to start a container:Copydockerrundocker/whalesaycowsaysupoldfashionedcontainerrunThis command runs a container from thedocker/whalesayimage. The container executes thecowsay sup old fashioned container runcommand:Copy_________________________________<sup old fashioned container run>---------------------------------\\\##        .## ## ##       ==## ## ## ##      ===/""""""""""""""""___/===~~~{~~~~~~~~~~~~~~~~/===-~~~\______o__/\\__/\____\______/Bacalhau CommandCopyexportJOB_ID=$(bacalhaudockerrun\--wait\--id-only\docker/whalesay--bash-c'cowsay hello web3 uber-run')This command also runs a container from thedocker/whalesayimage, using Bacalhau. We use thebacalhau docker runcommand to start a job in a Docker container. It contains additional flags such as--waitto wait for job completion and--id-onlyto return only the job identifier. Inside the container, thebash -c 'cowsay hello web3 uber-run'command is executed.When a job is submitted, Bacalhau prints out the relatedjob_id(7e41b9b9-a9e2-4866-9fce-17020d8ec9e0):Copy7e41b9b9-a9e2-4866-9fce-17020d8ec9e0We store that in an environment variable so that we can reuse it later on.You can download your job results directly by usingbacalhau job get. Alternatively, you can choose to create a directory to store your results. In the command below, we created a directory (results) and downloaded our job output to be stored in that directory.Copyrm-rfresults&&mkdir-presultsbacalhaujobget${JOB_ID}--output-dirresultsViewing your job outputCopycat./results/stdout_____________________<hello web3 uber-run>---------------------\\\##        .## ## ##       ==## ## ## ##      ===/""""""""""""""""___/===~~~{~~~~~~~~~~~~~~~~/===-~~~\______o__/\\__/\____\______/Both commands execute cowsay in thedocker/whalesaycontainer, but Bacalhau provides additional features for working with jobs at scale.Bacalhau SyntaxBacalhau uses a syntax that is similar to Docker, and you can use the same containers. The main difference is that input and output data is passed to the container via IPFS, to enable planetary scale. In the example above, it doesn't make too much difference except that we need to download the stdout.The--waitflag tells Bacalhau to wait for the job to finish before returning. This is useful in interactive sessions like this, but you would normally allow jobs to complete in the background and use thebacalhau job listcommand to check on their status.Another difference is that by default Bacalhau overwrites the default entry point for the container, so you have to pass all shell commands as arguments to theruncommand after the--flag.2. Building Your Own Custom Container For BacalhauTo use your own custom container, you must publish the container to a container registry that is accessible from the Bacalhau network. At this time, only public container registries are supported.To demonstrate this, you will develop and build a simple custom container that comes from an old Docker example. I remember seeing cowsay at a Docker conference about a decade ago. I think it's about time we brought it back to life and distribute it across the Bacalhau network.Copy# write to the cod.cow$the_cow=<<"EOC";$thoughts$thoughts,,,,_┌Φ▓╬▓╬▓▓▓W@▓▓▒,╠▓╬▓╬╣╬╬▓╬▓▓   ╔╣╬╬▓╬╣▓,__,┌╓═╠╬╠╬╬╬Ñ╬╬╬Ñ╬╬¼,╣╬╬▓╬╬▓╬▓▓▓┐        ╔W_,φ▓▓,«@▒╠╠╠╠╩╚╙╙╩Ü╚╚╚╚╩╙╙╚╠╩╚╚╟▓▒╠╠╫╣╬╬╫╬╣▓,_φ╬▓╬╬▓,,φ╣▓▓╬╬_,φÆ╩╬╩╙╚╩░╙╙░░╩`=░╙╚»»╦░=╓╙Ü1R░│░╚Ü░╙╙╚╠╠╠╣╣╬≡Φ╬▀╬╣╬╬▓▓▓_   ╓▄▓▓▓▓▓▓╬▌_,φ╬Ñ╩▌▐█[▒░░░░R░░▀░`,_`!R`````╙`-'╚Ü░░Ü░░░░░░░│││░╚╚╙╚╩╩╩╣Ñ╩╠▒▒╩╩▀▓▓╣▓▓╬╠▌'╚╩Ü╙│░░╙Ö▒Ü░░░H░░R ▒¥╣╣@@@▓▓▓  := '`   `░``````````````````````````]▓▓▓╬╬╠H'¬═▄ `\░╙Ü░╠DjK` Å»»╙╣▓▓▓▓╬Ñ     -»`       -`      `  ,;╓▄╔╗∞  ~▓▓▓▀▓▓╬╬╬▌'^^^`   _╒Γ   `╙▀▓▓╨                     _, ⁿD╣▓╬╣▓╬▓╜      ╙╬▓▓╬╬▓▓```└                           _╓▄@▓▓▓╜   `╝╬▓▓╙           ²╣╬▓▓%φ▄╓_~#▓╠▓▒╬▓╬▓▓^        `                ╙╙`╣▓▓▓              ╠╬▓╬▓╬▀`╚▓▌'╨▀╜EOCNext, the Dockerfile adds the script and sets the entry point.Copy# write the DockerfileFROM debian:stretchRUN apt-get update && apt-get install-y cowsay# "cowsay" installs to /usr/gamesENV PATH $PATH:/usr/gamesRUN echo'#!/bin/bash\ncowsay "${@:1}"'>/usr/bin/codsay &&\chmod+x/usr/bin/codsayCOPY cod.cow/usr/share/cowsay/cows/default.cowNow let's build and test the container locally.Copydockerbuild-tghcr.io/bacalhau-project/examples/codsay:latest.2>/dev/nullCopy%%bashdockerrun--rmghcr.io/bacalhau-project/examples/codsay:latestcodsayIlikeswimmingindataOnce your container is working as expected then you should push it to a public container registry. In this example, I'm pushing to Github's container registry, but we'll skip the step below because you probably don't have permission. Remember that the Bacalhau nodes expect your container to have alinux/amd64architecture.Copydockerbuildxbuild--platformlinux/amd64,linux/arm64--push-tghcr.io/bacalhau-project/examples/codsay:latest.3. Running Your Custom Container on BacalhauNow we're ready to submit a Bacalhau job using your custom container. This code runs a job, downloads the results, and prints the stdout.Thebacalhau docker runcommand strips the default entry point, so don't forget to run your entry point in the command line arguments.CopyexportJOB_ID=$(bacalhaudockerrun\--wait\--id-only\ghcr.io/bacalhau-project/examples/codsay:v1.0.0\--bash-c'codsay Look at all this data')When a job is submitted, Bacalhau prints out the relatedjob_id. We store that in an environment variable so that we can reuse it later on.Download your job results directly by usingbacalhau job getcommand.Copyrm-rfresults&&mkdir-presultsbacalhaujobget${JOB_ID}--output-dirresultsView your job outputCopycat./results/stdout_______________________<Look at all this data>-----------------------\\,,,,_┌Φ▓╬▓╬▓▓▓W@▓▓▒,╠▓╬▓╬╣╬╬▓╬▓▓╔╣╬╬▓╬╣▓,__,┌╓═╠╬╠╬╬╬Ñ╬╬╬Ñ╬╬¼,╣╬╬▓╬╬▓╬▓▓▓┐╔W_,φ▓▓,«@▒╠╠╠╠╩╚╙╙╩Ü╚╚╚╚╩╙╙╚╠╩╚╚╟▓▒╠╠╫╣╬╬╫╬╣▓,_φ╬▓╬╬▓,,φ╣▓▓╬╬_,φÆ╩╬╩╙╚╩░╙╙░░╩`=░╙╚»»╦░=╓╙Ü1R░│░╚Ü░╙╙╚╠╠╠╣╣╬≡Φ╬▀╬╣╬╬▓▓▓_╓▄▓▓▓▓▓▓╬▌_,φ╬Ñ╩▌▐█[▒░░░░R░░▀░`,_`!R`````╙`-'╚Ü░░Ü░░░░░░░│││░╚╚╙╚╩╩╩╣Ñ╩╠▒▒╩╩▀▓▓╣▓▓╬╠▌'╚╩Ü╙│░░╙Ö▒Ü░░░H░░R▒¥╣╣@@@▓▓▓:='`   `░``````````````````````````]▓▓▓╬╬╠H'¬═▄`░╙Ü░╠DjK`Å»»╙╣▓▓▓▓╬Ñ-»`-`      `,;╓▄╔╗∞~▓▓▓▀▓▓╬╬╬▌'^^^`   _╒Γ   `╙▀▓▓╨                     _, ⁿD╣▓╬╣▓╬▓╜      ╙╬▓▓╬╬▓▓```└                           _╓▄@▓▓▓╜   `╝╬▓▓╙           ²╣╬▓▓%φ▄╓_             ~#▓╠▓▒╬▓╬▓▓^        `                ╙╙`╣▓▓▓              ╠╬▓╬▓╬▀`╚▓▌               '╨▀╜SupportIf you have questions or need support or guidance, please reach out to theBacalhau team via Slack(#generalchannel).PreviousBacalhau Docker ImageNextPythonLast updated2 months agoOn this pagePrerequisite1. Running ContainersDocker CommandBacalhau CommandBacalhau Syntax2. Building Your Own Custom Container For Bacalhau3. Running Your Custom Container on BacalhauSupportWas this helpful?Edit on GitHubExport as PDFGet SupportExpansoSupportUse CasesDistributed ETLEdge MLDistributed Data WarehousingFlett ManagementAbout UsWho we areWhat we valueNews & BlogBlogNewsExpanso (2024). All Rights Reserved.