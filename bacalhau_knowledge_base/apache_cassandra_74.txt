URL: https://cassandra.apache.org/doc/latest/cassandra/developing/cql/ddl.html

Get StartedCassandra BasicsQuickstartEcosystemDocumentationCommunityWelcomeDiscussionsGovernanceContributeMeet the CommunityCatalyst ProgramEventsLearnCassandra 5.0Case StudiesResourcesBlogDownload NowCassandra DocumentationVersion:5.0mastertrunk5.04.14.03.11MainGlossaryHow to report bugsContact usDevelopmentGetting startedBuilding and IDE integrationTestingContributing code changesCode styleReview checklistHow to commitWorking on documentationJenkins CI environmentDependency managementRelease processCassandraFAQGetting StartedCassandra QuickstartSAI QuickstartVector Search QuickstartInstalling CassandraConfiguring CassandraInserting and queryingClient driversProduction recommendationsWhat’s newSupport for JavaArchitectureOverviewDynamoStorage EngineGuaranteesImproved Internode MessagingImproved StreamingData ModelingIntroductionConceptual data modelingRDBMS designDefining application queriesLogical data modelingPhysical data modelingEvaluating and refining data modelsDefining database schemaCassandra data modeling toolsCassandra Query Language (CQL)DefinitionsData typesData definition (DDL)Data manipulation (DML)Dynamic Data Masking (DDM)OperatorsIndexing conceptsSAI OverviewConceptsSAI QuickstartSAI FAQWorking with SAISAI operationsSecondary indexes (2i) overviewConceptsWorking with 2iRebuild 2iMaterialized viewsFunctionsJSONSecurityTriggersAppendicesChangesSASISingle file of CQL informationVector Search overviewConceptsData ModelingVector Search QuickstartWorking with Vector SearchManagingConfiguringcassandra.yamlcassandra-rackdc.propertiescassandra-env.shcassandra-topologies.propertiescommitlog-archiving.propertieslogback.xmljvm-* filesLiberating cassandra.yaml Parameters' Names from Their UnitsOperatingBackupsBloom filtersBulk loadingChange Data Capture (CDC)CompactionCompressionHardwareHintsLoggingAudit loggingAudit logging 2Full query loggingMonitoring metricsRepairRead repairSecuritySnitchesTopology changesTransient replicationVirtual tablesToolscqlsh: the CQL shellnodetoolSSTable toolscassandra-stressTroubleshootingFinding misbehaving nodesReading Cassandra logsUsing nodetoolUsing external tools to deep-diveReferenceALTER TABLECREATE INDEXCREATE CUSTOM INDEXCREATE TABLEDROP INDEXDROP TABLEPlug-insYou are viewing the documentation for a prerelease version.CassandraCassandra Query Language (CQL)Data definition (DDL)EditData DefinitionCQL stores data intables, whose schema defines the layout of the
data in the table. Tables are located inkeyspaces.
A keyspace defines options that apply to all the keyspace’s tables.
Thereplication strategyis an important keyspace option, as is the replication factor.
A good general rule is one keyspace per application.
It is common for a cluster to define only one keyspace for an active application.This section describes the statements used to create, modify, and remove
those keyspace and tables.Common definitionsThe names of the keyspaces and tables are defined by the following
grammar:keyspace_name::= name
table_name::= [keyspace_name '.' ] name
name::= unquoted_name | quoted_name
unquoted_name::= re('[a-zA-Z_0-9]\{1, 48}')
quoted_name::= '"' unquoted_name '"'Both keyspace and table name should be comprised of only alphanumeric
characters, cannot be empty and are limited in size to 48 characters
(that limit exists mostly to avoid filenames (which may include the
keyspace and table name) to go over the limits of certain file systems).
By default, keyspace and table names are case-insensitive (myTableis
equivalent tomytable) but case sensitivity can be forced by using
double-quotes ("myTable"is different frommytable).Further, a table is always part of a keyspace and a table name can be
provided fully-qualified by the keyspace it is part of. If is is not
fully-qualified, the table is assumed to be in thecurrentkeyspace
(seeUSEstatement).Further, the valid names for columns are defined as:column_name::= identifierWe also define the notion of statement options for use in the following
section:options::= option ( AND option )*
option::= identifier '=' ( identifier
	| constant
	| map_literal )CREATE KEYSPACEA keyspace is created with aCREATE KEYSPACEstatement:create_keyspace_statement::= CREATE KEYSPACE [ IF NOT EXISTS ] keyspace_name
	WITH optionsFor example:CREATE KEYSPACE excelsior
   WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 3};

CREATE KEYSPACE excalibur
   WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1' : 1, 'DC2' : 3}
   AND durable_writes = false;Attempting to create a keyspace that already exists will return an error
unless theIF NOT EXISTSoption is used. If it is used, the statement
will be a no-op if the keyspace already exists.The supportedoptionsare:namekindmandatorydefaultdescriptionreplicationmapyesn/aThe replication strategy and options to use for the keyspace (see
details below).durable_writessimplenotrueWhether to use the commit log for updates on this keyspace (disable this
option at your own risk!).Thereplicationproperty is mandatory and must contain the'class'sub-option that defines the desiredreplication strategyclass.
The rest of the sub-options depend on which replication strategy is used.
By default, Cassandra supports the following'class'values:SimpleStrategyA simple strategy that defines a replication factor for data to be
spread across the entire cluster. This is generally not a wise choice
for production, as it does not respect datacenter layouts and can
lead to wildly varying query latency. For production, useNetworkTopologyStrategy.SimpleStrategysupports a single
mandatory argument:sub-optiontypesincedescription'replication_factor'intallThe number of replicas to store per rangeNetworkTopologyStrategyA production-ready replication strategy that sets the
replication factor independently for each data-center. The rest of the
sub-options are key-value pairs, with a key set to a data-center name and
its value set to the associated replication factor. Options:sub-optiontypedescription'<datacenter>'intThe number of replicas to store per range in the provided datacenter.'replication_factor'intWhen later altering keyspaces and changing thereplication_factor,
auto-expansion will onlyaddnew datacenters for safety, it will not
alter existing datacenters or remove any, even if they are no longer in
the cluster. If you want to remove datacenters while setting thereplication_factor, explicitly zero out the datacenter you want to
have zero replicas.An example of auto-expanding datacenters with two datacenters:DC1andDC2:CREATE KEYSPACE excalibur
    WITH replication = {'class': 'NetworkTopologyStrategy', 'replication_factor' : 3};

DESCRIBE KEYSPACE excalibur;will result in:CREATE KEYSPACE excalibur WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '3', 'DC2': '3'} AND durable_writes = true;An example of auto-expanding and overriding a datacenter:CREATE KEYSPACE excalibur
   WITH replication = {'class': 'NetworkTopologyStrategy', 'replication_factor' : 3, 'DC2': 2};

DESCRIBE KEYSPACE excalibur;will result in:CREATE KEYSPACE excalibur WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '3', 'DC2': '2'} AND durable_writes = true;An example that excludes a datacenter while usingreplication_factor:CREATE KEYSPACE excalibur
   WITH replication = {'class': 'NetworkTopologyStrategy', 'replication_factor' : 3, 'DC2': 0};

DESCRIBE KEYSPACE excalibur;will result in:CREATE KEYSPACE excalibur WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '3'} AND durable_writes = true;Iftransient replicationhas been enabled, transient replicas can be
configured for bothSimpleStrategyandNetworkTopologyStrategyby
defining replication factors in the format'<total_replicas>/<transient_replicas>'For instance, this keyspace will have 3 replicas in DC1, 1 of which is
transient, and 5 replicas in DC2, 2 of which are transient:CREATE KEYSPACE some_keyspace
   WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1' : '3/1'', 'DC2' : '5/2'};USETheUSEstatement changes thecurrentkeyspace to the specified keyspace.
A number of objects in CQL are bound to a keyspace (tables, user-defined types, functions, etc.) and the
current keyspace is the default keyspace used when those objects are
referred to in a query without a fully-qualified name (without a prefixed keyspace name).
AUSEstatement specifies the keyspace to use as an argument:use_statement::= USE keyspace_nameUsing CQL:USE excelsior;ALTER KEYSPACEAnALTER KEYSPACEstatement modifies the options of a keyspace:alter_keyspace_statement::= ALTER KEYSPACE [ IF EXISTS ] keyspace_name
	WITH optionsFor example:ALTER KEYSPACE excelsior
    WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 4};If the keyspace does not exist, the statement will return an error, unlessIF EXISTSis used in which case the operation is a no-op.
The supported options are the same as forcreating a keyspace.DROP KEYSPACEDropping a keyspace is done with theDROP KEYSPACEstatement:drop_keyspace_statement::= DROP KEYSPACE [ IF EXISTS ] keyspace_nameFor example:DROP KEYSPACE excelsior;Dropping a keyspace results in the immediate, irreversible removal of
that keyspace, including all the tables, user-defined types, user-defined functions, and
all the data contained in those tables.If the keyspace does not exists, the statement will return an error,
unlessIF EXISTSis used in which case the operation is a no-op.CREATE TABLECreating a new table uses theCREATE TABLEstatement:create_table_statement::= CREATE TABLE [ IF NOT EXISTS ] table_name '('
	column_definition  ( ',' column_definition )*
	[ ',' PRIMARY KEY '(' primary_key ')' ]
	 ')' [ WITH table_options ]
column_definition::= column_name cql_type [ STATIC ] [ column_mask ] [ PRIMARY KEY]
column_mask::= MASKED WITH ( DEFAULT | function_name '(' term ( ',' term )* ')' )
primary_key::= partition_key [ ',' clustering_columns ]
partition_key::= column_name  | '(' column_name ( ',' column_name )* ')'
clustering_columns::= column_name ( ',' column_name )*
table_options::= COMPACT STORAGE [ AND table_options ]
	| CLUSTERING ORDER BY '(' clustering_order ')'
	[ AND table_options ]  | options
clustering_order::= column_name (ASC | DESC) ( ',' column_name (ASC | DESC) )*For example, here are some CQL statements to create tables:CREATE TABLE monkey_species (
    species text PRIMARY KEY,
    common_name text,
    population varint,
    average_size int
) WITH comment='Important biological records';

CREATE TABLE timeline (
    userid uuid,
    posted_month int,
    posted_time uuid,
    body text,
    posted_by text,
    PRIMARY KEY (userid, posted_month, posted_time)
) WITH compaction = { 'class' : 'LeveledCompactionStrategy' };

CREATE TABLE loads (
    machine inet,
    cpu int,
    mtime timeuuid,
    load float,
    PRIMARY KEY ((machine, cpu), mtime)
) WITH CLUSTERING ORDER BY (mtime DESC);A CQL table has a name and is composed of a set ofrows.
Creating a table amounts to defining whichcolumnseach rows will have,
which of those columns comprise theprimary key, as well as definedoptionsfor the table.Attempting to create an already existing table will return an error
unless theIF NOT EXISTSdirective is used. If it is used, the
statement will be a no-op if the table already exists.Column definitionsEvery row in a CQL table will have the predefined columns defined at table creation.
Columns can be added later using analter statement.Acolumn_definitionis comprised of the name of the column and itstype,
restricting the  values that are accepted for that column. Additionally, a column definition can have the
following modifiers:STATIC: declares the column as astatic columnPRIMARY KEY: declares the column as the sole component of theprimary keyof the tableStatic columnsSome columns can be declared asSTATICin a table definition. A column
that is static will be âsharedâ by all the rows belonging to the same
partition (having the samepartition key.For example:CodeResultsCREATE TABLE t (
    pk int,
    t int,
    v text,
    s text static,
    PRIMARY KEY (pk, t)
);
INSERT INTO t (pk, t, v, s) VALUES (0, 0, 'val0', 'static0');
INSERT INTO t (pk, t, v, s) VALUES (0, 1, 'val1', 'static1');
SELECT * FROM t;pk | t | v      | s
  ----+---+--------+-----------
   0  | 0 | 'val0' | 'static1'
   0  | 1 | 'val1' | 'static1'As can be seen, thesvalue is the same (static1) for both of the
rows in the partition (the partition key beingpk, and both
rows are in the same partition): the second insertion overrides the
value fors.The use of static columns has the following restrictions:A table without clustering columns cannot have static columns.
In a table without clustering columns, every partition has only one row, and
so every column is inherently static)Only non-primary key columns can be static.The Primary keyWithin a table, a row is uniquely identified by itsPRIMARY KEY, and
hence all tablesmustdefine a single PRIMARY KEY.
APRIMARY KEYis composed of one or more of the defined columns in the table.
Syntactically, the primary key is defined with the phrasePRIMARY KEYfollowed by a comma-separated list of the column names within parenthesis.
If the primary key has only one column, you can alternatively add thePRIMARY KEYphrase to
that column in the table definition.
The order of the columns in the primary key definition defines the partition key and
clustering columns.A CQL primary key is composed of two parts:partition keyIt is the first component of the primary key definition.
It can be a single column or, using an additional set of parenthesis, can be multiple columns.
A table must have at least one partition key, the smallest possible table definition is:CREATE TABLE t (k text PRIMARY KEY);clustering columnsThe columns are the columns that follow the partition key in the primary key definition.
The order of those columns define theclustering order.Some examples of primary key definition are:PRIMARY KEY (a):ais the single partition key and there are no clustering columnsPRIMARY KEY (a, b, c):ais the single partition key andbandcare the clustering columnsPRIMARY KEY ((a, b), c):aandbcompose thecompositepartition key andcis the clustering columnThe primary key uniquely identifies a row in the table, as described above.
A consequence of this uniqueness is that if another row is inserted using the same primary key,
then anUPSERToccurs and an existing row with the same primary key is replaced.
Columns that are not part of the primary key cannot define uniqueness.Partition keyWithin a table, CQL defines the notion of apartitionthat defines the location of data within a Cassandra cluster.
A partition is the set of rows that share the same value for their partition key.Note that if the partition key is composed of multiple columns, then rows belong to the same partition
when they have the same values for all those partition key columns.
A hash is computed from the partition key columns and that hash value defines the partition location.
So, for instance, given the following table definition and content:CREATE TABLE t (
    a int,
    b int,
    c int,
    d int,
    PRIMARY KEY ((a, b), c, d)
);
INSERT INTO t (a, b, c, d) VALUES (0,0,0,0);
INSERT INTO t (a, b, c, d) VALUES (0,0,1,1);
INSERT INTO t (a, b, c, d) VALUES (0,1,2,2);
INSERT INTO t (a, b, c, d) VALUES (0,1,3,3);
INSERT INTO t (a, b, c, d) VALUES (1,1,4,4);
SELECT * FROM t;will result ina | b | c | d
---+---+---+---
 0 | 0 | 0 | 0(1)0 | 0 | 1 | 1
 0 | 1 | 2 | 2(2)0 | 1 | 3 | 3
 1 | 1 | 4 | 4(3)(5 rows)1Rows 1 and 2 are in the same partition, because both columnsaandbare zero.2Rows 3 and 4 are in the same partition, but a different one, because columnais zero and columnbis 1 in both rows.3Row 5 is in a third partition by itself, because both columnsaandbare 1.Note that a table always has a partition key, and that if the table has
noclustering columns, then every partition of that table has a single row.
because the partition key, compound or otherwise, identifies a single location.The most important property of partition is that all the rows belonging
to the same partition are guaranteed to be stored on the same set of
replica nodes.
In other words, the partition key of a table defines which rows will be localized on the same
node in the cluster.
The localization of data is important to the efficient retrieval of data, requiring the Cassandra coordinator
to contact as few nodes as possible.
However, there is a flip-side to this guarantee, and all rows sharing a partition key will be stored on the same
node, creating a hotspot for both reading and writing.
While selecting a primary key that groups table rows assists batch updates and can ensure that the updates areatomicand done inisolation, the partitions must be sized "just right, not too big nor too small".Data modeling that considers the querying patterns and assigns primary keys based on the queries will have the lowest
latency in fetching data.Clustering columnsThe clustering columns of a table define the clustering order for the partition of that table.
For a givenpartition, all rows are ordered by that clustering order. Clustering columns also add uniqueness to
a row in a table.For instance, given:CREATE TABLE t2 (
    a int,
    b int,
    c int,
    d int,
    PRIMARY KEY (a, b, c)
);
INSERT INTO t2 (a, b, c, d) VALUES (0,0,0,0);
INSERT INTO t2 (a, b, c, d) VALUES (0,0,1,1);
INSERT INTO t2 (a, b, c, d) VALUES (0,1,2,2);
INSERT INTO t2 (a, b, c, d) VALUES (0,1,3,3);
INSERT INTO t2 (a, b, c, d) VALUES (1,1,4,4);
SELECT * FROM t2;will result ina | b | c | d
---+---+---+---
 1 | 1 | 4 | 4(1)0 | 0 | 0 | 0
 0 | 0 | 1 | 1
 0 | 1 | 2 | 2
 0 | 1 | 3 | 3

(5 rows)1Row 1 is in one partition, and Rows 2-5 are in a different one. The display order is also different.Looking more closely at the four rows in the same partition, thebclustering column defines the order in which those rows
are displayed.
Whereas the partition key of the table groups rows on the same node, the clustering columns control
how those rows are stored on the node.That sorting allows the very efficient retrieval of a range of rows within a partition:SELECT * FROM t2 WHERE a = 0 AND b > 0 and b <= 3;will result ina | b | c | d
---+---+---+---
 0 | 1 | 2 | 2
 0 | 1 | 3 | 3

(2 rows)Table optionsA CQL table has a number of options that can be set at creation (and,
for most of them, altered later). These options are specified after theWITHkeyword.One important option that cannot be changed after creation,CLUSTERING ORDER BY, influences how queries can be done against the table. It is worth discussing in more detail here.Clustering orderThe clustering order of a table is defined by the clustering columns.
By default, the clustering order is ascending for the clustering column’s data types.
For example, integers order from 1, 2, …​ n, while text orders from A to Z.TheCLUSTERING ORDER BYtable option uses a comma-separated list of the
clustering columns, each set for eitherASC(forascendingorder) orDESC(for _descending order).
The default is ascending for all clustering columns if theCLUSTERING ORDER BYoption is not set.This option is basically a hint for the storage engine that changes the order in which it stores the row.
Beware of the consequences of setting this option:It changes the default ascending order of results when queried with aSELECTstatement with noORDER BYclause.It limits how theORDER BYclause is used inSELECTstatements on that table.
Results can only be ordered with either the original clustering order or the reverse clustering order.
Suppose you create a table with two clustering columnsaandb, definedWITH CLUSTERING ORDER BY (a DESC, b ASC).
Queries on the table can useORDER BY (a DESC, b ASC)orORDER BY (a ASC, b DESC).
Mixed order, such asORDER BY (a ASC, b ASC)orORDER BY (a DESC, b DESC)will not return expected order.It has a performance impact on queries. Queries in reverse clustering order are slower than the default ascending order.
If you plan to query mostly in descending order, declare the clustering order in the table schema usingWITH CLUSTERING ORDER BY ().
This optimization is common for time series, to retrieve the data from newest to oldest.Other table optionsA table supports the following options:optionkinddefaultdescriptioncommentsimplenoneA free-form, human-readable commentspeculative_retrysimple99PERCENTILESpeculative retry optionscdcbooleanfalseCreate a Change Data Capture (CDC) log on the tableadditional_write_policysimple99PERCENTILESame asspeculative_retrygc_grace_secondssimple864000Time to wait before garbage collecting tombstones (deletion markers)bloom_filter_fp_chancesimple0.00075The target probability of
false positive of the sstable bloom filters. Said bloom filters will be
sized to provide the provided probability, thus lowering this value
impacts the size of bloom filters in-memory and on-disk.default_time_to_livesimple0Default expiration time (âTTLâ) in seconds for a tablecompactionmapsee belowCompaction optionscompressionmapsee belowCompression optionscachingmapsee belowCaching optionsmemtable_flush_period_in_mssimple0Time (in ms) before Cassandra flushes memtables to diskread_repairsimpleBLOCKINGSets read repair behavior (see below)Speculative retry optionsBy default, Cassandra read coordinators only query as many replicas as
necessary to satisfy consistency levels: one for consistency levelONE, a quorum forQUORUM, and so on.speculative_retrydetermines
when coordinators may query additional replicas, a useful action when
replicas are slow or unresponsive. Speculative retries reduce the latency.
The speculative_retry option configures rapid read protection, where a coordinator sends more
requests than needed to satisfy the consistency level.Frequently reading from additional replicas can hurt cluster
performance. When in doubt, keep the default99PERCENTILE.Pre-Cassandra 4.0 speculative retry policy takes a single string as a parameter:NONEALWAYS99PERCENTILE(PERCENTILE)50MS(CUSTOM)An example of setting speculative retry sets a custom value:ALTER TABLE users WITH speculative_retry = '10ms';This example uses a percentile for the setting:ALTER TABLE users WITH speculative_retry = '99PERCENTILE';A percentile setting can backfire. If a single host becomes unavailable, it can
force up the percentiles. A value ofp99will not speculate as intended because the
value at the specified percentile has increased too much. If the consistency level is set toALL, all
replicas are queried regardless of the speculative retry setting.Cassandra 4.0 supports case-insensitivity for speculative retry values (CASSANDRA-14293). For example, assigning the value asnone,None, orNONEhas the same effect.Additionally, the following values are added:FormatExampleDescriptionXPERCENTILE90.5PERCENTILECoordinators record average per-table response times
for all replicas. If a replica takes longer thanXpercent of this
table’s average response time, the coordinator queries an additional
replica.Xmust be between 0 and 100.XP90.5PSame asXPERCENTILEYms25msIf a replica takes more thanYmilliseconds to respond, the
coordinator queries an additional replica.MIN(XPERCENTILE,YMS)MIN(99PERCENTILE,35MS)A hybrid policy that uses either the
specified percentile or fixed milliseconds depending on which value is
lower at the time of calculation. Parameters areXPERCENTILE,XP, orYms. This setting helps protect against a single slow instance.MAX(XPERCENTILE,YMS)ALWAYSNEVERMAX(90.5P,25ms)A hybrid policy that uses either the specified
percentile or fixed milliseconds depending on which value is higher at
the time of calculation.Cassandra 4.0 adds support for hybridMIN()andMAX()speculative retry policies, with a mix and match of eitherMIN(), MAX(),MIN(), MIN(), orMAX(), MAX()(CASSANDRA-14293).
The hybrid mode will still speculate if the normalp99for the table is < 50ms, the minimum value.
But if thep99level goes higher than the maximum value, then that value can be used.
In a hybrid value, one value must be a fixed time (ms) value and the other a percentile value.To illustrate variations, the following examples are all valid:min(99percentile,50ms)
max(99p,50MS)
MAX(99P,50ms)
MIN(99.9PERCENTILE,50ms)
max(90percentile,100MS)
MAX(100.0PERCENTILE,60ms)Theadditional_write_policysetting specifies the threshold at which a cheap
quorum write will be upgraded to include transient replicas.Compaction optionsThecompactionoptions must minimally define the'class'sub-option,
to specify the compaction strategy class to use.
The supported classes are:'SizeTieredCompactionStrategy',STCS(Default)'LeveledCompactionStrategy',LCS'TimeWindowCompactionStrategy',TWCSIf a custom strategies is required, specify the full class name as astring constant.All default strategies support a number ofcommon options, as well as options specific to the strategy chosen. See the section corresponding to your strategy for details:STCS,LCS,TWCS.Compression optionsThecompressionoptions define if and how the SSTables of the table
are compressed. Compression is configured on a per-table basis as an
optional argument toCREATE TABLEorALTER TABLE. The following
sub-options are available:OptionDefaultDescriptionclassLZ4CompressorThe compression algorithm to use. Default compressor are: LZ4Compressor,
SnappyCompressor, DeflateCompressor and ZstdCompressor.
Use'enabled' : falseto disable compression.
Custom compressor can be provided by specifying the full class name as astring constant.enabledtrueEnable/disable sstable compression.
If theenabledoption is set tofalse, no other options must be specified.chunk_length_in_kb64On disk SSTables are compressed by block (to allow random reads).
This option defines the size (in KB) of said block. Seenotefor further information.compression_level3Compression level. Only applicable forZstdCompressor.
Accepts values between-131072and22.Bigger values may improve the compression rate, but will increase the minimum size of data to be read from
disk for a read.
The default value is an optimal value for compressing tables.
Chunk length must be a power of 2 when computing the chunk number from an uncompressed file offset.
Block size may be adjusted based on read/write access patterns such as:How much data is typically requested at onceAverage size of rows in the tableFor instance, to create a table with LZ4Compressor and achunk_length_in_kbof 4 KB:CREATE TABLE simple (
   id int,
   key text,
   value text,
   PRIMARY KEY (key, value)
) WITH compression = {'class': 'LZ4Compressor', 'chunk_length_in_kb': 4};Caching optionsCaching optimizes the use of cache memory of a table. The cached data is
weighed by size and access frequency.
Thecachingoptions can configure both thekey cacheand therow cachefor the table.
The following sub-options are available:OptionDefaultDescriptionkeysALLWhether to cache keys (key cache) for this table. Valid values are:ALLandNONE.rows_per_partitionNONEThe amount of rows to cache per partition (row cache).
If an integernis specified, the firstnqueried rows of a partition will be cached.
Valid values are:ALL, to cache all rows of a queried partition, orNONEto disable row caching.For instance, to create a table with both a key cache and 10 rows cached per partition:CREATE TABLE simple (
id int,
key text,
value text,
PRIMARY KEY (key, value)
) WITH caching = {'keys': 'ALL', 'rows_per_partition': 10};Read Repair optionsTheread_repairoptions configure the read repair behavior, tuning for various performance and consistency behaviors.The values are:OptionDefaultDescriptionBLOCKINGyesIf a read repair is triggered, the read blocks writes sent to other replicas until the consistency level is reached by the writes.NONEnoIf set, the coordinator reconciles any differences between replicas, but doesn’t attempt to repair them.Two consistency properties are affected by read repair behavior.Monotonic quorum reads: Monotonic quorum reads
prevents reads from appearing to go back in time in some circumstances.
When monotonic quorum reads are not provided and a write fails to reach
a quorum of replicas, the read values may be visible in one read, and then disappear
in a subsequent read.BLOCKINGprovides this behavior.Write atomicity: Write atomicity prevents reads
from returning partially-applied writes. Cassandra attempts to provide
partition-level write atomicity, but since only the data covered by a
SELECT statement is repaired by a read repair, read repair can break
write atomicity when data is read at a more granular level than it is
written. For example, read repair can break write atomicity if you write
multiple rows to a clustered partition in a batch, but then select a
single row by specifying the clustering column in a SELECT statement.NONEprovides this behavior.Other considerations:Adding new columns (seeALTER TABLEbelow) is a constant time
operation. Thus, there is no need to anticipate future usage while initially creating a table.ALTER TABLEAltering an existing table uses theALTER TABLEstatement:alter_table_statement::= ALTER TABLE [ IF EXISTS ] table_name alter_table_instruction
alter_table_instruction::= ADD [ IF NOT EXISTS ] column_definition ( ',' column_definition)*
	| DROP [ IF EXISTS ] column_name ( ',' column_name )*
	| RENAME [ IF EXISTS ] column_name to column_name (AND column_name to column_name)*
	| ALTER [ IF EXISTS ] column_name ( column_mask | DROP MASKED )
	| WITH options
column_definition::= column_name cql_type [ column_mask]
column_mask::= MASKED WITH ( DEFAULT | function_name '(' term ( ',' term )* ')' )If the table does not exist, the statement will return an error, unlessIF EXISTSis used in which case the operation is a no-op.For example:ALTER TABLE addamsFamily ADD gravesite varchar;
ALTER TABLE addamsFamily
   WITH comment = 'A most excellent and useful table';TheALTER TABLEstatement can:ADDa new column to a table. The primary key of a table cannot ever be altered.
A new column, thus, cannot be part of the primary key.
Adding a column is a constant-time operation based on the amount of data in the table.
If the new column already exists, the statement will return an error, unlessIF NOT EXISTSis used in which case the operation is a no-op.DROPa column from a table. This command drops both the column and all
its content. Be aware that, while the column becomes immediately
unavailable, its content are removed lazily during compaction. Because of this lazy removal,
the command is a constant-time operation based on the amount of data in the table.
Also, it is important to know that once a column is dropped, a column with the same name can be re-added,
unless the dropped column was a non-frozen column like a collection.
If the dropped column does not already exist, the statement will return an error, unlessIF EXISTSis used in which case the operation is a no-op.WarningDropping a column assumes that the timestamps used for the value of this
column are "real" timestamp in microseconds. Using "real" timestamps in
microseconds is the default is and isstronglyrecommended but as
Cassandra allows the client to provide any timestamp on any table, it is
theoretically possible to use another convention. Please be aware that
if you do so, dropping a column will not correctly execute.RENAMEa primary key column of a table. Non primary key columns cannot be renamed.
Furthermore, renaming a column to another name which already exists isn’t allowed.
It’s important to keep in mind that renamed columns shouldn’t have dependent seconday indexes.
If the renamed column does not already exist, the statement will return an error, unlessIF EXISTSis used in which case the operation is a no-op.UseWITHto change a table option. Thesupported optionsare the same as those used when creating a table, with the exception ofCLUSTERING ORDER.
However, setting anycompactionsub-options will eraseALLpreviouscompactionoptions, so you need to re-specify
all the sub-options you wish to keep. The same is true forcompressionsub-options.DROP TABLEDropping a table uses theDROP TABLEstatement:drop_table_statement::= DROP TABLE [ IF EXISTS ] table_nameDropping a table results in the immediate, irreversible removal of the
table, including all data it contains.If the table does not exist, the statement will return an error, unlessIF EXISTSis used, when the operation is a no-op.TRUNCATE TABLEA table can be truncated using theTRUNCATEstatement:truncate_statement::= TRUNCATE [ TABLE ] table_nameTRUNCATE TABLE foois the preferred syntax for consistency with other DDL
statements.
However, tables are the only object that can be truncated currently, and theTABLEkeyword can be omitted.Truncating a table permanently removes all existing data from the table, but without removing the table itself.Get started with Cassandra, fast.Quickstart GuideApache Cassandrapowers mission-critical deployments with improved performance and unparalleled levels of scale in the cloud.HomeCassandra BasicsQuickstartEcosystemDocumentationCommunityCase StudiesResourcesBlogFoundationEventsLicenseThanksSecurityPrivacySponsorshipÂ© 2009-The Apache Software Foundationunder the terms of the Apache License 2.0.  Apache, the Apache feather logo, Apache Cassandra, Cassandra, and the Cassandra logo, are either registered trademarks or trademarks of The Apache Software Foundation.