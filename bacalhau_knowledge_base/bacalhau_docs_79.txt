URL: https://docs.bacalhau.org/examples/model-training/stable-diffusion-dreambooth-finetuning

Bacalhau Docsv.1.4.0v.1.3.0v.1.3.1v.1.3.2v.1.4.0GitHubSlackContactMoreGitHubSlackContactAsk or SearchCtrl+â€†KWelcomeGetting StartedHow Bacalhau WorksInstallationCreate NetworkHardware SetupContainer OnboardingDocker WorkloadsWebAssembly (Wasm) WorkloadsSetting UpRunning NodesNode OnboardingGPU InstallationJob selection policyAccess ManagementNode persistenceConnect StorageConfiguration ManagementConfiguring Transport Level SecurityLimits and TimeoutsTest Network LocallyBacalhau WebUIWorkload OnboardingContainerDocker Workload OnboardingWebAssembly (Wasm) WorkloadsBacalhau Docker ImageHow To Work With Custom Containers in BacalhauPythonBuilding and Running Custom Python ContainerRunning Pandas on BacalhauRunning a Python ScriptRunning Jupyter Notebooks on BacalhauScripting Bacalhau with PythonR (language)Building and Running your Custom R Containers on BacalhauRunning a Simple R Script on BacalhauRun CUDA programs on BacalhauRunning a Prolog ScriptReading Data from Multiple S3 Buckets using BacalhauRunning Rust programs as WebAssembly (WASM)Generate Synthetic Data using Sparkov Data Generation techniqueData IngestionCopy Data from URL to Public StoragePinning DataRunning a Job over S3 dataNetworking InstructionsAccessing the Internet from JobsUtilizing NATS.io within BacalhauGPU Workloads SetupAutomatic Update CheckingMarketplace DeploymentsGoogle Cloud MarketplaceGuidesWrite a config.yamlWrite a SpecConfigExamplesData EngineeringUsing Bacalhau with DuckDBEthereum Blockchain Analysis with Ethereum-ETL and BacalhauConvert CSV To Parquet Or AvroSimple Image ProcessingOceanography - Data ConversionVideo ProcessingModel InferenceEasyOCR (Optical Character Recognition) on BacalhauRunning Inference on Dolly 2.0 Model with Hugging FaceSpeech Recognition using WhisperStable Diffusion on a GPUStable Diffusion on a CPUObject Detection with YOLOv5 on BacalhauGenerate Realistic Images using StyleGAN3 and BacalhauStable Diffusion Checkpoint InferenceRunning Inference on a Model stored on S3Model TrainingTraining Pytorch Model with BacalhauTraining Tensorflow ModelStable Diffusion Dreambooth (Finetuning)Molecular DynamicsRunning BIDS Apps on BacalhauCoresets On BacalhauGenomics Data GenerationGromacs for AnalysisMolecular Simulation with OpenMM and BacalhauReferencesJobs GuideJob SpecificationJob TypesTask SpecificationEnginesDocker Engine SpecificationWebAssembly (WASM) Engine SpecificationPublishersIPFS Publisher SpecificationLocal Publisher SpecificationS3 Publisher SpecificationSourcesIPFS Source SpecificationLocal Source SpecificationS3 Source SpecificationURL Source SpecificationNetwork SpecificationInput Source SpecificationResources SpecificationResultPath SpecificationConstraint SpecificationLabels SpecificationMeta SpecificationJob TemplatesQueuing & TimeoutsJob QueuingTimeouts SpecificationJob ResultsStateCLI GuideSingle CLI commandsAgentAgent OverviewAgent AliveAgent NodeAgent VersionConfigConfig OverviewConfig Auto-ResourcesConfig DefaultConfig ListConfig SetJobJob OverviewJob DescribeJob ExecJob ExecutionsJob HistoryJob ListJob LogsJob RunJob StopNodeNode OverviewNode ApproveNode DeleteNode ListNode DescribeNode RejectCLI Commands OverviewCommand MigrationAPI GuideBacalhau API overviewBest PracticesAgent EndpointOrchestrator EndpointMigration APINode ManagementAuthentication & AuthorizationDatabase IntegrationDebuggingDebugging Failed JobsDebugging LocallyOpen Telemetry in BacalhauRunning locally in 'devstack'Setting up Dev EnvironmentHelp & FAQBacalhau FAQsRelease NotesGlossaryIntegrationsApache Airflow Provider for BacalhauLilypadBacalhau Python SDKObservability for WebAssembly WorkloadsCommunitySocial MediaStyle GuideWays to ContributePowered by GitBookStable Diffusion Dreambooth (Finetuning)Introductionâ€‹Stable diffusion has revolutionalized text2image models by producing high quality images based on a prompt. Dreambooth is a approach for personalization of text-to-image diffusion models. With images as input subject, we can fine-tune a pretrained text-to-image modelAlthough thedreambooth paperusedImagento finetune the pre-trained model since both the Imagen model and Dreambooth code are closed source, several opensource projects have emerged using stable diffusion.Dreambooth makes stable-diffusion even more powered with the ability to generate realistic looking pictures of humans, animals or any other object by just training them on 20-30 images.In this example tutorial, we will be fine-tuning a pretrained stable diffusion using images of a human and generating images of him drinking coffee.TL;DRâ€‹The following command generates the following:Subject: SBFPrompt: a photo of SBF without hairCopybacalhaudockerrun\--gpu1\--timeout3600\--wait-timeout-secs3600\-iipfs://QmRKnvqvpFzLjEoeeNNGHtc7H8fCn9TvNWHFnbBHkK8Mhy\jsacex/dreambooth:full\--bashfinetune.sh/inputs/outputs"a photo of sbf man""a photo of man"3000"/man""/model"Inferenceâ€‹Copybacalhaudockerrun\--gpu1\-iipfs://QmUEJPr5pfV6tRzWQuNSSb3wdcN6tRQS5tdk3dYSCJ55Xs:/SBF.ckpt\jsacex/stable-diffusion-ckpt\-- conda run --no-capture-output -n ldm python scripts/txt2img.py --prompt "a photo of sbf without hair" --plms --ckpt ../SBF.ckpt --skip_grid --n_samples 1 --skip_grid --outdir ../outputsOutput:Prerequisitesâ€‹To get started, you need to install the Bacalhau client, see more informationhereSetting up Docker Containerâ€‹You can skip this section entirely and directly go torunning a job on BacalhauBuilding this container requires you to have a supported GPU which needs to have 16gb+ of memory, since it can be resource intensive.We will create aDockerfileand add the desired configuration to the file. Following commands specify how the image will be built, and what extra requirements will be included:CopyFROMpytorch/pytorch:1.12.1-cuda11.3-cudnn8-develWORKDIR/# Install requirements# RUN git clone https://github.com/TheLastBen/diffusersRUNapt update && apt install wget git unzip -yRUN wget -q https://gist.githubusercontent.com/js-ts/28684a7e6217214ec944a9224584e9af/raw/d7492bc8f36700b75d51e3346259d1a466b99a40/train_dreambooth.pyRUNwget -q https://github.com/TheLastBen/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py# RUN cp /content/convert_diffusers_to_original_stable_diffusion.py /content/diffusers/scripts/convert_diffusers_to_original_stable_diffusion.pyRUNpip install -qq git+https://github.com/TheLastBen/diffusersRUNpip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort# Install xformersRUN pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whlRUNwget'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Women'-O woman.zipRUNwget'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Men'-O man.zipRUNwget'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Mix'-O mix.zipRUNunzip -j woman.zip -d womanRUNunzip -j man.zip -d manRUNunzip -j mix.zip -d mixThis container is using thepytorch/pytorch:1.12.1-cuda11.3-cudnn8-develimage and the working directory is set. Next, we add our custom code and pull the dependent repositories.Copy# finetune.shpythonclear_mem.pyacceleratelaunchtrain_dreambooth.py\--image_captions_filename\--train_text_encoder\--save_n_steps=$(expr$5 /6)\--stop_text_encoder_training=$(expr$5 +100)\--class_data_dir="$6"\--pretrained_model_name_or_path=${7:=/model}\--tokenizer_name=${7:=/model}/tokenizer/\--instance_data_dir="$1"\--output_dir="$2"\--instance_prompt="$3"\--class_prompt="$4"\--seed=96576\--resolution=512\--mixed_precision="fp16"\--train_batch_size=1\--gradient_accumulation_steps=1\--use_8bit_adam\--learning_rate=2e-6\--lr_scheduler="polynomial"\--center_crop\--lr_warmup_steps=0\--max_train_steps=$5echoConvertweightstockptpythonconvert_diffusers_to_original_stable_diffusion.py--model_path$2--checkpoint_path$2/model.ckpt--halfechomodelsavedat$2/model.ckptThe shell script is there to make things much simpler since the command to train the model needs many parameters to pass and later convert the model weights to the checkpoint, you can edit this script and add in your own parametersDownloading the modelsâ€‹To download the models and run a test job in the Docker file, copy the following:CopyFROMpytorch/pytorch:1.12.1-cuda11.3-cudnn8-develWORKDIR/# Install requirements# RUN git clone https://github.com/TheLastBen/diffusersRUNapt update && apt install wget git unzip -yRUN wget -q https://gist.githubusercontent.com/js-ts/28684a7e6217214ec944a9224584e9af/raw/d7492bc8f36700b75d51e3346259d1a466b99a40/train_dreambooth.pyRUNwget -q https://github.com/TheLastBen/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py# RUN cp /content/convert_diffusers_to_original_stable_diffusion.py /content/diffusers/scripts/convert_diffusers_to_original_stable_diffusion.pyRUNpip install -qq git+https://github.com/TheLastBen/diffusersRUNpip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort# Install xformersRUN pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl# You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox if you agree. You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work.# https://huggingface.co/settings/tokensRUNmkdir -p ~/.huggingfaceRUNecho -n"<your-hugging-face-token>"> ~/.huggingface/token# copy the test dataset from a local file# COPY jfk /jfk# Download and extract the test datasetRUNwget https://github.com/js-ts/test-images/raw/main/jfk.zipRUNunzip -j jfk.zip -d jfkRUNmkdir modelRUNwget'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Women'-O woman.zipRUNwget'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Men'-O man.zipRUNwget'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Regularization/Mix'-O mix.zipRUNunzip -j woman.zip -d womanRUNunzip -j man.zip -d manRUNunzip -j mix.zip -d mixRUNaccelerate launch train_dreambooth.py \--image_captions_filename \--train_text_encoder \--save_starting_step=5\--stop_text_encoder_training=31 \--class_data_dir=/man \--save_n_steps=5 \--pretrained_model_name_or_path="CompVis/stable-diffusion-v1-4"\--instance_data_dir="/jfk"\--output_dir="/model"\--instance_prompt="a photo of jfk man"\--class_prompt="a photo of man"\--instance_prompt=""\--seed=96576 \--resolution=512 \--mixed_precision="fp16"\--train_batch_size=1 \--gradient_accumulation_steps=1 \--use_8bit_adam \--learning_rate=2e-6 \--lr_scheduler="polynomial"\--center_crop \--lr_warmup_steps=0 \--max_train_steps=30COPYfinetune.sh /finetune.shRUN wget -q https://gist.githubusercontent.com/js-ts/624fecc3fff807d4948688cb28993a94/raw/fd69ac084debe26a815485c1f363b8a45566f1ba/clear_mem.py# Removing your tokenRUNrm -rf  ~/.huggingface/tokenThen executefinetune.shwith following commands:Copy# finetune.shpythonclear_mem.pyacceleratelaunchtrain_dreambooth.py\--image_captions_filename\--train_text_encoder\--save_n_steps=$(expr$5 /6)\--stop_text_encoder_training=$(expr$5 +100)\--class_data_dir="$6"\--pretrained_model_name_or_path=${7:=/model}\--tokenizer_name=${7:=/model}/tokenizer/\--instance_data_dir="$1"\--output_dir="$2"\--instance_prompt="$3"\--class_prompt="$4"\--seed=96576\--resolution=512\--mixed_precision="fp16"\--train_batch_size=1\--gradient_accumulation_steps=1\--use_8bit_adam\--learning_rate=2e-6\--lr_scheduler="polynomial"\--center_crop\--lr_warmup_steps=0\--max_train_steps=$5echoConvertweightstockptpythonconvert_diffusers_to_original_stable_diffusion.py--model_path$2--checkpoint_path$2/model.ckpt--halfechomodelsavedat$2/model.ckptBuild the Docker containerâ€‹We will rundocker buildcommand to build the container:Copydockerbuild-t<hub-user>/<repo-name>:<tag>.Before running the command replace:hub-userwith your docker hub username, If you donâ€™t have a docker hub account followthese instructionsto create a Docker account, and use the username of the account you create.repo-namewith the name of the container, you can name it anything you want.tagthis is not required but you can use the latest tagNow you can push this repository to the registry designated by its name or tag.Copydockerpush<hub-user>/<repo-name>:<tag>Create the Subject Datasetâ€‹The optimal dataset size is between 20-30 images. You can choose the images of the subject in different positions, full body images, half body, pictures of the face etc.Only the subject should appear in the image so you can crop the image to just fit the subject. Make sure that the images are 512x512 size and are named in the following pattern:CopySubject Name.jpg, Subject Name (2).jpg ... Subject Name (n).jpgYou can view theSubject Image dataset of David Aronchickfor reference.After the Subject dataset is created we upload it to IPFS.Uploading the Subject Images to IPFSâ€‹In this case, we will be usingNFT.Storage(Recommended Option) to upload files and directories withNFTUp.To upload your dataset using NFTup just drag and drop your directory it will upload it to IPFS:After the checkpoint file has been uploaded, copy its CID which will look like this:Copybafybeidqbuphwkqwgrobv2vakwsh3l6b4q2mx7xspgh4l7lhulhc3dfa7aApproaches to run a Bacalhau Job on a Finetuned Modelâ€‹Since there are a lot of combinations that you can try, processing of finetuned model can take almost 1hr+ to complete. Here are a few approaches that you can try based on your requirements:Case 1: If the subject is of class maleâ€‹Structure of the commandâ€‹bacalhau docker run: call to bacalhauThe--gpu 1flag is set to specify hardware requirements, a GPU is needed to run such a job-i ipfs://bafybeidqbuphwkqwgrobv2vakwsh3l6b4q2mx7xspgh4l7lhulhc3dfa7aMounts the data from IPFS via its CIDjsacex/dreambooth:latestName and tag of the docker image we are using-- bash finetune.sh /inputs /outputs "a photo of David Aronchick man" "a photo of man" 3000 "/man"execute script with following paramters:/inputsPath to the subject Images/outputsPath to save the generated outputs"a photo of < name of the subject > < class >"->"a photo of David Aronchick man"Subject name along with class"a photo of < class >" ->"a photo of man"Name of the classCopybacalhaudockerrun\--gpu1\--timeout3600\--wait-timeout-secs3600\--timeout3600\--wait-timeout-secs3600\-i<CID-OF-THE-SUBJECT>\jsacex/dreambooth:full\--bashfinetune.sh/inputs/outputs"a photo of <name-of-the-subject> man""a photo of man"3000"/man""/model"The number of iterations is 3000. This number should be no of subject images x 100. So if there are 30 images, it would be 3000. It takes around 32 minutes on av100for 3000 iterations, but you can increase/decrease the number based on your requirements.Here is our command with our parameters replaced:Copybacalhaudockerrun\--gpu1\--timeout3600\--wait-timeout-secs3600\--timeout3600\--wait-timeout-secs3600\-iipfs://bafybeidqbuphwkqwgrobv2vakwsh3l6b4q2mx7xspgh4l7lhulhc3dfa7a\--wait\--id-only\jsacex/dreambooth:full\--bashfinetune.sh/inputs/outputs"a photo of David Aronchick man""a photo of man"3000"/man""/model"If your subject fits the above class, but has a different name you just need to replace the input CID and the subject name.Case 2 : If the subject is of class femaleâ€‹Use the/womanclass imagesCopybacalhaudockerrun\--gpu1\--timeout3600\--wait-timeout-secs3600\-i<CID-OF-THE-SUBJECT>\jsacex/dreambooth:full\-- bash finetune.sh /inputs /outputs "a photo of <name-of-the-subject> woman" "a photo of woman" 3000 "/woman"  "/model"Case 3: If the subject is of class mixâ€‹Here you can provide your own regularization images or use the mix class.Use the/mixclass images if the class of the subject is mixCopybacalhaudockerrun\--gpu1\--timeout3600\--wait-timeout-secs3600\-i<CID-OF-THE-SUBJECT>\jsacex/dreambooth:full\--bashfinetune.sh/inputs/outputs"a photo of <name-of-the-subject> mix""a photo of mix"3000"/mix""/model"Case 4: If you want a different tokenizer, model, and a different shell script with custom parametersâ€‹You can upload the model to IPFS and then create a gist, mount the model and script to the lightweight containerCopybacalhaudockerrun\--gpu1\--timeout3600\--wait-timeout-secs3600\-iipfs://bafybeidqbuphwkqwgrobv2vakwsh3l6b4q2mx7xspgh4l7lhulhc3dfa7a:/aronchick\-iipfs://<CID-OF-THE-MODEL>:/model-i https://gist.githubusercontent.com/js-ts/54b270a36aa3c35fdc270640680b3bd4/raw/7d8e8fa47bc3811ef63772f7fc7f4360aa9d51a8/finetune.sh--wait\--id-only\jsacex/dreambooth:lite\--bash/inputs/finetune.sh/aronchick/outputs"a photo of aronchick man""a photo of man"3000"/man""/model"When a job is submitted, Bacalhau prints out the relatedjob_id. Use theexport JOB_ID=$(bacalhau docker run ...)wrapper to store that in an environment variable so that we can reuse it later on.Declarative job descriptionâ€‹The same job can be presented in thedeclarativeformat. In this case, the description will look like this. Change the command in the Parameters section and CID to suit your goals.Copyname:Stable Diffusion Dreambooth Finetuningtype:batchcount:1tasks:-name:My main taskEngine:type:dockerparams:Image:"jsacex/dreambooth:full"Parameters:-bash finetune.sh /inputs /outputs "a photo of aronchick man" "a photo of man" 3000 "/man" "/model"InputSources:-Target:"/inputs/data"Source:Type:"ipfs"Params:CID:"QmRKnvqvpFzLjEoeeNNGHtc7H8fCn9TvNWHFnbBHkK8Mhy"Resources:GPU:"1"Checking the State of your Jobsâ€‹Job statusâ€‹You can check the status of the job usingbacalhau job list.Copybacalhaujoblist--id-filter${JOB_ID}When it saysCompleted, that means the job is done, and we can get the results.Job informationâ€‹You can find out more information about your job by usingbacalhau job describe.Copybacalhaujobdescribe${JOB_ID}Job downloadâ€‹You can download your job results directly by usingbacalhau job get. Alternatively, you can choose to create a directory to store your results. In the command below, we created a directory and downloaded our job output to be stored in that directory.Copyrm-rfresults&&mkdir-presultsbacalhaujobget$JOB_ID--output-dirresultsAfter the download has finished you should see the following contents in results directoryViewing your Job Outputâ€‹Now you can find the file in theresults/outputsfolder. You can view results by running following commands:Copylsresults# list the contents of the current directoryIn the next steps, we will be doing inference on the finetuned modelInference on the Fine-Tuned Modelâ€‹Refer to ourguide on CKPT modelfor more details of how to build a SD inference containerBacalhau currently doesn't support mounting subpaths of the CID, so instead of just mounting themodel.ckptfile we need to mount the whole output CID which is 6.4GB, which might result in errors likeFAILED TO COPY /inputs. So you have to manually copy the CID of themodel.ckptwhich is of 2GB.To get the CID of themodel.ckptfile go tohttps://gateway.ipfs.io/ipfs/< YOUR-OUTPUT-CID >/outputs/. For example:Copyhttps://gateway.ipfs.io/ipfs/QmcmD7M7pYLP8QgwjqpbP4dojRLiLuEBdhevuCD9kFmbdV/outputs/If you use theBravebrowser, you can use following:Copyipfs://QmdpsqZn9BZx9XxzCsyPcJyS7yfYacmQXZxHzcuYwzmtGg/outputsOr you can use the IPFS CLI:CopyipfslsQmdpsqZn9BZx9XxzCsyPcJyS7yfYacmQXZxHzcuYwzmtGg/outputsCopy the link ofmodel.ckpthighlighted in the box:Copyhttps://gateway.ipfs.io/ipfs/QmdpsqZn9BZx9XxzCsyPcJyS7yfYacmQXZxHzcuYwzmtGg?filename=model.ckptThen extract the CID portion of the link and copy it.Run the Bacalhau Job on the Fine-Tuned Modelâ€‹To run a Bacalhau Job on the fine-tuned model, we will use thebacalhau docker runcommand.CopyexportJOB_ID=$(bacalhaudockerrun\--gpu1\--timeout3600\--wait-timeout-secs3600\--wait\--id-only\-iipfs://QmdpsqZn9BZx9XxzCsyPcJyS7yfYacmQXZxHzcuYwzmtGg\jsacex/stable-diffusion-ckpt\-- conda run --no-capture-output -n ldm python scripts/txt2img.py --prompt "a photo of aronchick drinking coffee" --plms --ckpt ../inputs/model.ckpt --skip_grid --n_samples 1 --skip_grid --outdir ../outputs)If you are facing difficulties using the above method you can mount the whole output CIDCopyexportJOB_ID=$(bacalhaudockerrun\--gpu1\--timeout3600\--wait-timeout-secs3600\--wait\--id-only\-iipfs://QmcmD7M7pYLP8QgwjqpbP4dojRLiLuEBdhevuCD9kFmbdV\jsacex/stable-diffusion-ckpt\-- conda run --no-capture-output -n ldm python scripts/txt2img.py --prompt "a photo of aronchick drinking coffee" --plms --ckpt ../inputs/outputs/model.ckpt --skip_grid --n_samples 1 --skip_grid --outdir ../outputs)When a job is sumbitted, Bacalhau prints out the relatedjob_id. We store that in an environment variable so that we can reuse it later on.To check the status of your job and download results refer back to theguide above.We got an image like this as a result:PreviousTraining Tensorflow ModelNextMolecular DynamicsLast updated1 month agoOn this pageIntroductionâ€‹TL;DRâ€‹Inferenceâ€‹Prerequisitesâ€‹Setting up Docker Containerâ€‹Downloading the modelsâ€‹Build the Docker containerâ€‹Uploading the Subject Images to IPFSâ€‹Approaches to run a Bacalhau Job on a Finetuned Modelâ€‹Case 1: If the subject is of class maleâ€‹Case 2 : If the subject is of class femaleâ€‹Case 3: If the subject is of class mixâ€‹Case 4: If you want a different tokenizer, model, and a different shell script with custom parametersâ€‹Declarative job descriptionâ€‹Checking the State of your Jobsâ€‹Job statusâ€‹Job informationâ€‹Job downloadâ€‹Viewing your Job Outputâ€‹Inference on the Fine-Tuned Modelâ€‹Run the Bacalhau Job on the Fine-Tuned Modelâ€‹Was this helpful?Edit on GitHubExport as PDFGet SupportExpansoSupportUse CasesDistributed ETLEdge MLDistributed Data WarehousingFlett ManagementAbout UsWho we areWhat we valueNews & BlogBlogNewsExpanso (2024). All Rights Reserved.