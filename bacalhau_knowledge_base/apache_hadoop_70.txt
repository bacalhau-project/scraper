Source: apache_hadoop
URL: https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/WebHDFS.html

Wiki|git|Apache Hadoop| Last Published: 2024-03-04
               | Version: 3.4.0GeneralOverviewSingle Node SetupCluster SetupCommands ReferenceFileSystem ShellCompatibility SpecificationDownstream Developer's GuideAdmin Compatibility GuideInterface ClassificationFileSystem SpecificationCommonCLI Mini ClusterFair Call QueueNative LibrariesProxy UserRack AwarenessSecure ModeService Level AuthorizationHTTP AuthenticationCredential Provider APIHadoop KMSTracingUnix Shell GuideRegistryAsync ProfilerHDFSArchitectureUser GuideCommands ReferenceNameNode HA With QJMNameNode HA With NFSObserver NameNodeFederationViewFsViewFsOverloadSchemeSnapshotsEdits ViewerImage ViewerPermissions and HDFSQuotas and HDFSlibhdfs (C API)WebHDFS (REST API)HttpFSShort Circuit Local ReadsCentralized Cache ManagementNFS GatewayRolling UpgradeExtended AttributesTransparent EncryptionMultihomingStorage PoliciesMemory Storage SupportSynthetic Load GeneratorErasure CodingDisk BalancerUpgrade DomainDataNode AdminRouter FederationProvided StorageMapReduceTutorialCommands ReferenceCompatibility with 1.xEncrypted ShufflePluggable Shuffle/SortDistributed Cache DeploySupport for YARN Shared CacheMapReduce REST APIsMR Application MasterMR History ServerYARNArchitectureCommands ReferenceCapacity SchedulerFair SchedulerResourceManager RestartResourceManager HAResource ModelNode LabelsNode AttributesWeb Application ProxyTimeline ServerTimeline Service V.2Writing YARN ApplicationsYARN Application SecurityNodeManagerRunning Applications in Docker ContainersRunning Applications in runC ContainersUsing CGroupsSecure ContainersReservation SystemGraceful DecommissionOpportunistic ContainersYARN FederationShared CacheUsing GPUUsing FPGAPlacement ConstraintsYARN UI2YARN REST APIsIntroductionResource ManagerNode ManagerTimeline ServerTimeline Service V.2YARN ServiceOverviewQuickStartConceptsYarn Service APIService DiscoverySystem ServicesHadoop Compatible File SystemsAliyun OSSAmazon S3Azure Blob StorageAzure Data Lake StorageTencent COSHuaweicloud OBSAuthOverviewExamplesConfigurationBuildingToolsHadoop StreamingHadoop ArchivesHadoop Archive LogsDistCpHDFS Federation BalanceGridMixRumenResource Estimator ServiceScheduler Load SimulatorHadoop BenchmarkingDynamometerReferenceChangelog and Release NotesJava API docsUnix Shell APIMetricsConfigurationcore-default.xmlhdfs-default.xmlhdfs-rbf-default.xmlmapred-default.xmlyarn-default.xmlkms-default.xmlhttpfs-default.xmlDeprecated PropertiesWebHDFS REST APIDocument ConventionsIntroductionOperationsFileSystem URIs vs HTTP URLsHDFS Configuration OptionsAuthenticationSSL Configurations for SWebHDFSProxy UsersCross-Site Request Forgery PreventionWebHDFS Retry PolicyWebHDFS Request FilteringFile and Directory OperationsCreate and Write to a FileAppend to a FileConcat File(s)Open and Read a FileMake a DirectoryCreate a Symbolic LinkRename a File/DirectoryDelete a File/DirectoryTruncate a FileStatus of a File/DirectoryList a DirectoryList a FileIteratively List a DirectoryOther File System OperationsGet Content Summary of a DirectoryGet Quota Usage of a DirectorySet QuotaSet Quota By Storage TypeGet File ChecksumGet Home DirectoryGet Trash RootSet PermissionSet OwnerSet Replication FactorSet Access or Modification TimeModify ACL EntriesRemove ACL EntriesRemove Default ACLRemove ACLSet ACLGet ACL StatusCheck accessGet Server DefaultsGet Link TargetGet File Link StatusGet EC PoliciesGet StatusGet EC CodecsGet Trash RootsStorage Policy OperationsGet all Storage PoliciesSet Storage PolicyUnset Storage PolicyGet Storage PolicySatisfy Storage PolicyGet File Block LocationsExtended Attributes(XAttrs) OperationsSet XAttrRemove XAttrGet an XAttrGet multiple XAttrsGet all XAttrsList all XAttrsErasure Coding OperationsEnable EC PolicyDisable EC PolicySet EC PolicyGet EC PolicyUnset EC PolicySnapshot OperationsAllow SnapshotDisallow SnapshotCreate SnapshotDelete SnapshotRename SnapshotGet Snapshot DiffGet Snapshot Diff IterativelyGet Snapshottable Directory ListGet Snapshot ListDelegation Token OperationsGet Delegation TokenRenew Delegation TokenCancel Delegation TokenError ResponsesHTTP Response CodesIllegal Argument ExceptionSecurity ExceptionAccess Control ExceptionFile Not Found ExceptionJSON SchemasACL Status JSON SchemaXAttrs JSON SchemaXAttrNames JSON SchemaBoolean JSON SchemaContentSummary JSON SchemaQuotaUsage JSON SchemaFileChecksum JSON SchemaFileStatus JSON SchemaFileStatus PropertiesFileStatuses JSON SchemaDirectoryListing JSON SchemaLong JSON SchemaPath JSON SchemaRemoteException JSON SchemaToken JSON SchemaToken PropertiesBlockStoragePolicy JSON SchemaBlockStoragePolicy PropertiesECPolicy JSON SchemaBlockStoragePolicies JSON SchemaSnapshotDiffReport JSON SchemaDiffReport EntriesSnapshotDiffReportListing JSON SchemaDiffReportListing EntriesSnapshottableDirectoryList JSON SchemaSnapshottableDirectoryStatusSnapshotList JSON SchemaSnapshotStatusBlockLocations JSON SchemaBlockLocation JSON SchemaBlockLocation PropertiesServer Defaults JSON SchemaFsStatus JSON SchemaEC Policies JSON SchemaEC Codecs JSON SchemaPaths JSON SchemaHTTP Query Parameter DictionaryACL SpecXAttr NameXAttr ValueXAttr set flagXAttr value encodingAccess TimeBlock SizeBuffer SizeCreate FlagCreate ParentDelegationDestinationDo AsFs ActionGroupLengthModification TimeNew LengthOffsetOld Snapshot NameOpOverwriteOwnerPermissionRecursiveRenewerReplicationSnapshot NameSourcesTokenToken KindToken ServiceUsernameNoRedirectNamespace QuotaStorage Space QuotaStorage TypeStorage PolicyErasure Coding PolicyStart AfterDocument ConventionsMonospacedUsed for commands, HTTP request and responses and code blocks.<Monospaced>User entered values.[Monospaced]Optional values. When the value is not specified, the default value is used.ItalicsImportant phrases and words.IntroductionThe HTTP REST API supports the completeFileSystem/FileContextinterface for HDFS. The operations and the corresponding FileSystem/FileContext methods are shown in the next section. The SectionHTTP Query Parameter Dictionaryspecifies the parameter details such as the defaults and the valid values.OperationsHTTP GETOPEN(seeFileSystem.open)GETFILESTATUS(seeFileSystem.getFileStatus)LISTSTATUS(seeFileSystem.listStatus)LISTSTATUS_BATCH(seeFileSystem.listStatusIterator)GETCONTENTSUMMARY(seeFileSystem.getContentSummary)GETQUOTAUSAGE(seeFileSystem.getQuotaUsage)GETFILECHECKSUM(seeFileSystem.getFileChecksum)GETHOMEDIRECTORY(seeFileSystem.getHomeDirectory)GETDELEGATIONTOKEN(seeFileSystem.getDelegationToken)GETTRASHROOT(seeFileSystem.getTrashRoot)GETXATTRS(seeFileSystem.getXAttr)GETXATTRS(seeFileSystem.getXAttrs)GETXATTRS(seeFileSystem.getXAttrs)LISTXATTRS(seeFileSystem.listXAttrs)CHECKACCESS(seeFileSystem.access)GETALLSTORAGEPOLICY(seeFileSystem.getAllStoragePolicies)GETSTORAGEPOLICY(seeFileSystem.getStoragePolicy)GETSNAPSHOTDIFFGETSNAPSHOTDIFFLISTINGGETSNAPSHOTTABLEDIRECTORYLISTGETSNAPSHOTLISTGETFILEBLOCKLOCATIONS(seeFileSystem.getFileBlockLocations)GETECPOLICY(seeHDFSErasureCoding.getErasureCodingPolicy)GETSERVERDEFAULTS(seeFileSystem.getServerDefaults)GETLINKTARGET(seeFileSystem.getLinkTarget)GETFILELINKSTATUS(seeFileSystem.getFileLinkStatus)GETSTATUS(seeFileSystem.getStatus)GETECPOLICIESGETECCODECSGETTRASHROOTS(seeFileSystem.getTrashRoots)HTTP PUTCREATE(seeFileSystem.create)MKDIRS(seeFileSystem.mkdirs)CREATESYMLINK(seeFileContext.createSymlink)RENAME(seeFileSystem.rename)SETREPLICATION(seeFileSystem.setReplication)SETOWNER(seeFileSystem.setOwner)SETPERMISSION(seeFileSystem.setPermission)SETTIMES(seeFileSystem.setTimes)RENEWDELEGATIONTOKEN(seeDelegationTokenAuthenticator.renewDelegationToken)CANCELDELEGATIONTOKEN(seeDelegationTokenAuthenticator.cancelDelegationToken)ALLOWSNAPSHOTDISALLOWSNAPSHOTCREATESNAPSHOT(seeFileSystem.createSnapshot)RENAMESNAPSHOT(seeFileSystem.renameSnapshot)SETXATTR(seeFileSystem.setXAttr)REMOVEXATTR(seeFileSystem.removeXAttr)SETSTORAGEPOLICY(seeFileSystem.setStoragePolicy)SATISFYSTORAGEPOLICY(seeArchivalStorage.satisfyStoragePolicy)ENABLEECPOLICY(seeHDFSErasureCoding.enablePolicy)DISABLEECPOLICY(seeHDFSErasureCoding.disablePolicy)SETECPOLICY(seeHDFSErasureCoding.setErasureCodingPolicy)HTTP POSTAPPEND(seeFileSystem.append)CONCAT(seeFileSystem.concat)TRUNCATE(seeFileSystem.truncate)UNSETSTORAGEPOLICY(seeFileSystem.unsetStoragePolicy)UNSETECPOLICY(seeHDFSErasureCoding.unsetErasureCodingPolicy)HTTP DELETEDELETE(seeFileSystem.delete)DELETESNAPSHOT(seeFileSystem.deleteSnapshot)FileSystem URIs vs HTTP URLsThe FileSystem scheme of WebHDFS is “webhdfs://”. A WebHDFS FileSystem URI has the following format.webhdfs://<HOST>:<HTTP_PORT>/<PATH>The above WebHDFS URI corresponds to the below HDFS URI.hdfs://<HOST>:<RPC_PORT>/<PATH>In the REST API, the prefix “/webhdfs/v1” is inserted in the path and a query is appended at the end. Therefore, the corresponding HTTP URL has the following format.http://<HOST>:<HTTP_PORT>/webhdfs/v1/<PATH>?op=...Notethat if WebHDFS is secured with SSL, then the scheme should be “swebhdfs://”.swebhdfs://<HOST>:<HTTP_PORT>/<PATH>See also:SSL Configurations for SWebHDFSHDFS Configuration OptionsBelow are the HDFS configuration options for WebHDFS.Property NameDescriptiondfs.web.authentication.kerberos.principalThe HTTP Kerberos principal used by Hadoop-Auth in the HTTP endpoint. The HTTP Kerberos principal MUST start with ‘HTTP/’ per Kerberos HTTP SPNEGO specification. A value of “*” will use all HTTP principals found in the keytab.dfs.web.authentication.kerberos.keytabThe Kerberos keytab file with the credentials for the HTTP Kerberos principal used by Hadoop-Auth in the HTTP endpoint.dfs.webhdfs.socket.connect-timeoutHow long to wait for a connection to be established before failing.  Specified as a time duration, ie numerical value followed by a units symbol, eg 2m for two minutes. Defaults to 60s.dfs.webhdfs.socket.read-timeoutHow long to wait for data to arrive before failing.  Defaults to 60s.AuthenticationWhen security isoff, the authenticated user is the username specified in theuser.namequery parameter. If theuser.nameparameter is not set, the server may either set the authenticated user to a default web user, if there is any, or return an error response.When security ison, authentication is performed by either Hadoop delegation token or Kerberos SPNEGO. If a token is set in thedelegationquery parameter, the authenticated user is the user encoded in the token. If thedelegationparameter is not set, the user is authenticated by Kerberos SPNEGO.Below are examples using thecurlcommand tool.Authentication when security is off:curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?[user.name=<USER>&]op=..."Authentication using Kerberos SPNEGO when security is on:curl -i --negotiate -u : "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=..."Authentication using Hadoop delegation token when security is on:curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?delegation=<TOKEN>&op=..."See also:Authentication for Hadoop HTTP web-consolesAdditionally, WebHDFS supports OAuth2 on the client side. The Namenode and Datanodes do not currently support clients using OAuth2 but other backends that implement the WebHDFS REST interface may.WebHDFS supports two type of OAuth2 code grants (user-provided refresh and access token or user provided credential) by default and provides a pluggable mechanism for implementing other OAuth2 authentications per theOAuth2 RFC, or custom authentications.  When using either of the provided code grant mechanisms, the WebHDFS client will refresh the access token as necessary.OAuth2 should only be enabled for clients not running with Kerberos SPENGO.OAuth2 code grant mechanismDescriptionValue ofdfs.webhdfs.oauth2.access.token.providerthat implements code grantAuthorization Code GrantThe user provides an initial access token and refresh token, which are then used to authenticate WebHDFS requests and obtain replacement access tokens, respectively.org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProviderClient Credentials GrantThe user provides a credential which is used to obtain access tokens, which are then used to authenticate WebHDFS requests.org.apache.hadoop.hdfs.web.oauth2.ConfCredentialBasedAccessTokenProviderThe following properties control OAuth2 authentication.OAuth2 related propertyDescriptiondfs.webhdfs.oauth2.enabledBoolean to enable/disable OAuth2 authenticationdfs.webhdfs.oauth2.access.token.providerClass name of an implementation oforg.apache.hadoop.hdfs.web.oauth.AccessTokenProvider.Two are provided with the code, as described above, or the user may specify a user-provided implementation. The default value for this configuration key is theConfCredentialBasedAccessTokenProviderimplementation.dfs.webhdfs.oauth2.client.idClient id used to obtain access token with either credential or refresh tokendfs.webhdfs.oauth2.refresh.urlURL against which to post for obtaining bearer token with either credential or refresh tokendfs.webhdfs.oauth2.access.token(required if using ConfRefreshTokenBasedAccessTokenProvider) Initial access token with which to authenticatedfs.webhdfs.oauth2.refresh.token(required if using ConfRefreshTokenBasedAccessTokenProvider) Initial refresh token to use to obtain new access tokensdfs.webhdfs.oauth2.refresh.token.expires.ms.since.epoch(required if using ConfRefreshTokenBasedAccessTokenProvider) Access token expiration measured in milliseconds since Jan 1, 1970.Note this is a different value than provided by OAuth providers and has been munged as described in interface to be suitable for a client applicationdfs.webhdfs.oauth2.credential(required if using ConfCredentialBasedAccessTokenProvider).  Credential used to obtain initial and subsequent access tokens.SSL Configurations for SWebHDFSTo use SWebHDFS FileSystem (i.e. using the swebhdfs protocol), a SSL configuration file needs to be specified on the client side. This must specify 3 parameters:SSL propertyDescriptionssl.client.truststore.locationThe local-filesystem location of the trust-store file, containing the certificate for the NameNode.ssl.client.truststore.type(Optional) The format of the trust-store file.ssl.client.truststore.password(Optional) Password for the trust-store file.The following is an example SSL configuration file (ssl-client.xml):<configuration>
  <property>
    <name>ssl.client.truststore.location</name>
    <value>/work/keystore.jks</value>
    <description>Truststore to be used by clients. Must be specified.</description>
  </property>

  <property>
    <name>ssl.client.truststore.password</name>
    <value>changeme</value>
    <description>Optional. Default value is "".</description>
  </property>

  <property>
    <name>ssl.client.truststore.type</name>
    <value>jks</value>
    <description>Optional. Default value is "jks".</description>
  </property>
</configuration>The SSL configuration file must be in the class-path of the client program and the filename needs to be specified incore-site.xml:<property>
  <name>hadoop.ssl.client.conf</name>
  <value>ssl-client.xml</value>
  <description>
    Resource file from which ssl client keystore information will be extracted.
    This file is looked up in the classpath, typically it should be in Hadoop
    conf/ directory. Default value is "ssl-client.xml".
  </description>
</property>Proxy UsersWhen the proxy user feature is enabled, a proxy userPmay submit a request on behalf of another userU. The username ofUmust be specified in thedoasquery parameter unless a delegation token is presented in authentication. In such case, the information of both usersPandUmust be encoded in the delegation token.A proxy request when security is off:curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?[user.name=<USER>&]doas=<USER>&op=..."A proxy request using Kerberos SPNEGO when security is on:curl -i --negotiate -u : "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?doas=<USER>&op=..."A proxy request using Hadoop delegation token when security is on:curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?delegation=<TOKEN>&op=..."Cross-Site Request Forgery PreventionWebHDFS supports an optional, configurable mechanism for cross-site request forgery (CSRF) prevention.  When enabled, WebHDFS HTTP requests to the NameNode or DataNode must include a custom HTTP header.  Configuration properties allow adjusting which specific HTTP methods are protected and the name of the HTTP header.  The value sent in the header is not relevant.  Only the presence of a header by that name is required.Enabling CSRF prevention also sets up theWebHdfsFileSystemclass to send the required header.  This ensures that CLI commands likehdfs dfsandhadoop distcpcontinue to work correctly when used withwebhdfs:URIs.Enabling CSRF prevention also sets up the NameNode web UI to send the required header.  After enabling CSRF prevention and restarting the NameNode, existing users of the NameNode web UI need to refresh the browser to reload the page and find the new configuration.The following properties control CSRF prevention.PropertyDescriptionDefault Valuedfs.webhdfs.rest-csrf.enabledIf true, then enables WebHDFS protection against cross-site request forgery (CSRF).  The WebHDFS client also uses this property to determine whether or not it needs to send the custom CSRF prevention header in its HTTP requests.falsedfs.webhdfs.rest-csrf.custom-headerThe name of a custom header that HTTP requests must send when protection against cross-site request forgery (CSRF) is enabled for WebHDFS by setting dfs.webhdfs.rest-csrf.enabled to true.  The WebHDFS client also uses this property to determine whether or not it needs to send the custom CSRF prevention header in its HTTP requests.X-XSRF-HEADERdfs.webhdfs.rest-csrf.methods-to-ignoreA comma-separated list of HTTP methods that do not require HTTP requests to include a custom header when protection against cross-site request forgery (CSRF) is enabled for WebHDFS by setting dfs.webhdfs.rest-csrf.enabled to true.  The WebHDFS client also uses this property to determine whether or not it needs to send the custom CSRF prevention header in its HTTP requests.GET,OPTIONS,HEAD,TRACEdfs.webhdfs.rest-csrf.browser-useragents-regexA comma-separated list of regular expressions used to match against an HTTP request’s User-Agent header when protection against cross-site request forgery (CSRF) is enabled for WebHDFS by setting dfs.webhdfs.reset-csrf.enabled to true.  If the incoming User-Agent matches any of these regular expressions, then the request is considered to be sent by a browser, and therefore CSRF prevention is enforced.  If the request’s User-Agent does not match any of these regular expressions, then the request is considered to be sent by something other than a browser, such as scripted automation.  In this case, CSRF is not a potential attack vector, so the prevention is not enforced.  This helps achieve backwards-compatibility with existing automation that has not been updated to send the CSRF prevention header.^Mozilla.*,^Opera.*dfs.datanode.httpserver.filter.handlersComma separated list of Netty servlet-style filter handlers to inject into the Datanode WebHDFS I/O pathorg.apache.hadoop.hdfs.server.datanode.web.RestCsrfPreventionFilterHandlerThe following is an examplecurlcall that uses the-Hoption to include the custom header in the request.curl -i -L -X PUT -H 'X-XSRF-HEADER: ""' 'http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=CREATE'WebHDFS Retry PolicyWebHDFS supports an optional, configurable retry policy for resilient copy of large files that could timeout, or copy file between HA clusters that could failover during the copy.The following properties control WebHDFS retry and failover policy.PropertyDescriptionDefault Valuedfs.http.client.retry.policy.enabledIf “true”, enable the retry policy of WebHDFS client. If “false”, retry policy is turned off.falsedfs.http.client.retry.policy.specSpecify a policy of multiple linear random retry for WebHDFS client, e.g. given pairs of number of retries and sleep time (n0, t0), (n1, t1), …, the first n0 retries sleep t0 milliseconds on average, the following n1 retries sleep t1 milliseconds on average, and so on.10000,6,60000,10dfs.http.client.failover.max.attemptsSpecify the max number of failover attempts for WebHDFS client in case of network exception.15dfs.http.client.retry.max.attemptsSpecify the max number of retry attempts for WebHDFS client, if the difference between retried attempts and failovered attempts is larger than the max number of retry attempts, there will be no more retries.10dfs.http.client.failover.sleep.base.millisSpecify the base amount of time in milliseconds upon which the exponentially increased sleep time between retries or failovers is calculated for WebHDFS client.500dfs.http.client.failover.sleep.max.millisSpecify the upper bound of sleep time in milliseconds between retries or failovers for WebHDFS client.15000WebHDFS Request FilteringOne may control directionality of data in the WebHDFS protocol allowing only writing data from insecure networks. To enable, one must ensuredfs.datanode.httpserver.filter.handlersincludesorg.apache.hadoop.hdfs.server.datanode.web.HostRestrictingAuthorizationFilterHandler.  Configuration of theHostRestrictingAuthorizationFilteris controlled via the following properties.PropertyDescriptionDefault Valuedfs.datanode.httpserver.filter.handlersComma separated list of Netty servlet-style filter handlers to inject into the Datanode WebHDFS I/O pathorg.apache.hadoop.hdfs.server.datanode.web.RestCsrfPreventionFilterHandlerdfs.web.authentication.host.allow.rulesRules allowing users to read files in the format ofuser,network/bits,path globnewline or|-separated. Use*for a wildcard of allusersornetwork/bits.nothing - defaults to no one may read via WebHDFSFile and Directory OperationsCreate and Write to a FileStep 1: Submit a HTTP PUT request without automatically following redirects and without sending the file data.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=CREATE
                    [&overwrite=<true |false>][&blocksize=<LONG>][&replication=<SHORT>]
                    [&permission=<OCTAL>][&buffersize=<INT>][&noredirect=<true|false>]"Usually the request is redirected to a datanode where the file data is to be written.HTTP/1.1 307 TEMPORARY_REDIRECT
Location: http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=CREATE...
Content-Length: 0However, if you do not want to be automatically redirected, you can set the noredirect flag.HTTP/1.1 200 OK
Content-Type: application/json
{"Location":"http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=CREATE..."}Step 2: Submit another HTTP PUT request using the URL in theLocationheader (or the returned response in case you specified noredirect) with the file data to be written.curl -i -X PUT -T <LOCAL_FILE> "http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=CREATE..."The client receives a201 Createdresponse with zero content length and the WebHDFS URI of the file in theLocationheader:HTTP/1.1 201 Created
Location: webhdfs://<HOST>:<PORT>/<PATH>
Content-Length: 0If no permissions are specified, the newly created file will be assigned with default 644 permission. No umask mode will be applied from server side (so “fs.permissions.umask-mode” value configuration set on Namenode side will have no effect).Notethat the reason of having two-step create/append is for preventing clients to send out data before the redirect. This issue is addressed by the “Expect: 100-continue” header in HTTP/1.1; seeRFC 2616, Section 8.2.3. Unfortunately, there are software library bugs (e.g. Jetty 6 HTTP server and Java 6 HTTP client), which do not correctly implement “Expect: 100-continue”. The two-step create/append is a temporary workaround for the software library bugs.See also:overwrite,blocksize,replication,permission,buffersize,FileSystem.createAppend to a FileStep 1: Submit a HTTP POST request without automatically following redirects and without sending the file data.curl -i -X POST "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=APPEND[&buffersize=<INT>][&noredirect=<true|false>]"Usually the request is redirected to a datanode where the file data is to be appended:HTTP/1.1 307 TEMPORARY_REDIRECT
Location: http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=APPEND...
Content-Length: 0However, if you do not want to be automatically redirected, you can set the noredirect flag.HTTP/1.1 200 OK
    Content-Type: application/json
    {"Location":"http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=APPEND..."}Step 2: Submit another HTTP POST request using the URL in theLocationheader (or the returned response in case you specified noredirect) with the file data to be appended.curl -i -X POST -T <LOCAL_FILE> "http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=APPEND..."The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See the note in the previous section for the description of why this operation requires two steps.See also:buffersize,FileSystem.appendConcat File(s)Submit a HTTP POST request.curl -i -X POST "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=CONCAT&sources=<PATHS>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:sources,FileSystem.concatOpen and Read a FileSubmit a HTTP GET request with automatically following redirects.curl -i -L "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=OPEN
                    [&offset=<LONG>][&length=<LONG>][&buffersize=<INT>][&noredirect=<true|false>]"Usually the request is redirected to a datanode where the file data can be read:HTTP/1.1 307 TEMPORARY_REDIRECT
Location: http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=OPEN...
Content-Length: 0However if you do not want to be automatically redirected, you can set the noredirect flag.HTTP/1.1 200 OK
Content-Type: application/json
{"Location":"http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=OPEN..."}The client follows the redirect to the datanode and receives the file data:HTTP/1.1 200 OK
Content-Type: application/octet-stream
Content-Length: 22

Hello, webhdfs user!See also:offset,length,buffersize,FileSystem.openMake a DirectorySubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=MKDIRS[&permission=<OCTAL>]"The client receives a response with abooleanJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"boolean": true}If no permissions are specified, the newly created directory will have 755 permission as default. No umask mode will be applied from server side (so “fs.permissions.umask-mode” value configuration set on Namenode side will have no effect).See also:permission,FileSystem.mkdirsCreate a Symbolic LinkSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=CREATESYMLINK
                              &destination=<PATH>[&createParent=<true |false>]"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:destination,createParent,FileSystem.createSymlinkRename a File/DirectorySubmit a HTTP PUT request.curl -i -X PUT "<HOST>:<PORT>/webhdfs/v1/<PATH>?op=RENAME&destination=<PATH>"The client receives a response with abooleanJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"boolean": true}See also:destination,FileSystem.renameDelete a File/DirectorySubmit a HTTP DELETE request.curl -i -X DELETE "http://<host>:<port>/webhdfs/v1/<path>?op=DELETE
                              [&recursive=<true |false>]"The client receives a response with abooleanJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"boolean": true}See also:recursive,FileSystem.deleteTruncate a FileSubmit a HTTP POST request.curl -i -X POST "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=TRUNCATE&newlength=<LONG>"The client receives a response with abooleanJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"boolean": true}See also:newlength,FileSystem.truncateStatus of a File/DirectorySubmit a HTTP GET request.curl -i  "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETFILESTATUS"The client receives a response with aFileStatusJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
  "FileStatus":
  {
    "accessTime"      : 0,
    "blockSize"       : 0,
    "group"           : "supergroup",
    "length"          : 0,             //in bytes, zero for directories
    "modificationTime": 1320173277227,
    "owner"           : "webuser",
    "pathSuffix"      : "",
    "permission"      : "777",
    "replication"     : 0,
    "snapshotEnabled" : true
    "type"            : "DIRECTORY"    //enum {FILE, DIRECTORY, SYMLINK}
    "ecPolicy"        : "RS-6-3-1024k"
  }
}See also:FileSystem.getFileStatusList a DirectorySubmit a HTTP GET request.curl -i  "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=LISTSTATUS"The client receives a response with aFileStatusesJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 427

{
  "FileStatuses":
  {
    "FileStatus":
    [
      {
        "accessTime"      : 1320171722771,
        "blockSize"       : 33554432,
        "childrenNum"     : 0,
        "fileId"          : 16388,
        "group"           : "supergroup",
        "length"          : 24930,
        "modificationTime": 1320171722771,
        "owner"           : "webuser",
        "pathSuffix"      : "a.patch",
        "permission"      : "644",
        "replication"     : 1,
        "storagePolicy"   : 0,
        "type"            : "FILE"
      },
      {
        "accessTime"      : 0,
        "blockSize"       : 0,
        "childrenNum"     : 0,
        "fileId"          : 16389,
        "group"           : "supergroup",
        "length"          : 0,
        "modificationTime": 1320895981256,
        "owner"           : "username",
        "pathSuffix"      : "bar",
        "permission"      : "711",
        "replication"     : 0,
        "snapshotEnabled" : true
        "type"            : "DIRECTORY"
      },
      ...
    ]
  }
}See also:FileSystem.listStatusList a FileSubmit a HTTP GET request.curl -i  "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=LISTSTATUS"The client receives a response with aFileStatusesJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 427

{
  "FileStatuses":
  {
    "FileStatus":
    [
      {
        "accessTime"      : 1320171722771,
        "blockSize"       : 33554432,
        "childrenNum"     : 0,
        "fileId"          : 16390,
        "group"           : "supergroup",
        "length"          : 1366,
        "modificationTime": 1501770633062,
        "owner"           : "webuser",
        "pathSuffix"      : "",
        "permission"      : "644",
        "replication"     : 1,
        "storagePolicy"   : 0,
        "type"            : "FILE"
      }
    ]
  }
}See also:FileSystem.listStatusIteratively List a DirectorySubmit a HTTP GET request.curl -i  "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=LISTSTATUS_BATCH&startAfter=<CHILD>"The client receives a response with aDirectoryListingJSON object, which contains aFileStatusesJSON object, as well as iteration information:HTTP/1.1 200 OK
Cache-Control: no-cache
Expires: Thu, 08 Sep 2016 03:40:38 GMT
Date: Thu, 08 Sep 2016 03:40:38 GMT
Pragma: no-cache
Expires: Thu, 08 Sep 2016 03:40:38 GMT
Date: Thu, 08 Sep 2016 03:40:38 GMT
Pragma: no-cache
Content-Type: application/json
X-FRAME-OPTIONS: SAMEORIGIN
Transfer-Encoding: chunked
Server: Jetty(6.1.26)

{
    "DirectoryListing": {
        "partialListing": {
            "FileStatuses": {
                "FileStatus": [
                    {
                        "accessTime": 0,
                        "blockSize": 0,
                        "childrenNum": 0,
                        "fileId": 16387,
                        "group": "supergroup",
                        "length": 0,
                        "modificationTime": 1473305882563,
                        "owner": "andrew",
                        "pathSuffix": "bardir",
                        "permission": "755",
                        "replication": 0,
                        "storagePolicy": 0,
                        "type": "DIRECTORY"
                    },
                    {
                        "accessTime": 1473305896945,
                        "blockSize": 1024,
                        "childrenNum": 0,
                        "fileId": 16388,
                        "group": "supergroup",
                        "length": 0,
                        "modificationTime": 1473305896965,
                        "owner": "andrew",
                        "pathSuffix": "bazfile",
                        "permission": "644",
                        "replication": 3,
                        "storagePolicy": 0,
                        "type": "FILE"
                    }
                ]
            }
        },
        "remainingEntries": 2
    }
}IfremainingEntriesis non-zero, there are additional entries in the directory. To query the next batch, set thestartAfterparameter to thepathSuffixof the last item returned in the current batch. For example:curl -i  "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=LISTSTATUS_BATCH&startAfter=bazfile"Which will return the next batch of directory entries:HTTP/1.1 200 OK
    Cache-Control: no-cache
    Expires: Thu, 08 Sep 2016 03:43:20 GMT
    Date: Thu, 08 Sep 2016 03:43:20 GMT
    Pragma: no-cache
    Expires: Thu, 08 Sep 2016 03:43:20 GMT
    Date: Thu, 08 Sep 2016 03:43:20 GMT
    Pragma: no-cache
    Content-Type: application/json
    X-FRAME-OPTIONS: SAMEORIGIN
    Transfer-Encoding: chunked
    Server: Jetty(6.1.26)

    {
        "DirectoryListing": {
            "partialListing": {
                "FileStatuses": {
                    "FileStatus": [
                        {
                            "accessTime": 0,
                            "blockSize": 0,
                            "childrenNum": 0,
                            "fileId": 16386,
                            "group": "supergroup",
                            "length": 0,
                            "modificationTime": 1473305878951,
                            "owner": "andrew",
                            "pathSuffix": "foodir",
                            "permission": "755",
                            "replication": 0,
                            "storagePolicy": 0,
                            "type": "DIRECTORY"
                        },
                        {
                            "accessTime": 1473305902864,
                            "blockSize": 1024,
                            "childrenNum": 0,
                            "fileId": 16389,
                            "group": "supergroup",
                            "length": 0,
                            "modificationTime": 1473305902878,
                            "owner": "andrew",
                            "pathSuffix": "quxfile",
                            "permission": "644",
                            "replication": 3,
                            "storagePolicy": 0,
                            "type": "FILE"
                        }
                    ]
                }
            },
            "remainingEntries": 0
        }
    }Batch size is controlled by thedfs.ls.limitoption on the NameNode.See also:FileSystem.listStatusIteratorOther File System OperationsGet Content Summary of a DirectorySubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETCONTENTSUMMARY"The client receives a response with aContentSummaryJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
  "ContentSummary":
  {
    "directoryCount": 2,
    "ecPolicy"      : "RS-6-3-1024k",
    "fileCount"     : 1,
    "length"        : 24930,
    "quota"         : -1,
    "spaceConsumed" : 24930,
    "spaceQuota"    : -1,
    "typeQuota":
    {
      "ARCHIVE":
      {
        "consumed": 500,
        "quota": 10000
      },
      "DISK":
      {
        "consumed": 500,
        "quota": 10000
      },
      "SSD":
      {
        "consumed": 500,
        "quota": 10000
      }
    }
  }
}See also:FileSystem.getContentSummaryGet Quota Usage of a DirectorySubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETQUOTAUSAGE"The client receives a response with aQuotaUsageJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
  "QuotaUsage":
  {
    "fileAndDirectoryCount": 1,
    "quota"         : 100,
    "spaceConsumed" : 24930,
    "spaceQuota"    : 100000,
    "typeQuota":
    {
      "ARCHIVE":
      {
        "consumed": 500,
        "quota": 10000
      },
      "DISK":
      {
        "consumed": 500,
        "quota": 10000
      },
      "SSD":
      {
        "consumed": 500,
        "quota": 10000
      }
    }
  }
}See also:FileSystem.getQuotaUsageSet QuotaSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETQUOTA
                              &namespacequota=<QUOTA>[&storagespacequota=<QUOTA>]"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.setQuotaSet Quota By Storage TypeSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETQUOTABYSTORAGETYPE
                              &storagetype=<STORAGETYPE>&storagespacequota=<QUOTA>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.setQuotaByStorageTypeGet File ChecksumSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETFILECHECKSUM"Usually the request is redirected to a datanode:HTTP/1.1 307 TEMPORARY_REDIRECT
Location: http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=GETFILECHECKSUM...
Content-Length: 0However, if you do not want to be automatically redirected, you can set the noredirect flag.HTTP/1.1 200 OK
Content-Type: application/json
{"Location":"http://<DATANODE>:<PORT>/webhdfs/v1/<PATH>?op=GETFILECHECKSUM..."}The client follows the redirect to the datanode and receives aFileChecksumJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
  "FileChecksum":
  {
    "algorithm": "MD5-of-1MD5-of-512CRC32",
    "bytes"    : "eadb10de24aa315748930df6e185c0d ...",
    "length"   : 28
  }
}See also:FileSystem.getFileChecksumGet Home DirectorySubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/?op=GETHOMEDIRECTORY"The client receives a response with aPathJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"Path": "/user/username"}See also:FileSystem.getHomeDirectoryGet Trash RootSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETTRASHROOT"The client receives a response with aPathJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"Path": "/user/username/.Trash"}if the path is an encrypted zone path and user has permission of the path, the client receives a response like this:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"Path": "/PATH/.Trash/username"}See also:FileSystem.getTrashRootFor more details about trash root in an encrypted zone, please refer toTransparent Encryption Guide.Set PermissionSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETPERMISSION
                              [&permission=<OCTAL>]"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:permission,FileSystem.setPermissionSet OwnerSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETOWNER
                              [&owner=<USER>][&group=<GROUP>]"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:owner,group,FileSystem.setOwnerSet Replication FactorSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETREPLICATION
                              [&replication=<SHORT>]"The client receives a response with abooleanJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"boolean": true}See also:replication,FileSystem.setReplicationSet Access or Modification TimeSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETTIMES
                              [&modificationtime=<TIME>][&accesstime=<TIME>]"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:modificationtime,accesstime,FileSystem.setTimesModify ACL EntriesSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=MODIFYACLENTRIES
                              &aclspec=<ACLSPEC>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.modifyAclEntriesRemove ACL EntriesSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=REMOVEACLENTRIES
                              &aclspec=<ACLSPEC>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.removeAclEntriesRemove Default ACLSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=REMOVEDEFAULTACL"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.removeDefaultAclRemove ACLSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=REMOVEACL"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.removeAclSet ACLSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETACL
                              &aclspec=<ACLSPEC>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.setAclGet ACL StatusSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETACLSTATUS"The client receives a response with aAclStatusJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
    "AclStatus": {
        "entries": [
            "user:carla:rw-", 
            "group::r-x"
        ], 
        "group": "supergroup", 
        "owner": "hadoop", 
        "permission":"775",
        "stickyBit": false
    }
}See also:FileSystem.getAclStatusCheck accessSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=CHECKACCESS
                              &fsaction=<FSACTION>The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.accessGet Server DefaultsSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETSERVERDEFAULTS"The client receives a response with aServerDefaultsJSON object:HTTP/1.1 200 OK
    Content-Type: application/json
    Transfer-Encoding: chunked

    {
        "FsServerDefaults": {
            "replication": 3,
            "encryptDataTransfer": "false",
            "defaultStoragePolicyId":7,
            "writePacketSize": 65536,
            "fileBufferSize": 4096,
            "checksumType": 2,
            "trashInterval": 10080,
            "keyProviderUri": "",
            "blockSize": 134217728,
            "bytesPerChecksum": 512
        }
    }See also:FileSystem.getServerDefaultsGet Link TargetSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETLINKTARGET"The client receives a response with aPathJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"Path": "/user/username/targetFile"}See also:FileSystem.getLinkTargetGet File Link StatusSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETFILELINKSTATUS"The client receives a response with aFileStatusJSON object:HTTP/1.1 200 OK
    Content-Type: application/json
    Transfer-Encoding: chunked

    {
        "FileStatus": {
            "accessTime": 0,
            "blockSize": 0,
            "childrenNum":0,
            "fileId": 16388,
            "group": "supergroup",
            "length": 0,
            "modificationTime": 1681916788427,
            "owner": "hadoop",
            "pathSuffix": "",
            "permission": "777",
            "replication": 0,
            "storagePolicy": 0,
            "symlink": "/webHdfsTest/file",
            "type": "SYMLINK"
        }
    }See also:FileSystem.getFileLinkInfoGet EC PoliciesSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETECPOLICIES"The client receives a response with aECPoliciesJSON object:HTTP/1.1 200 OK
    Content-Type: application/json
    Transfer-Encoding: chunked

    {
      "ErasureCodingPolicies": {
        "ErasureCodingPolicyInfo": [
          {
            "state": "ENABLED",
            "policy": {
              "name": "RS-6-3-1024k",
              "schema": {
                "codecName": "rs",
                "numDataUnits": 6,
                "numParityUnits": 3,
                "extraOptions": {}
              },
              "cellSize": 1048576,
              "id": 1,
              "replicationPolicy": false,
              "codecName": "rs",
              "numDataUnits": 6,
              "numParityUnits": 3,
              "systemPolicy": true
            }
          }
        ]
      }
    }Get StatusSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETSTATUS"The client receives a response with aFsStatusJSON object:HTTP/1.1 200 OK
    Content-Type: application/json
    Transfer-Encoding: chunked

    {
        "FsStatus": {
            "used": 29229154304,
            "remaining": 292893392896,
            "capacity":322122547200
        }
    }See also:FileSystem.getStatusGet EC CodecsSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETALLECCODECS"The client receives a response with aECCodecsJSON object:HTTP/1.1 200 OK
    Content-Type: application/json
    Transfer-Encoding: chunked

    {
        "ErasureCodeCodecs": {
            "rs": "rs_native, rs_java",
            "rs-legacy": "rs-legacy_java",
            "xor":"xor_native, xor_java"
        }
    }Get Trash RootsSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETTRASHROOTS
                              &allusers=<true|false>"The client receives a response with aPathsJSON object:HTTP/1.1 200 OK
    Content-Type: application/json
    Transfer-Encoding: chunked

    {
        "Paths": [{
            "blocksize": 0,
            "owner": "hadoop",
            "path": "/user/user0/.Trash",
            "length": 0,
            "permission": "755",
            "modification_time": 1693050205747,
            "isdir": true,
            "block_replication": 0,
            "access_time": 0,
            "group": "supergroup"
         }, {
            "blocksize": 0,
            "owner": "hadoop",
            "path": "/user/user1/.Trash",
            "length": 0,
            "permission": "755",
            "modification_time": 1693049382962,
            "isdir": true,
            "block_replication": 0,
            "access_time": 0,
            "group": "supergroup"
         }]
    }See also:FileSystem.getTrashRootsStorage Policy OperationsGet all Storage PoliciesSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1?op=GETALLSTORAGEPOLICY"The client receives a response with aBlockStoragePoliciesJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
    "BlockStoragePolicies": {
        "BlockStoragePolicy": [
           {
               "copyOnCreateFile": false,
               "creationFallbacks": [],
               "id": 2,
               "name": "COLD",
               "replicationFallbacks": [],
               "storageTypes": ["ARCHIVE"]
           },
           {
               "copyOnCreateFile": false,
               "creationFallbacks": ["DISK","ARCHIVE"],
               "id": 5,
               "name": "WARM",
               "replicationFallbacks": ["DISK","ARCHIVE"],
               "storageTypes": ["DISK","ARCHIVE"]
           },
           {
               "copyOnCreateFile": false,
               "creationFallbacks": [],
               "id": 7,
               "name": "HOT",
               "replicationFallbacks": ["ARCHIVE"],
               "storageTypes": ["DISK"]
           },
           {
               "copyOnCreateFile": false,
               "creationFallbacks": ["SSD","DISK"],
               "id": 10,"name": "ONE_SSD",
               "replicationFallbacks": ["SSD","DISK"],
               "storageTypes": ["SSD","DISK"]
           },
           {
               "copyOnCreateFile": false,
               "creationFallbacks": ["DISK"],
               "id": 12,
               "name": "ALL_SSD",
               "replicationFallbacks": ["DISK"],
               "storageTypes": ["SSD"]
           },
           {
               "copyOnCreateFile": false,
               "creationFallbacks": ["DISK"],
               "id": 14,
               "name": "ALL_NVDIMM",
               "replicationFallbacks": ["DISK"],
               "storageTypes": ["NVDIMM"]
           },
           {
               "copyOnCreateFile": true,
               "creationFallbacks": ["DISK"],
               "id": 15,
               "name": "LAZY_PERSIST",
               "replicationFallbacks": ["DISK"],
               "storageTypes": ["RAM_DISK","DISK"]
           }
       ]
   }
}See also:FileSystem.getAllStoragePoliciesSet Storage PolicySubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETSTORAGEPOLICY
                              &storagepolicy=<policy>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.setStoragePolicyUnset Storage PolicySubmit a HTTP POT request.curl -i -X POST "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=UNSETSTORAGEPOLICY"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.unsetStoragePolicyGet Storage PolicySubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETSTORAGEPOLICY"The client receives a response with aBlockStoragePolicyJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
    "BlockStoragePolicy": {
        "copyOnCreateFile": false,
       "creationFallbacks": [],
        "id":7,
        "name":"HOT",
        "replicationFallbacks":["ARCHIVE"],
        "storageTypes":["DISK"]
    }
}See also:FileSystem.getStoragePolicySatisfy Storage PolicySubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SATISFYSTORAGEPOLICY"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:ArchivalStorage.satisfyStoragePolicyGet File Block LocationsSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETFILEBLOCKLOCATIONSThe client receives a response with aBlockLocationsJSON Object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
  "BlockLocations" :
  {
    "BlockLocation":
    [
      {
        "cachedHosts" : [],
        "corrupt" : false,
        "hosts" : ["host"],
        "length" : 134217728,                             // length of this block
        "names" : ["host:ip"],
        "offset" : 0,                                     // offset of the block in the file
        "storageTypes" : ["DISK"],                        // enum {RAM_DISK, SSD, DISK, ARCHIVE}
        "topologyPaths" : ["/default-rack/hostname:ip"]
      }, {
        "cachedHosts" : [],
        "corrupt" : false,
        "hosts" : ["host"],
        "length" : 62599364,
        "names" : ["host:ip"],
        "offset" : 134217728,
        "storageTypes" : ["DISK"],
        "topologyPaths" : ["/default-rack/hostname:ip"]
      },
      ...
    ]
  }
}See also:offset,length,FileSystem.getFileBlockLocationsExtended Attributes(XAttrs) OperationsSet XAttrSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETXATTR
                              &xattr.name=<XATTRNAME>&xattr.value=<XATTRVALUE>
                              &flag=<FLAG>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.setXAttrRemove XAttrSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=REMOVEXATTR
                              &xattr.name=<XATTRNAME>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.removeXAttrGet an XAttrSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETXATTRS
                              &xattr.name=<XATTRNAME>&encoding=<ENCODING>"The client receives a response with aXAttrsJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
    "XAttrs": [
        {
            "name":"XATTRNAME",
            "value":"XATTRVALUE"
        }
    ]
}See also:FileSystem.getXAttrGet multiple XAttrsSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETXATTRS
                              &xattr.name=<XATTRNAME1>&xattr.name=<XATTRNAME2>
                              &encoding=<ENCODING>"The client receives a response with aXAttrsJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
    "XAttrs": [
        {
            "name":"XATTRNAME1",
            "value":"XATTRVALUE1"
        },
        {
            "name":"XATTRNAME2",
            "value":"XATTRVALUE2"
        }
    ]
}See also:FileSystem.getXAttrsGet all XAttrsSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETXATTRS
                              &encoding=<ENCODING>"The client receives a response with aXAttrsJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
    "XAttrs": [
        {
            "name":"XATTRNAME1",
            "value":"XATTRVALUE1"
        },
        {
            "name":"XATTRNAME2",
            "value":"XATTRVALUE2"
        },
        {
            "name":"XATTRNAME3",
            "value":"XATTRVALUE3"
        }
    ]
}See also:FileSystem.getXAttrsList all XAttrsSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=LISTXATTRS"The client receives a response with aXAttrNamesJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
    "XAttrNames":"[\"XATTRNAME1\",\"XATTRNAME2\",\"XATTRNAME3\"]"
}See also:FileSystem.listXAttrsErasure Coding OperationsEnable EC PolicySubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/?op=ENABLEECPOLICY
                              &ecpolicy=<policy>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:HDFSErasureCoding.enablePolicyDisable EC PolicySubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/?op=DISABLEECPOLICY
                              &ecpolicy=<policy>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:HDFSErasureCoding.disablePolicySet EC PolicySubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=SETECPOLICY
                              &ecpolicy=<policy>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:HDFSErasureCoding.setErasureCodingPolicyGet EC PolicySubmit a HTTP GET request.curl -i -X GET "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETECPOLICY
                             "The client receives a response with aECPolicyJSON object:{
        "name": "RS-10-4-1024k",
        "schema":
        {
        "codecName": "rs",
        "numDataUnits": 10,
        "numParityUnits": 4,
        "extraOptions": {}
        }
        "cellSize": 1048576,
        "id":5,
        "codecname":"rs",
        "numDataUnits": 10,
        "numParityUnits": 4,
        "replicationpolicy":false,
        "systemPolicy":true

    }See also:HDFSErasureCoding.getErasureCodingPolicyUnset EC PolicySubmit a HTTP POST request.curl -i -X POST "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=UNSETECPOLICY
                             "The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:HDFSErasureCoding.unsetErasureCodingPolicySnapshot OperationsAllow SnapshotSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=ALLOWSNAPSHOT"The client receives a response with zero content length on success:HTTP/1.1 200 OK
Content-Length: 0Disallow SnapshotSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=DISALLOWSNAPSHOT"The client receives a response with zero content length on success:HTTP/1.1 200 OK
Content-Length: 0Create SnapshotSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=CREATESNAPSHOT[&snapshotname=<SNAPSHOTNAME>]"The client receives a response with aPathJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"Path": "/user/username/.snapshot/s1"}See also:FileSystem.createSnapshotDelete SnapshotSubmit a HTTP DELETE request.curl -i -X DELETE "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=DELETESNAPSHOT&snapshotname=<SNAPSHOTNAME>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.deleteSnapshotRename SnapshotSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=RENAMESNAPSHOT
                   &oldsnapshotname=<SNAPSHOTNAME>&snapshotname=<SNAPSHOTNAME>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:FileSystem.renameSnapshotGet Snapshot DiffSubmit a HTTP GET request.curl -i GET "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETSNAPSHOTDIFF
                   &oldsnapshotname=<SNAPSHOTNAME>&snapshotname=<SNAPSHOTNAME>"The client receives a response with aSnapshotDiffReportJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"SnapshotDiffReport":{"diffList":[],"fromSnapshot":"s3","snapshotRoot":"/foo","toSnapshot":"s4"}}Get Snapshot Diff IterativelySubmit a HTTP GET request.curl -i -X GET "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?op=GETSNAPSHOTDIFFLISTING
                   &oldsnapshotname=<SNAPSHOTNAME>&snapshotname=<SNAPSHOTNAME>&snapshotdiffstartpath=<STARTPATH>&snapshotdiffindex=<STARTINDEX>Ifsnapshotdiffstartpathandsnapshotdiffindexare not given,""(empty string) and-1are used respectively implying the first iteration.The client receives a response with aSnapshotDiffReportListingJSON object. The value oflastPathandlastIndexmust be specified as the value ofsnapshotdiffstartpathandsnapshotdiffindexrespectively on next iteration.HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"SnapshotDiffReportListing":{"createList":[],"deleteList":[],"isFromEarlier":true,"lastIndex":-1,"lastPath":"","modifyList":[]}}Get Snapshottable Directory ListSubmit a HTTP GET request.curl -i GET "http://<HOST>:<PORT>/webhdfs/v1/?user.name=<USER>&op=GETSNAPSHOTTABLEDIRECTORYLIST"If the USER is not the hdfs super user, the call lists only the snapshottable directories owned by the user. If the USER is the hdfs super user, the call lists all the snapshottable directories. The client receives a response with aSnapshottableDirectoryListJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
    "SnapshottableDirectoryList":
    [
        {
          "dirStatus":
            {
                "accessTime":0,
                "blockSize":0,
                "childrenNum":0,
                "fileId":16386,
                "group":"hadoop",
                "length":0,
                "modificationTime":1520761889225,
                "owner":"random",
                "pathSuffix":"bar",
                "permission":"755",
                "replication":0,
                "storagePolicy":0,
                "type":"DIRECTORY"
            },
          "parentFullPath":"/",
          "snapshotNumber":0,
          "snapshotQuota":65536
        }
    ]
}Get Snapshot ListSubmit a HTTP GET request.curl -i GET "http://<HOST>:<PORT>/webhdfs/v1/<PATH>?"The call lists the snapshots for a snapshottable directory. The client receives a response with aSnapshotListJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
    "SnapshotList":
    [
        {
          "dirStatus":
            {
                "accessTime":0,
                "blockSize":0,
                "childrenNum":0,
                "fileId":16386,
                "group":"hadoop",
                "length":0,
                "modificationTime":1520761889225,
                "owner":"random",
                "pathSuffix":"bar",
                "permission":"755",
                "replication":0,
                "storagePolicy":0,
                "type":"DIRECTORY"
            },
          "fullPath":"/",
          "snapshotID":0,
          "deletionStatus":ACTIVE
        }
    ]
}Delegation Token OperationsGet Delegation TokenSubmit a HTTP GET request.curl -i "http://<HOST>:<PORT>/webhdfs/v1/?op=GETDELEGATIONTOKEN
            [&renewer=<USER>][&service=<SERVICE>][&kind=<KIND>]"The client receives a response with aTokenJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{
  "Token":
  {
    "urlString": "JQAIaG9y..."
  }
}See also:renewer,FileSystem.getDelegationToken,kind,serviceRenew Delegation TokenSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/?op=RENEWDELEGATIONTOKEN&token=<TOKEN>"The client receives a response with alongJSON object:HTTP/1.1 200 OK
Content-Type: application/json
Transfer-Encoding: chunked

{"long": 1320962673997}           //the new expiration timeSee also:token,DelegationTokenAuthenticator.renewDelegationTokenCancel Delegation TokenSubmit a HTTP PUT request.curl -i -X PUT "http://<HOST>:<PORT>/webhdfs/v1/?op=CANCELDELEGATIONTOKEN&token=<TOKEN>"The client receives a response with zero content length:HTTP/1.1 200 OK
Content-Length: 0See also:token,DelegationTokenAuthenticator.cancelDelegationTokenError ResponsesWhen an operation fails, the server may throw an exception. The JSON schema of error responses is defined inRemoteException JSON Schema. The table below shows the mapping from exceptions to HTTP response codes.HTTP Response CodesExceptionsHTTP Response CodesIllegalArgumentException400 Bad RequestUnsupportedOperationException400 Bad RequestSecurityException401 UnauthorizedIOException403 ForbiddenFileNotFoundException404 Not FoundRuntimeException500 Internal Server ErrorBelow are examples of exception responses.Illegal Argument ExceptionHTTP/1.1 400 Bad Request
Content-Type: application/json
Transfer-Encoding: chunked

{
  "RemoteException":
  {
    "exception"    : "IllegalArgumentException",
    "javaClassName": "java.lang.IllegalArgumentException",
    "message"      : "Invalid value for webhdfs parameter \"permission\": ..."
  }
}Security ExceptionHTTP/1.1 401 Unauthorized
Content-Type: application/json
Transfer-Encoding: chunked

{
  "RemoteException":
  {
    "exception"    : "SecurityException",
    "javaClassName": "java.lang.SecurityException",
    "message"      : "Failed to obtain user group information: ..."
  }
}Access Control ExceptionHTTP/1.1 403 Forbidden
Content-Type: application/json
Transfer-Encoding: chunked

{
  "RemoteException":
  {
    "exception"    : "AccessControlException",
    "javaClassName": "org.apache.hadoop.security.AccessControlException",
    "message"      : "Permission denied: ..."
  }
}File Not Found ExceptionHTTP/1.1 404 Not Found
Content-Type: application/json
Transfer-Encoding: chunked

{
  "RemoteException":
  {
    "exception"    : "FileNotFoundException",
    "javaClassName": "java.io.FileNotFoundException",
    "message"      : "File does not exist: /foo/a.patch"
  }
}JSON SchemasAll operations, except forOPEN, either return a zero-length response or a JSON response. ForOPEN, the response is an octet-stream. The JSON schemas are shown below. Seedraft-zyp-json-schema-03for the syntax definitions of the JSON schemas.Notethat the default value ofadditionalPropertiesis an empty schema which allows any value for additional properties. Therefore, all WebHDFS JSON responses allow any additional property. However, if additional properties are included in the responses, they are considered as optional properties in order to maintain compatibility.ACL Status JSON Schema{
  "name"      : "AclStatus",
  "properties":
  {
    "AclStatus":
    {
      "type"      : "object",
      "properties":
      {
        "entries":
        {
          "type": "array",
          "items":
          {
            "description": "ACL entry.",
            "type": "string"
          }
        },
        "group":
        {
          "description": "The group owner.",
          "type"       : "string",
          "required"   : true
        },
        "owner":
        {
          "description": "The user who is the owner.",
          "type"       : "string",
          "required"   : true
        },
        "stickyBit":
        {
          "description": "True if the sticky bit is on.",
          "type"       : "boolean",
          "required"   : true
        }
      }
    }
  }
}XAttrs JSON Schema{
  "name"      : "XAttrs",
  "properties":
  {
    "XAttrs":
    {
      "type"      : "array",
      "items":
      {
        "type"    : "object",
        "properties":
        {
          "name":
          {
            "description": "XAttr name.",
            "type"       : "string",
            "required"   : true
          },
          "value":
          {
            "description": "XAttr value.",
            "type"       : "string"
          }
        }
      }
    }
  }
}XAttrNames JSON Schema{
  "name"      : "XAttrNames",
  "properties":
  {
    "XAttrNames":
    {
      "description": "XAttr names.",
      "type"       : "string",
      "required"   : true
    }
  }
}Boolean JSON Schema{
  "name"      : "boolean",
  "properties":
  {
    "boolean":
    {
      "description": "A boolean value",
      "type"       : "boolean",
      "required"   : true
    }
  }
}See also:MKDIRS,RENAME,DELETE,SETREPLICATIONContentSummary JSON Schema{
  "name"      : "ContentSummary",
  "properties":
  {
    "ContentSummary":
    {
      "type"      : "object",
      "properties":
      {
        "directoryCount":
        {
          "description": "The number of directories.",
          "type"       : "integer",
          "required"   : true
        },
        "fileCount":
        {
          "description": "The number of files.",
          "type"       : "integer",
          "required"   : true
        },
        "length":
        {
          "description": "The number of bytes used by the content.",
          "type"       : "integer",
          "required"   : true
        },
        "quota":
        {
          "description": "The namespace quota of this directory.",
          "type"       : "integer",
          "required"   : true
        },
        "spaceConsumed":
        {
          "description": "The disk space consumed by the content.",
          "type"       : "integer",
          "required"   : true
        },
        "spaceQuota":
        {
          "description": "The disk space quota.",
          "type"       : "integer",
          "required"   : true
        },
        "typeQuota":
        {
          "type"      : "object",
          "properties":
          {
            "ARCHIVE":
            {
              "type"      : "object",
              "properties":
              {
                "consumed":
                {
                  "description": "The storage type space consumed.",
                  "type"       : "integer",
                  "required"   : true
                },
                "quota":
                {
                  "description": "The storage type quota.",
                  "type"       : "integer",
                  "required"   : true
                }
              }
            },
            "DISK":
            {
              "type"      : "object",
              "properties":
              {
                "consumed":
                {
                  "description": "The storage type space consumed.",
                  "type"       : "integer",
                  "required"   : true
                },
                "quota":
                {
                  "description": "The storage type quota.",
                  "type"       : "integer",
                  "required"   : true
                }
              }
            },
            "SSD":
            {
              "type"      : "object",
              "properties":
              {
                "consumed":
                {
                  "description": "The storage type space consumed.",
                  "type"       : "integer",
                  "required"   : true
                },
                "quota":
                {
                  "description": "The storage type quota.",
                  "type"       : "integer",
                  "required"   : true
                }
              }
            }
          }
        }
      }
    }
  }
}See also:GETCONTENTSUMMARYQuotaUsage JSON Schema{
  "name"      : "QuotaUsage",
  "properties":
  {
    "QuotaUsage":
    {
      "type"      : "object",
      "properties":
      {
        "fileAndDirectoryCount":
        {
          "description": "The number of files and directories.",
          "type"       : "integer",
          "required"   : true
        },
        "quota":
        {
          "description": "The namespace quota of this directory.",
          "type"       : "integer",
          "required"   : true
        },
        "spaceConsumed":
        {
          "description": "The disk space consumed by the content.",
          "type"       : "integer",
          "required"   : true
        },
        "spaceQuota":
        {
          "description": "The disk space quota.",
          "type"       : "integer",
          "required"   : true
        },
        "typeQuota":
        {
          "type"      : "object",
          "properties":
          {
            "ARCHIVE":
            {
              "type"      : "object",
              "properties":
              {
                "consumed":
                {
                  "description": "The storage type space consumed.",
                  "type"       : "integer",
                  "required"   : true
                },
                "quota":
                {
                  "description": "The storage type quota.",
                  "type"       : "integer",
                  "required"   : true
                }
              }
            },
            "DISK":
            {
              "type"      : "object",
              "properties":
              {
                "consumed":
                {
                  "description": "The storage type space consumed.",
                  "type"       : "integer",
                  "required"   : true
                },
                "quota":
                {
                  "description": "The storage type quota.",
                  "type"       : "integer",
                  "required"   : true
                }
              }
            },
            "SSD":
            {
              "type"      : "object",
              "properties":
              {
                "consumed":
                {
                  "description": "The storage type space consumed.",
                  "type"       : "integer",
                  "required"   : true
                },
                "quota":
                {
                  "description": "The storage type quota.",
                  "type"       : "integer",
                  "required"   : true
                }
              }
            }
          }
        }
      }
    }
  }
}See also:GETQUOTAUSAGEFileChecksum JSON Schema{
  "name"      : "FileChecksum",
  "properties":
  {
    "FileChecksum":
    {
      "type"      : "object",
      "properties":
      {
        "algorithm":
        {
          "description": "The name of the checksum algorithm.",
          "type"       : "string",
          "required"   : true
        },
        "bytes":
        {
          "description": "The byte sequence of the checksum in hexadecimal.",
          "type"       : "string",
          "required"   : true
        },
        "length":
        {
          "description": "The length of the bytes (not the length of the string).",
          "type"       : "integer",
          "required"   : true
        }
      }
    }
  }
}FileStatus JSON Schema{
  "name"      : "FileStatus",
  "properties":
  {
    "FileStatus": fileStatusProperties      //See FileStatus Properties
  }
}See also:FileStatusProperties,GETFILESTATUS,FileStatusFileStatus PropertiesJavaScript syntax is used to definefileStatusPropertiesso that it can be referred in bothFileStatusandFileStatusesJSON schemas.var fileStatusProperties =
{
  "type"      : "object",
  "properties":
  {
    "accessTime":
    {
      "description": "The access time.",
      "type"       : "integer",
      "required"   : true
    },
    "blockSize":
    {
      "description": "The block size of a file.",
      "type"       : "integer",
      "required"   : true
    },
    "group":
    {
      "description": "The group owner.",
      "type"       : "string",
      "required"   : true
    },
    "length":
    {
      "description": "The number of bytes in a file.",
      "type"       : "integer",
      "required"   : true
    },
    "modificationTime":
    {
      "description": "The modification time.",
      "type"       : "integer",
      "required"   : true
    },
    "owner":
    {
      "description": "The user who is the owner.",
      "type"       : "string",
      "required"   : true
    },
    "pathSuffix":
    {
      "description": "The path suffix.",
      "type"       : "string",
      "required"   : true
    },
    "permission":
    {
      "description": "The permission represented as a octal string.",
      "type"       : "string",
      "required"   : true
    },
    "replication":
    {
      "description": "The number of replication of a file.",
      "type"       : "integer",
      "required"   : true
    },
   "symlink":                                         //an optional property
    {
      "description": "The link target of a symlink.",
      "type"       : "string"
    },
   "type":
    {
      "description": "The type of the path object.",
      "enum"       : ["FILE", "DIRECTORY", "SYMLINK"],
      "required"   : true
    },
    "aclBit":
    {
       "description": "Has ACLs set or not.",
       "type"       : "boolean",
    },
    "encBit":
    {
       "description": "Is Encrypted or not.",
       "type"       : "boolean",
    },
    "ecBit":
    {
       "description": "Is ErasureCoded or not.",
       "type"       : "boolean",
    },
    "ecPolicy":
    {
       "description": "The namenode of ErasureCodePolicy.",
       "type"       : "String",
    }
  }
};FileStatuses JSON SchemaAFileStatusesJSON object represents an array ofFileStatusJSON objects.{
  "name"      : "FileStatuses",
  "properties":
  {
    "FileStatuses":
    {
      "type"      : "object",
      "properties":
      {
        "FileStatus":
        {
          "description": "An array of FileStatus",
          "type"       : "array",
          "items"      : fileStatusProperties      //See FileStatus Properties
        }
      }
    }
  }
}See also:FileStatusProperties,LISTSTATUS,FileStatusDirectoryListing JSON SchemaADirectoryListingJSON object represents a batch of directory entries while iteratively listing a directory. It contains aFileStatusesJSON object as well as iteration information.{
  "name"      : "DirectoryListing",
  "properties":
  {
    "DirectoryListing":
    {
      "type"      : "object",
      "properties":
      {
        "partialListing":
        {
          "description": "A partial directory listing",
          "type"       : "object", // A FileStatuses object
          "required"   : true
        },
        "remainingEntries":
        {
          "description": "Number of remaining entries",
          "type"       : "integer",
          "required"   : true
        }
      }
    }
  }

}See also:FileStatusesJSON Schema,LISTSTATUS_BATCH,FileStatusLong JSON Schema{
  "name"      : "long",
  "properties":
  {
    "long":
    {
      "description": "A long integer value",
      "type"       : "integer",
      "required"   : true
    }
  }
}See also:RENEWDELEGATIONTOKEN,Path JSON Schema{
  "name"      : "Path",
  "properties":
  {
    "Path":
    {
      "description": "The string representation a Path.",
      "type"       : "string",
      "required"   : true
    }
  }
}See also:GETHOMEDIRECTORY,PathRemoteException JSON Schema{
  "name"      : "RemoteException",
  "properties":
  {
    "RemoteException":
    {
      "type"      : "object",
      "properties":
      {
        "exception":
        {
          "description": "Name of the exception",
          "type"       : "string",
          "required"   : true
        },
        "message":
        {
          "description": "Exception message",
          "type"       : "string",
          "required"   : true
        },
        "javaClassName":                                     //an optional property
        {
          "description": "Java class name of the exception",
          "type"       : "string"
        }
      }
    }
  }
}See also:Error ResponsesToken JSON Schema{
  "name"      : "Token",
  "properties":
  {
    "Token": tokenProperties      //See Token Properties
  }
}See also:TokenProperties,GETDELEGATIONTOKEN, the note inDelegation.Token PropertiesJavaScript syntax is used to definetokenPropertiesso that it can be referred inTokenJSON schema.var tokenProperties =
{
  "type"      : "object",
  "properties":
  {
    "urlString":
    {
      "description": "A delegation token encoded as a URL safe string.",
      "type"       : "string",
      "required"   : true
    }
  }
}See also:TokenProperties, the note inDelegation.BlockStoragePolicy JSON Schema{
  "name"      : "BlockStoragePolicy",
  "properties":
  {
    "BlockStoragePolicy": blockStoragePolicyProperties      //See BlockStoragePolicy Properties
  }
}See also:BlockStoragePolicyProperties,GETSTORAGEPOLICYBlockStoragePolicy PropertiesJavaScript syntax is used to defineblockStoragePolicyPropertiesso that it can be referred in bothBlockStoragePolicyandBlockStoragePoliciesJSON schemas.var blockStoragePolicyProperties =
{
  "type"      : "object",
  "properties":
  {
    "id":
    {
      "description": "Policy ID.",
      "type"       : "integer",
      "required"   : true
    },
    "name":
    {
      "description": "Policy name.",
      "type"       : "string",
      "required"   : true
    },
    "storageTypes":
    {
      "description": "An array of storage types for block placement.",
      "type"       : "array",
      "required"   : true
      "items"      :
      {
        "type": "string"
      }
    },
    "replicationFallbacks":
    {
      "description": "An array of fallback storage types for replication.",
      "type"       : "array",
      "required"   : true
      "items"      :
      {
        "type": "string"
      }
    },
    "creationFallbacks":
    {
      "description": "An array of fallback storage types for file creation.",
      "type"       : "array",
      "required"   : true
      "items"      :
      {
       "type": "string"
      }
    },
    "copyOnCreateFile":
    {
      "description": "If set then the policy cannot be changed after file creation.",
      "type"       : "boolean",
      "required"   : true
    }
  }
};ECPolicy JSON Schema{
  "name": "RS-10-4-1024k",
  schema {
           "codecName": "rs",
           "numDataUnits": 10,
           "numParityUnits": 4,
           "extraOptions": {}
          }
  "cellSize": 1048576,
  "id":5,
  "codecname":"rs",
  "numDataUnits": 10,
  "numParityUnits": 4,
  "replicationpolicy":false,
  "systemPolicy":true
}BlockStoragePolicies JSON SchemaABlockStoragePoliciesJSON object represents an array ofBlockStoragePolicyJSON objects.{
  "name"      : "BlockStoragePolicies",
  "properties":
  {
    "BlockStoragePolicies":
    {
      "type"      : "object",
      "properties":
      {
        "BlockStoragePolicy":
        {
          "description": "An array of BlockStoragePolicy",
          "type"       : "array",
          "items"      : blockStoragePolicyProperties      //See BlockStoragePolicy Properties
        }
      }
    }
  }
}SnapshotDiffReport JSON Schema{
  "name": "SnapshotDiffReport",
  "type": "object",
  "properties":
  {
    "SnapshotDiffReport":
    {
      "type"        : "object",
      "properties"  :
      {
        "diffList":
        {
          "description": "An array of DiffReportEntry",
          "type"        : "array",
          "items"       : diffReportEntries,
          "required"    : true
        },
        "fromSnapshot":
        {
          "description": "Source snapshot",
          "type"        : "string",
          "required"    : true
        },
        "snapshotRoot":
        {
          "description" : "String representation of snapshot root path",
          "type"        : "string",
          "required"    : true
        },
        "toSnapshot":
        {
          "description" : "Destination snapshot",
          "type"        : "string",
          "required"    : true
        }
      }
    }
  }
}DiffReport EntriesJavaScript syntax is used to definediffReportEntriesso that it can be referred inSnapshotDiffReportJSON schema.var diffReportEntries =
{
  "type": "object",
  "properties":
  {
    "sourcePath":
    {
      "description" : "Source path name relative to snapshot root",
      "type"        : "string",
      "required"    : true
    },
    "targetPath":
    {
      "description" : "Target path relative to snapshot root used for renames",
      "type"        : "string",
      "required"    : true
    },
    "type":
    {
      "description" : "Type of diff report entry",
      "enum"        : ["CREATE", "MODIFY", "DELETE", "RENAME"],
      "required"    : true
    }
  }
}SnapshotDiffReportListing JSON Schema{
  "name": "SnapshotDiffReportListing",
  "type": "object",
  "properties":
  {
    "SnapshotDiffReportListing":
    {
      "type"        : "object",
      "properties"  :
      {
        "isFromEarlier":
        {
          "description" : "the diff is calculated from older to newer snapshot or not",
          "type"        : "boolean",
          "required"    : true
        },
        "lastIndex":
        {
          "description" : "the last index of listing iteration",
          "type"        : "integer",
          "required"    : true
        },
        "lastPath":
        {
          "description" : "String representation of the last path of the listing iteration",
          "type"        : "string",
          "required"    : true
        },
        "modifyList":
        {
          "description": "An array of DiffReportListingEntry",
          "type"        : "array",
          "items"       : diffReportListingEntries,
          "required"    : true
        },
        "createList":
        {
          "description": "An array of DiffReportListingEntry",
          "type"        : "array",
          "items"       : diffReportListingEntries,
          "required"    : true
        },
        "deleteList":
        {
          "description": "An array of DiffReportListingEntry",
          "type"        : "array",
          "items"       : diffReportListingEntries,
          "required"    : true
        }
      }
    }
  }
}DiffReportListing EntriesJavaScript syntax is used to definediffReportEntriesso that it can be referred inSnapshotDiffReportJSON schema.var diffReportListingEntries =
{
  "type": "object",
  "properties":
  {
    "dirId":
    {
      "description" : "inode id of the directory",
      "type"        : "integer",
      "required"    : true
    },
    "fileId":
    {
      "description" : "inode id of the file",
      "type"        : "integer",
      "required"    : true
    },
    "isRereference":
    {
      "description" : "this is reference or not",
      "type"        : "boolean",
      "required"    : true
    },
    "sourcePath":
    {
      "description" : "string representation of path where changes have happened",
      "type"        : "string",
      "required"    : true
    },
    "targetPath":
    {
      "description" : "string representation of target path of rename op",
      "type"        : "string",
      "required"    : false
    }
  }
}SnapshottableDirectoryList JSON Schema{
  "name": "SnapshottableDirectoryList",
  "type": "object",
  "properties":
  {
    "SnapshottableDirectoryList":
    {
      "description": "An array of SnapshottableDirectoryStatus",
      "type"        : "array",
      "items"       : snapshottableDirectoryStatus,
      "required"    : true
    }
  }
}SnapshottableDirectoryStatusJavaScript syntax is used to definesnapshottableDirectoryStatusso that it can be referred inSnapshottableDirectoryListJSON schema.var snapshottableDirectoryStatus =
{
  "type": "object",
  "properties":
  {
    "dirStatus": fileStatusProperties,
    "parentFullPath":
    {
      "description" : "Full path of the parent of snapshottable directory",
      "type"        : "string",
      "required"    : true
    },
    "snapshotNumber":
    {
      "description" : "Number of snapshots created on the snapshottable directory",
      "type"        : "integer",
      "required"    : true
    },
    "snapshotQuota":
    {
      "description" : "Total number of snapshots allowed on the snapshottable directory",
      "type"        : "integer",
      "required"    : true
    }
  }
}SnapshotList JSON Schema{
  "name": "SnapshotList",
  "type": "object",
  "properties":
  {
    "SnapshotList":
    {
      "description": "An array of SnapshotStatus",
      "type"        : "array",
      "items"       : snapshotStatus,
      "required"    : true
    }
  }
}SnapshotStatusJavaScript syntax is used to definesnapshotStatusso that it can be referred inSnapshotListJSON schema.var snapshotStatus =
{
  "type": "object",
  "properties":
  {
    "dirStatus": fileStatusProperties,
    "fullPath":
    {
      "description" : "Full path of the parent of the snapshot",
      "type"        : "string",
      "required"    : true
    },
    "snapshotID":
    {
      "description" : "snapshot ID for the snapshot",
      "type"        : "integer",
      "required"    : true
    },
    "deletionStatus":
    {
      "description" : "Status showing whether the snapshot is active or in deleted state",
      "type"        : "string",
      "required"    : true
    }
  }
}BlockLocations JSON SchemaABlockLocationsJSON object represents an array ofBlockLocationJSON objects.{
  "name"      : "BlockLocations",
  "properties":
  {
    "BlockLocations":
    {
      "type"      : "object",
      "properties":
      {
        "BlockLocation":
        {
          "description": "An array of BlockLocation",
          "type"       : "array",
          "items"      : blockLocationProperties      //See BlockLocation Properties
        }
      }
    }
  }
}See alsoBlockLocationProperties,GETFILEBLOCKLOCATIONS,BlockLocationBlockLocation JSON Schema{
  "name"      : "BlockLocation",
  "properties":
  {
    "BlockLocation": blockLocationProperties      //See BlockLocation Properties
  }
}See alsoBlockLocationProperties,GETFILEBLOCKLOCATIONS,BlockLocationBlockLocation PropertiesJavaScript syntax is used to defineblockLocationPropertiesso that it can be referred in bothBlockLocationandBlockLocationsJSON schemas.var blockLocationProperties =
{
  "type"      : "object",
  "properties":
  {
    "cachedHosts":
    {
      "description": "Datanode hostnames with a cached replica",
      "type"       : "array",
      "required"   : "true",
      "items"      :
      {
        "description": "A datanode hostname",
        "type"       : "string"
      }
    },
    "corrupt":
    {
      "description": "True if the block is corrupted",
      "type"       : "boolean",
      "required"   : "true"
    },
    "hosts":
    {
      "description": "Datanode hostnames store the block",
      "type"       : "array",
      "required"   : "true",
      "items"      :
      {
        "description": "A datanode hostname",
        "type"       : "string"
      }
    },
    "length":
    {
      "description": "Length of the block",
      "type"       : "integer",
      "required"   : "true"
    },
    "names":
    {
      "description": "Datanode IP:xferPort for accessing the block",
      "type"       : "array",
      "required"   : "true",
      "items"      :
      {
        "description": "DatanodeIP:xferPort",
        "type"       : "string"
      }
    },
    "offset":
    {
      "description": "Offset of the block in the file",
      "type"       : "integer",
      "required"   : "true"
    },
    "storageTypes":
    {
      "description": "Storage type of each replica",
      "type"       : "array",
      "required"   : "true",
      "items"      :
      {
        "description": "Storage type",
        "enum"       : ["RAM_DISK", "SSD", "DISK", "ARCHIVE"]
      }
    },
    "topologyPaths":
    {
      "description": "Datanode addresses in network topology",
      "type"       : "array",
      "required"   : "true",
      "items"      :
      {
        "description": "/rack/host:ip",
        "type"       : "string"
      }
    }
  }
};Server Defaults JSON Schema{
  "FsServerDefaults": {
    "replication": 3,
    "encryptDataTransfer": false,
    "defaultStoragePolicyId": 7,
    "writePacketSize": 65536,
    "fileBufferSize": 4096,
    "checksumType": 2,
    "trashInterval": 10080,
    "keyProviderUri": "",
    "blockSize": 134217728,
    "bytesPerChecksum": 512
  }
}FsStatus JSON Schema{
  "FsStatus": {
    "used": 29229154304,
    "remaining": 292893392896,
    "capacity": 322122547200
  }
}EC Policies JSON Schema{
  "ErasureCodingPolicies": {
    "ErasureCodingPolicyInfo": [
      {
        "state": "ENABLED",
        "policy": {
          "name": "RS-6-3-1024k",
          "schema": {
            "codecName": "rs",
            "numDataUnits": 6,
            "numParityUnits": 3,
            "extraOptions": {}
          },
          "cellSize": 1048576,
          "id": 1,
          "replicationPolicy": false,
          "codecName": "rs",
          "numDataUnits": 6,
          "numParityUnits": 3,
          "systemPolicy": true
        }
      }
    ]
  }
}EC Codecs JSON Schema{
  "ErasureCodingCodecs": {
    "rs": "rs_native, rs_java",
    "rs-legacy": "rs-legacy_java",
    "xor": "xor_native, xor_java"
  }
}Paths JSON Schema{
  "Paths": [{
    "blocksize": 0,
    "owner": "hadoop",
    "path": "/user/user0/.Trash",
    "length": 0,
    "permission": "755",
    "modification_time": 1693050205747,
    "isdir": true,
    "block_replication": 0,
    "access_time": 0,
    "group": "supergroup"
  }]
}HTTP Query Parameter DictionaryACL SpecNameaclspecDescriptionThe ACL spec included in ACL modification operations.TypeStringDefault Value<empty>Valid ValuesSeePermissions and HDFS.SyntaxSeePermissions and HDFS.XAttr NameNamexattr.nameDescriptionThe XAttr name of a file/directory.TypeStringDefault Value<empty>Valid ValuesAny string prefixed with user./trusted./system./security..SyntaxAny string prefixed with user./trusted./system./security..XAttr ValueNamexattr.valueDescriptionThe XAttr value of a file/directory.TypeStringDefault Value<empty>Valid ValuesAn encoded value.SyntaxEnclosed in double quotes or prefixed with 0x or 0s.See also:Extended AttributesXAttr set flagNameflagDescriptionThe XAttr set flag.TypeStringDefault Value<empty>Valid ValuesCREATE,REPLACE.SyntaxCREATE,REPLACE.See also:Extended AttributesXAttr value encodingNameencodingDescriptionThe XAttr value encoding.TypeStringDefault Value<empty>Valid Valuestexthexbase64Syntaxtexthexbase64See also:Extended AttributesAccess TimeNameaccesstimeDescriptionThe access time of a file/directory.TypelongDefault Value-1 (means keeping it unchanged)Valid Values-1 or a timestampSyntaxAny integer.See also:SETTIMESBlock SizeNameblocksizeDescriptionThe block size of a file.TypelongDefault ValueSpecified in the configuration.Valid Values> 0SyntaxAny integer.See also:CREATEBuffer SizeNamebuffersizeDescriptionThe size of the buffer used in transferring data.TypeintDefault ValueSpecified in the configuration.Valid Values> 0SyntaxAny integer.See also:CREATE,APPEND,OPENCreate FlagNamecreateflagDescriptionEnum of possible flags to process while creating a fileTypeenumerated stringsDefault Value<empty>Valid ValuesLegal combinations of create, overwrite, append and sync_blockSyntaxSee note belowThe following combinations are not valid: * append,create * create,append,overwriteSee also:CREATECreate ParentNamecreateparentDescriptionIf the parent directories do not exist, should they be created?TypebooleanDefault ValuetrueValid Valuestrue, falseSyntaxtrueSee also:CREATESYMLINKDelegationNamedelegationDescriptionThe delegation token used for authentication.TypeStringDefault Value<empty>Valid ValuesAn encoded token.SyntaxSee the note below.Notethat delegation tokens are encoded as a URL safe string; seeencodeToUrlString()anddecodeFromUrlString(String)inorg.apache.hadoop.security.token.Tokenfor the details of the encoding.See also:AuthenticationDestinationNamedestinationDescriptionThe destination path.TypePathDefault Value<empty> (an invalid path)Valid ValuesAn absolute FileSystem path without scheme and authority.SyntaxAny path.See also:CREATESYMLINK,RENAMEDo AsNamedoasDescriptionAllowing a proxy user to do as another user.TypeStringDefault ValuenullValid ValuesAny valid username.SyntaxAny string.See also:Proxy UsersFs ActionNamefsactionDescriptionFile system operation read/write/executeTypeStringDefault Valuenull (an invalid value)Valid ValuesStrings matching regex pattern  "[r-][w-][x-] "Syntax"[r-][w-][x-] "See also:CHECKACCESS,GroupNamegroupDescriptionThe name of a group.TypeStringDefault Value<empty> (means keeping it unchanged)Valid ValuesAny valid group name.SyntaxAny string.See also:SETOWNERLengthNamelengthDescriptionThe number of bytes to be processed.TypelongDefault Valuenull (means the entire file)Valid Values>= 0 or nullSyntaxAny integer.See also:OPENModification TimeNamemodificationtimeDescriptionThe modification time of a file/directory.TypelongDefault Value-1 (means keeping it unchanged)Valid Values-1 or a timestampSyntaxAny integer.See also:SETTIMESNew LengthNamenewlengthDescriptionThe size the file is to be truncated to.TypelongValid Values>= 0SyntaxAny long.OffsetNameoffsetDescriptionThe starting byte position.TypelongDefault Value0Valid Values>= 0SyntaxAny integer.See also:OPENOld Snapshot NameNameoldsnapshotnameDescriptionThe old name of the snapshot to be renamed.TypeStringDefault ValuenullValid ValuesAn existing snapshot name.SyntaxAny string.See also:RENAMESNAPSHOTOpNameopDescriptionThe name of the operation to be executed.TypeenumDefault Valuenull (an invalid value)Valid ValuesAny valid operation name.SyntaxAny string.See also:OperationsOverwriteNameoverwriteDescriptionIf a file already exists, should it be overwritten?TypebooleanDefault ValuefalseValid ValuestrueSyntaxtrueSee also:CREATEOwnerNameownerDescriptionThe username who is the owner of a file/directory.TypeStringDefault Value<empty> (means keeping it unchanged)Valid ValuesAny valid username.SyntaxAny string.See also:SETOWNERPermissionNamepermissionDescriptionThe permission of a file/directory.TypeOctalDefault Value644 for files, 755 for directoriesValid Values0 - 1777SyntaxAny radix-8 integer (leading zeros may be omitted.)See also:CREATE,MKDIRS,SETPERMISSIONRecursiveNamerecursiveDescriptionShould the operation act on the content in the subdirectories?TypebooleanDefault ValuefalseValid ValuestrueSyntaxtrueSee also:RENAMERenewerNamerenewerDescriptionThe username of the renewer of a delegation token.TypeStringDefault Value<empty> (means the current user)Valid ValuesAny valid username.SyntaxAny string.See also:GETDELEGATIONTOKENReplicationNamereplicationDescriptionThe number of replications of a file.TypeshortDefault ValueSpecified in the configuration.Valid Values> 0SyntaxAny integer.See also:CREATE,SETREPLICATIONSnapshot NameNamesnapshotnameDescriptionThe name of the snapshot to be created/deleted. Or the new name for snapshot rename.TypeStringDefault ValuenullValid ValuesAny valid snapshot name.SyntaxAny string.See also:CREATESNAPSHOT,DELETESNAPSHOT,RENAMESNAPSHOTSourcesNamesourcesDescriptionA list of source paths.TypeStringDefault Value<empty>Valid ValuesA list of comma separated absolute FileSystem paths without scheme and authority.SyntaxAny string.See also:CONCATTokenNametokenDescriptionThe delegation token used for the operation.TypeStringDefault Value<empty>Valid ValuesAn encoded token.SyntaxSee the note inDelegation.See also:RENEWDELEGATIONTOKEN,CANCELDELEGATIONTOKENToken KindNamekindDescriptionThe kind of the delegation token requestedTypeStringDefault Value<empty> (Server sets the default kind for the service)Valid ValuesA string that represents token kind e.g “HDFS_DELEGATION_TOKEN” or “WEBHDFS delegation”SyntaxAny string.See also:GETDELEGATIONTOKENToken ServiceNameserviceDescriptionThe name of the service where the token is supposed to be used, e.g. ip:port of the namenodeTypeStringDefault Value<empty>Valid Valuesip:port in string format or logical name of the serviceSyntaxAny string.See also:GETDELEGATIONTOKENUsernameNameuser.nameDescriptionThe authenticated user; seeAuthentication.TypeStringDefault ValuenullValid ValuesAny valid username.SyntaxAny string.See also:AuthenticationNoRedirectNamenoredirectDescriptionWhether the response should return an HTTP 307 redirect or HTTP 200 OK. SeeCreate and Write to a File.TypebooleanDefault ValuefalseValid ValuestrueSyntaxtrueSee also:Create and Write to a FileNamespace QuotaNamenamespacequotaDescriptionLimit on the namespace usage, i.e., number of files/directories, under a directory.TypeStringDefault ValueLong.MAX_VALUEValid Values> 0.SyntaxAny integer.See also:SETQUOTAStorage Space QuotaNamestoragespacequotaDescriptionLimit on storage space usage (in bytes, including replication) under a directory.TypeStringDefault ValueLong.MAX_VALUEValid Values> 0.SyntaxAny integer.See also:SETQUOTA,SETQUOTABYSTORAGETYPEStorage TypeNamestoragetypeDescriptionStorage type of the specific storage type quota to be modified.TypeStringDefault Value<empty>Valid ValuesAny valid storage type.SyntaxAny string.See also:SETQUOTABYSTORAGETYPEStorage PolicyNamestoragepolicyDescriptionThe name of the storage policy.TypeStringDefault Value<empty>Valid ValuesAny valid storage policy name; seeGETALLSTORAGEPOLICY.SyntaxAny string.See also:SETSTORAGEPOLICYErasure Coding PolicyNameecpolicyDescriptionThe name of the erasure coding policy.TypeStringDefault Value<empty>Valid ValuesAny valid erasure coding policy name;SyntaxAny string.See also:ENABLEECPOLICYorDISABLEECPOLICYStart AfterNamestartAfterDescriptionThe last item returned in the liststatus batch.TypeStringDefault Value<empty>Valid ValuesAny valid file/directory name.SyntaxAny string.See also:LISTSTATUS_BATCH©            2008-2024
              Apache Software Foundation
            
                          -Privacy Policy.
        Apache Maven, Maven, Apache, the Apache feather logo, and the Apache Maven project logos are trademarks of The Apache Software Foundation.