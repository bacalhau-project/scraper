URL: https://docs.bacalhau.org/guides/write-a-config.yaml

Bacalhau Docsv.1.4.0v.1.3.0v.1.3.1v.1.3.2v.1.4.0GitHubSlackContactMoreGitHubSlackContactAsk or SearchCtrl+ KWelcomeGetting StartedHow Bacalhau WorksInstallationCreate NetworkHardware SetupContainer OnboardingDocker WorkloadsWebAssembly (Wasm) WorkloadsSetting UpRunning NodesNode OnboardingGPU InstallationJob selection policyAccess ManagementNode persistenceConnect StorageConfiguration ManagementConfiguring Transport Level SecurityLimits and TimeoutsTest Network LocallyBacalhau WebUIWorkload OnboardingContainerDocker Workload OnboardingWebAssembly (Wasm) WorkloadsBacalhau Docker ImageHow To Work With Custom Containers in BacalhauPythonBuilding and Running Custom Python ContainerRunning Pandas on BacalhauRunning a Python ScriptRunning Jupyter Notebooks on BacalhauScripting Bacalhau with PythonR (language)Building and Running your Custom R Containers on BacalhauRunning a Simple R Script on BacalhauRun CUDA programs on BacalhauRunning a Prolog ScriptReading Data from Multiple S3 Buckets using BacalhauRunning Rust programs as WebAssembly (WASM)Generate Synthetic Data using Sparkov Data Generation techniqueData IngestionCopy Data from URL to Public StoragePinning DataRunning a Job over S3 dataNetworking InstructionsAccessing the Internet from JobsUtilizing NATS.io within BacalhauGPU Workloads SetupAutomatic Update CheckingMarketplace DeploymentsGoogle Cloud MarketplaceGuidesWrite a config.yamlWrite a SpecConfigExamplesData EngineeringUsing Bacalhau with DuckDBEthereum Blockchain Analysis with Ethereum-ETL and BacalhauConvert CSV To Parquet Or AvroSimple Image ProcessingOceanography - Data ConversionVideo ProcessingModel InferenceEasyOCR (Optical Character Recognition) on BacalhauRunning Inference on Dolly 2.0 Model with Hugging FaceSpeech Recognition using WhisperStable Diffusion on a GPUStable Diffusion on a CPUObject Detection with YOLOv5 on BacalhauGenerate Realistic Images using StyleGAN3 and BacalhauStable Diffusion Checkpoint InferenceRunning Inference on a Model stored on S3Model TrainingTraining Pytorch Model with BacalhauTraining Tensorflow ModelStable Diffusion Dreambooth (Finetuning)Molecular DynamicsRunning BIDS Apps on BacalhauCoresets On BacalhauGenomics Data GenerationGromacs for AnalysisMolecular Simulation with OpenMM and BacalhauReferencesJobs GuideJob SpecificationJob TypesTask SpecificationEnginesDocker Engine SpecificationWebAssembly (WASM) Engine SpecificationPublishersIPFS Publisher SpecificationLocal Publisher SpecificationS3 Publisher SpecificationSourcesIPFS Source SpecificationLocal Source SpecificationS3 Source SpecificationURL Source SpecificationNetwork SpecificationInput Source SpecificationResources SpecificationResultPath SpecificationConstraint SpecificationLabels SpecificationMeta SpecificationJob TemplatesQueuing & TimeoutsJob QueuingTimeouts SpecificationJob ResultsStateCLI GuideSingle CLI commandsAgentAgent OverviewAgent AliveAgent NodeAgent VersionConfigConfig OverviewConfig Auto-ResourcesConfig DefaultConfig ListConfig SetJobJob OverviewJob DescribeJob ExecJob ExecutionsJob HistoryJob ListJob LogsJob RunJob StopNodeNode OverviewNode ApproveNode DeleteNode ListNode DescribeNode RejectCLI Commands OverviewCommand MigrationAPI GuideBacalhau API overviewBest PracticesAgent EndpointOrchestrator EndpointMigration APINode ManagementAuthentication & AuthorizationDatabase IntegrationDebuggingDebugging Failed JobsDebugging LocallyOpen Telemetry in BacalhauRunning locally in 'devstack'Setting up Dev EnvironmentHelp & FAQBacalhau FAQsRelease NotesGlossaryIntegrationsApache Airflow Provider for BacalhauLilypadBacalhau Python SDKObservability for WebAssembly WorkloadsCommunitySocial MediaStyle GuideWays to ContributePowered by GitBookWrite a config.yamlHow to write the config.yaml file to configure your nodesOn installation, Bacalhau creates a `.bacalhau` directory that includes a `config.yaml` file tailored for your specific settings. This configuration file is the central repository for custom settings for your Bacalhau nodes.When initializing a Bacalhau node, the system determines its configuration by following a specific hierarchy. First, it checks the default settings, then the `config.yaml` file, followed by environment variables, and finally, any command line flags specified during execution. Configurations are set and overridden in that sequence. This layered approach allows the  default Bacalhau settings to provide a baseline, while environment variables and command-line flags offer added flexibility. However, the `config.yaml` file offers a reliable way to predefine all necessary settings before node creation across environments, ensuring consistency and ease of management.Modifications to the `config.yaml` file are not dynamically applied to existing nodes. A restart of the Bacalhau node is required for any changes to take effect.Your `config.yaml` file starts off empty. However, you can see all available settings using the following commandCopybacalhauconfiglistThis command showcases over a hundred configuration parameters related to users, security, metrics, updates, and node configuration, providing a comprehensive overview of the customization options available for your Bacalhau setup.Let’s go through the different options and how your configuration file is structured.Config.yaml StructureThe `bacalhau config list` command displays your configuration paths, segmented with periods to indicate each part you are configuring.Consider these configuration settings; `user.installationid`, `node.name`, `node.compute.executionstore.path`, `node.compute.executionstore.type`, `node.requester.jobstore.type`, and `node.requester.jobstore.path`. These settings help set an identifier tag for your Bacalhau user and node then establish storage options for your jobs and execution results.In your `config.yaml`, these settings will be formatted like this:Copynode:compute:executionstore:Type:BoltDBPath:/home/soot3/.bacalhau/compute_store/executions.dbname:n-716571d4-b6bd-40ed-a9b1-fd25662979adrequester:jobstore:Type:BoltDBPath:/home/soot3/.bacalhau/orchestrator_store/jobs.dbuser:installationid:60d292e8-58f7-4019-8031-90955c431a26Your yaml file hierarchy follows the period delineation - node > compute > executionstore > type for `node.compute.executionstore.type`.Configuration OptionsHere are your Bacalhau configuration options in alphabetical orderConfiguration OptionDescriptionauth.accesspolicypathString path to where your security policy is storedauth.methodsSet authentication method for your Bacalhau networkauth.tokenspathString path to where your security token is storedmetrics.eventtracerpathFor observability, the path to your event trace recordsnode.allowlistedlocalpathsA list of the local paths that should be allowed to be mounted into jobs within your networknode.clientapi.clienttls.cacertThe location of your node client’s chosen Certificate Authority certificate file when self-signed certificates are usednode.clientapi.clienttls.insecureBoolean binary indicating if the client TLS is insecure, when true instructs the client to use HTTPS (TLS), but not to attempt to verify the certificatenode.clientapi.clienttls.usetlsBoolean indicating if TLS should be used for client connectionsnode.clientapi.hostThe host for the client and server to communicate on (via REST). Ignored if BACALHAU_API_HOST environment variable is setnode.clientapi.portThe port for the client and server to communicate on (via REST). Ignored if BACALHAU_API_PORT environment variable is setnode.clientapi.tls.autocertHostname for a certificate to be automatically obtained via ACMEnode.clientapi.tls.autocertcachepathThe directory where the autocert process will cache certificates to avoid rate limitsnode.clientapi.tls.selfsignedBoolean indicating if a self-signed security certificate is being usednode.clientapi.tls.servercertificateThe location of a TLS certificate to be used by the requester to serve TLS requestsnode.clientapi.tls.serverkeyThe TLS server key to match the certificate to allow the requester to serve TLSnode.compute.capacity.defaultjobresourcelimits.cpuSets default CPU resource limits for jobs on your Compute nodenode.compute.capacity.defaultjobresourcelimits.diskSets default disk resource limits for jobs on your Compute nodenode.compute.capacity.defaultjobresourcelimits.gpuSets default GPU resource limits for jobs on your Compute nodenode.compute.capacity.defaultjobresourcelimits.memorySets default memory resource limits for jobs on your Compute nodenode.compute.capacity.ignorephysicalresourcelimitsBoolean that tells the compute node to ignore its physical resource limits when truenode.compute.capacity.jobresourcelimits.cpuSets the specific per job amount of CPU the system can use at one timenode.compute.capacity.jobresourcelimits.diskSets the specific per job amount of disk the system can use at one timenode.compute.capacity.jobresourcelimits.gpuSets the specific per job amount of GPU the system can use at one timenode.compute.capacity.jobresourcelimits.memorySets the specific per job amount of memory the system can use at one timenode.compute.capacity.totalresourcelimits.cpuTotal amount of CPU the system can use at one time in aggregate for all jobsnode.compute.capacity.totalresourcelimits.diskTotal amount of disk the system can use at one time in aggregate for all jobsnode.compute.capacity.totalresourcelimits.gpuTotal amount of GPU the system can use at one time in aggregate for all jobsnode.compute.capacity.totalresourcelimits.memoryTotal amount of memory the system can use at one time in aggregate for all jobsnode.compute.controlplanesettings.heartbeatfrequencyHow often the compute node will send a heartbeat to the requester node to let it know that the compute node is still alive. This should be less than the requester's configured heartbeat timeout to avoid flapping.node.compute.controlplanesettings.heartbeattopicThis is the pubsub topic that the compute node will use to send heartbeats to the requester nodenode.compute.controlplanesettings.infoupdatefrequencyThe frequency with which the compute node will send node info (including current labels) to the controlling requester nodenode.compute.controlplanesettings.resourceupdatefrequencyHow often the compute node will send current resource availability to the requester nodenode.compute.executionstore.pathA metadata store of job executions handled by the current compute nodenode.compute.executionstore.typeThe type of store used by the compute nodenode.compute.jobselection.acceptnetworkedjobsBoolean signifying if jobs that specify networking should be acceptednode.compute.jobselection.localitySets job selection policy based on where the data for the job is located. ‘local’ or ‘anywhere’node.compute.jobselection.probeexecUse the result of an executed external program to decide if a job should be accepted. Overrides data locality settingsnode.compute.jobselection.probehttpUse the result of a HTTP POST to decide if a job should be accepted. Overrides data locality settingsnode.compute.jobselection.rejectstatelessjobsBoolean signifying if jobs that don’t specify any data should be rejectednode.compute.jobtimeouts.defaultjobexecutiontimeoutDefault value for job execution timeouts on your current compute node. It will be assigned to jobs with no timeout requirement definednode.compute.jobtimeouts.jobexecutiontimeoutclientidbypasslistList of clients that are allowed to bypass the job execution timeout checknode.compute.jobtimeouts.jobnegotiationtimeoutDefault timeout value to hold a bid for a jobnode.compute.jobtimeouts.maxjobexecutiontimeoutDefault value for the maximum execution timeout this compute node supports. Jobs with higher timeout requirements will not be bid onnode.compute.jobtimeouts.minjobexecutiontimeoutDefault value for the minimum execution timeout this compute node supports. Jobs with lower timeout requirements will not be bid onnode.compute.localpublisher.addressThe address for the local publisher's server to bind tonode.compute.localpublisher.directoryThe directory where the local publisher will store contentnode.compute.localpublisher.portThe port for the local publisher's server to bind to (default: 6001)node.compute.logging.logrunningexecutionsintervalThe duration interval your compute node should generate logs on the running job executionsnode.compute.logstreamconfig.channelbuffersizeHow many messages to buffer in the log stream channel, per streamnode.compute.manifestcache.durationThe default time-to-live for each record in the manifest cachenode.compute.manifestcache.frequencyThe frequency that the checks for stale records is performednode.compute.manifestcache.sizeSpecifies the number of items that can be held in the manifest cachenode.computestoragepathPath to the storage repository for your execution data within your compute nodenode.disabledfeatures.enginesList of Engine types to disablenode.disabledfeatures.publishersList of Publisher types to disablenode.disabledfeatures.storagesList of Storage types to disablenode.downloadurlrequestretriesNumber of retries attempted for the download requests in your nodenode.downloadurlrequesttimeoutDuration before a timeout when processing download requestsnode.executorpluginpathPath to the directory for your executor pluginsnode.ipfs.connectThe ipfs host multiaddress to connect to, otherwise an in-process IPFS node will be created if not setnode.labelsList of labels to apply to the node that can be used for node selection and filteringnode.loggingmodeSwitch between available logging formats for your node - default, station, json, combined, eventnode.nameThe name of the node. If not set, the node name will be generated automatically based on the chosen name providernode.nameproviderThe name provider to use to generate the node name, if no name is setnode.network.advertisedaddressAddress to advertise to compute nodes to connect tonode.network.authsecretAuthentication secret for network connectionsnode.network.cluster.advertisedaddressAddress to advertise to other orchestrators to connect tonode.network.cluster.nameName of the cluster to joinnode.network.cluster.peersComma-separated list of other orchestrators to connect to form a clusternode.network.cluster.portPort to listen for connections from other orchestrators to form a clusternode.network.orchestratorsComma-separated list of orchestrators to connect to. Applies to compute nodesnode.network.portPort to listen for connections from other nodes. Applies to orchestrator nodesnode.network.storedirDirectory that the network can use for storagenode.requester.controlplanesettings.heartbeatcheckfrequencyThis setting is the time period after which a compute node is considered to be unresponsive. If the compute node misses two of these frequencies, it will be marked as unknown. The compute node should have a frequency setting less than this one to ensure that it does not keep switching between unknown and active too frequentlynode.requester.controlplanesettings.heartbeattopicThis is the pubsub topic that the compute node will use to send heartbeats to the requester nodenode.requester.controlplanesettings.nodedisconnectedafterThis is the time period after which a compute node is considered to be disconnected. If the compute node does not deliver a heartbeat everyNodeDisconnectedAfterthen it is considered disconnectednode.requester.defaultpublisherA default publisher to apply to all jobs without a publishernode.requester.evaluationbroker.evalbrokerinitialretrydelayInitial retry delay for the evaluation brokernode.requester.evaluationbroker.evalbrokermaxretrycountMaximum retry count for the evaluation brokernode.requester.evaluationbroker.evalbrokersubsequentretrydelaySubsequent retry delay for the evaluation brokernode.requester.evaluationbroker.evalbrokervisibilitytimeoutVisibility timeout for the evaluation brokernode.requester.externalverifierhookURL specifying where to send external verification requests tonode.requester.failureinjectionconfig.isbadactorBoolean indicating if failure injection config is a bad actornode.requester.housekeepingbackgroundtaskintervalDuration between Bacalhau housekeeping runsnode.requester.jobdefaults.executiontimeoutThe maximum amount of time a task is allowed to run in seconds. Zero means no timeout, such as for a daemon tasknode.requester.jobselectionpolicy.acceptnetworkedjobsBoolean signifying if jobs that specify networking should be acceptednode.requester.jobselectionpolicy.localitySets job selection policy based on where the data for the job is located. ‘local’ or ‘anywhere’node.requester.jobselectionpolicy.probeexecUse the result of an executed external program to decide if a job should be accepted. Overrides data locality settingsnode.requester.jobselectionpolicy.probehttpUse the result of a HTTP POST to decide if a job should be accepted. Overrides data locality settingsnode.requester.jobselectionpolicy.rejectstatelessjobsBoolean signifying if jobs that don’t specify any data should be rejectednode.requester.jobstore.pathThe path used for the requester job store store when using BoltDBnode.requester.jobstore.typeThe type of job store used by the requester node (BoltDB)node.requester.manualnodeapprovalBoolean signifying if new nodes should only be manually approved to your network. Default falsenode.requester.nodeinfostorettlSets the duration for which node information is retained in the node info store after which it is automatically removed from the storenode.requester.noderankrandomnessrangeDescription missingnode.requester.overaskforbidsfactorNumber of compute nodes the requester node should ask to bid for a job when deciding on schedulingnode.requester.scheduler.nodeoversubscriptionfactorNumerical value representing the sum of a node’s total active capacity and queue capacity. With a default value of 1.5, your node can handle 50% more of its total capacity before being excluded from job queueing consideration.node.requester.scheduler.queuebackoffThe interval between retry attempts by the requester node to assign queued jobsnode.requester.storageprovider.s3.presignedurldisabledBoolean deciding if a secure S3 URL should be generated and used. Default false, Disabled if true.node.requester.storageprovider.s3.presignedurlexpirationDefined expiration interval for your secure S3 urlsnode.requester.tagcache.durationThe default time-to-live for each record in the tag cachenode.requester.tagcache.frequencyThe frequency that the checks for stale records is performednode.requester.tagcache.sizeSpecifies the number of items that can be held in the tag cachenode.requester.translationenabledWhether jobs should be translated at the requester node or not. Default: falsenode.requester.worker.workercountNumber of workers that should be generated under your requester nodenode.requester.worker.workerevaldequeuebasebackoffDefault time for your workers to be taken off the evaluation list for new tasksnode.requester.worker.workerevaldequeuemaxbackoffMaximum time for your workers to be taken off the evaluation list for new tasksnode.requester.worker.workerevaldequeuetimeoutTime for your workers to be evaluated within the queuenode.serverapi.clienttls.cacertThe location of your server’s chosen Certificate Authority certificate file when self-signed certificates are usednode.serverapi.clienttls.insecureBoolean binary indicating if the server TLS is insecure, when true instructs the server to use HTTPS (TLS), but not to attempt to verify the certificatenode.serverapi.clienttls.usetlsBoolean indicating if TLS should be used for server connectionsnode.serverapi.hostThe host to serve onnode.serverapi.portThe port to serve onnode.serverapi.tls.autocertSpecifies a host name for which ACME is used to obtain a TLS Certificate. Using this option results in the API serving over HTTPSnode.serverapi.tls.autocertcachepathThe directory where the autocert process will cache certificates to avoid rate limitsnode.serverapi.tls.selfsignedBoolean indicating if a self-signed security certificate is being usednode.serverapi.tls.servercertificateSpecifies a TLS certificate file to be used by the requester nodenode.serverapi.tls.serverkeySpecifies a TLS key file matching the certificate to be used by the requester nodenode.strictversionmatchDescription missingnode.typeWhether the node is a compute, requester or bothnode.volumesizerequesttimeoutDuration before a timeout when parsing a node’s volume size.node.webui.enabledWhether to start the web UI alongside the bacalhau nodenode.webui.portThe port number to listen on for web-ui connectionsupdate.checkfrequencyThe frequency with which your system checks for version updatesupdate.checkstatepathVersion state is stored in this directoryupdate.skipchecksBoolean, checks are skipped on your system if trueuser.installationidString tag applied to your user on installationuser.keypathPath to user authentication key. Client key will be used if a private key is not specifiedPreviousGoogle Cloud MarketplaceNextWrite a SpecConfigLast updated1 month agoOn this pageConfig.yaml StructureConfiguration OptionsWas this helpful?Edit on GitHubExport as PDFGet SupportExpansoSupportUse CasesDistributed ETLEdge MLDistributed Data WarehousingFlett ManagementAbout UsWho we areWhat we valueNews & BlogBlogNewsExpanso (2024). All Rights Reserved.