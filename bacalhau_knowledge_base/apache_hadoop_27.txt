URL: http://hadoop.apache.org/docs/r3.3.5/index.html

Apache>Hadoop>
        Apache Hadoop 3.3.5Wiki|git| Last Published: 2023-03-15
               | Version: 3.3.5GeneralOverviewSingle Node SetupCluster SetupCommands ReferenceFileSystem ShellCompatibility SpecificationDownstream Developer's GuideAdmin Compatibility GuideInterface ClassificationFileSystem SpecificationCommonCLI Mini ClusterFair Call QueueNative LibrariesProxy UserRack AwarenessSecure ModeService Level AuthorizationHTTP AuthenticationCredential Provider APIHadoop KMSTracingUnix Shell GuideRegistryHDFSArchitectureUser GuideCommands ReferenceNameNode HA With QJMNameNode HA With NFSObserver NameNodeFederationViewFsViewFsOverloadSchemeSnapshotsEdits ViewerImage ViewerPermissions and HDFSQuotas and HDFSlibhdfs (C API)WebHDFS (REST API)HttpFSShort Circuit Local ReadsCentralized Cache ManagementNFS GatewayRolling UpgradeExtended AttributesTransparent EncryptionMultihomingStorage PoliciesMemory Storage SupportSynthetic Load GeneratorErasure CodingDisk BalancerUpgrade DomainDataNode AdminRouter FederationProvided StorageMapReduceTutorialCommands ReferenceCompatibility with 1.xEncrypted ShufflePluggable Shuffle/SortDistributed Cache DeploySupport for YARN Shared CacheMapReduce REST APIsMR Application MasterMR History ServerYARNArchitectureCommands ReferenceCapacity SchedulerFair SchedulerResourceManager RestartResourceManager HAResource ModelNode LabelsNode AttributesWeb Application ProxyTimeline ServerTimeline Service V.2Writing YARN ApplicationsYARN Application SecurityNodeManagerRunning Applications in Docker ContainersRunning Applications in runC ContainersUsing CGroupsSecure ContainersReservation SystemGraceful DecommissionOpportunistic ContainersYARN FederationShared CacheUsing GPUUsing FPGAPlacement ConstraintsYARN UI2YARN REST APIsIntroductionResource ManagerNode ManagerTimeline ServerTimeline Service V.2YARN ServiceOverviewQuickStartConceptsYarn Service APIService DiscoverySystem ServicesHadoop Compatible File SystemsAliyun OSSAmazon S3Azure Blob StorageAzure Data Lake StorageTencent COSAuthOverviewExamplesConfigurationBuildingToolsHadoop StreamingHadoop ArchivesHadoop Archive LogsDistCpGridMixRumenResource Estimator ServiceScheduler Load SimulatorHadoop BenchmarkingDynamometerReferenceChangelog and Release NotesJava API docsUnix Shell APIMetricsConfigurationcore-default.xmlhdfs-default.xmlhdfs-rbf-default.xmlmapred-default.xmlyarn-default.xmlkms-default.xmlhttpfs-default.xmlDeprecated PropertiesApache Hadoop 3.3.5Apache Hadoop 3.3.5 is an update to the Hadoop 3.3.x release branch.Overview of ChangesUsers are encouraged to read the full set of release notes. This page provides an overview of the major changes.Azure ABFS: Critical Stream Prefetch FixThe abfs has a critical bug fixHADOOP-18546.ABFS. Disable purging list of in-progress reads in abfs stream close().All users of the abfs connector in hadoop releases 3.3.2+ MUST either upgrade or disable prefetching by settingfs.azure.readaheadqueue.depthto0Consult the parent JIRAHADOOP-18521ABFS ReadBufferManager buffer sharing across concurrent HTTP requestsfor root cause analysis, details on what is affected, and mitigations.Vectored IO APIHADOOP-18103.High performance vectored read API in HadoopThePositionedReadableinterface has now added an operation for Vectored IO (also known as Scatter/Gather IO):void readVectored(List<? extends FileRange> ranges, IntFunction<ByteBuffer> allocate)All the requested ranges will be retrieved into the supplied byte buffers -possibly asynchronously, possibly in parallel, with results potentially coming in out-of-order.The default implementation uses a series ofreadFully()calls, so delivers equivalent performance.The local filesystem uses java native IO calls for higher performance reads thanreadFully().The S3A filesystem issues parallel HTTP GET requests in different threads.Benchmarking of enhanced Apache ORC and Apache Parquet clients throughfile://ands3a://show significant improvements in query performance.Further Reading: *FsDataInputStream. *Hadoop Vectored IO: Your Data Just Got Faster!Apachecon 2022 talk.Mapreduce: Manifest Committer for Azure ABFS and google GCSThe newIntermediate Manifest Committeruses a manifest file to commit the work of successful task attempts, rather than renaming directories. Job commit is matter of reading all the manifests, creating the destination directories (parallelized) and renaming the files, again in parallel.This is both fast and correct on Azure Storage and Google GCS, and should be used there instead of the classic v1/v2 file output committers.It is also safe to use on HDFS, where it should be faster than the v1 committer. It is however optimized for cloud storage where list and rename operations are significantly slower; the benefits may be less.More details are available in themanifest committer. documentation.HDFS: Dynamic Datanode ReconfigurationHDFS-16400, HDFS-16399, HDFS-16396, HDFS-16397, HDFS-16413, HDFS-16457.A number of Datanode configuration options can be changed without having to restart the datanode. This makes it possible to tune deployment configurations without cluster-wide Datanode Restarts.SeeDataNode.javafor the list of dynamically reconfigurable attributes.Transitive CVE fixesA lot of dependencies have been upgraded to address recent CVEs. Many of the CVEs were not actually exploitable through the Hadoop so much of this work is just due diligence. However applications which have all the library is on a class path may be vulnerable, and the ugprades should also reduce the number of false positives security scanners report.We have not been able to upgrade every single dependency to the latest version there is. Some of those changes are fundamentally incompatible. If you have concerns about the state of a specific library, consult the Apache JIRA issue tracker to see if an issue has been filed, discussions have taken place about the library in question, and whether or not there is already a fix in the pipeline.Please don’t file new JIRAs about dependency-X.Y.Z having a CVE without searching for any existing issue firstAs an open-source project, contributions in this area are always welcome, especially in testing the active branches, testing applications downstream of those branches and of whether updated dependencies trigger regressions.Security AdvisoryHadoop HDFS is a distributed filesystem allowing remote callers to read and write data.Hadoop YARN is a distributed job submission/execution engine allowing remote callers to submit arbitrary work into the cluster.Unless a Hadoop cluster is deployed withcaller authentication with Kerberos, anyone with network access to the servers has unrestricted access to the data and the ability to run whatever code they want in the system.In production, there are generally three deployment patterns which can, with care, keep data and computing resources private. 1. Physical cluster:configure Hadoop security, usually bonded to the enterprise Kerberos/Active Directory systems. Good. 1. Cloud: transient or persistent single or multiple user/tenant cluster with private VLANand security. Good. ConsiderApache Knoxfor managing remote access to the cluster. 1. Cloud: transient single user/tenant cluster with private VLANand no security at all. Requires careful network configuration as this is the sole means of securing the cluster.. ConsiderApache Knoxfor managing remote access to the cluster.If you deploy a Hadoop cluster in-cloud without security, and without configuring a VLAN to restrict access to trusted users, you are implicitly sharing your data and computing resources with anyone with network accessIf you do deploy an insecure cluster this way then port scanners will inevitably find it and submit crypto-mining jobs. If this happens to you, please do not report this as a CVE or security issue: it isutterly predictable. Secureyour clusterif you want to remain exclusivelyyour cluster.Finally, if you are using Hadoop as a service deployed/managed by someone else, do determine what security their products offer and make sure it meets your requirements.Getting StartedThe Hadoop documentation includes the information you need to get started using Hadoop. Begin with theSingle Node Setupwhich shows you how to set up a single-node Hadoop installation. Then move on to theCluster Setupto learn how to set up a multi-node Hadoop installation.Before deploying Hadoop in production, readHadoop in Secure Mode, and follow its instructions to secure your cluster.©            2008-2023
              Apache Software Foundation
            
                          -Privacy Policy.
        Apache Maven, Maven, Apache, the Apache feather logo, and the Apache Maven project logos are trademarks of The Apache Software Foundation.