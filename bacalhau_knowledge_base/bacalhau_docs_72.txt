URL: https://docs.bacalhau.org/examples/model-inference/object-detection-with-yolov5-on-bacalhau

Bacalhau Docsv.1.4.0v.1.3.0v.1.3.1v.1.3.2v.1.4.0GitHubSlackContactMoreGitHubSlackContactAsk or SearchCtrl+ KWelcomeGetting StartedHow Bacalhau WorksInstallationCreate NetworkHardware SetupContainer OnboardingDocker WorkloadsWebAssembly (Wasm) WorkloadsSetting UpRunning NodesNode OnboardingGPU InstallationJob selection policyAccess ManagementNode persistenceConnect StorageConfiguration ManagementConfiguring Transport Level SecurityLimits and TimeoutsTest Network LocallyBacalhau WebUIWorkload OnboardingContainerDocker Workload OnboardingWebAssembly (Wasm) WorkloadsBacalhau Docker ImageHow To Work With Custom Containers in BacalhauPythonBuilding and Running Custom Python ContainerRunning Pandas on BacalhauRunning a Python ScriptRunning Jupyter Notebooks on BacalhauScripting Bacalhau with PythonR (language)Building and Running your Custom R Containers on BacalhauRunning a Simple R Script on BacalhauRun CUDA programs on BacalhauRunning a Prolog ScriptReading Data from Multiple S3 Buckets using BacalhauRunning Rust programs as WebAssembly (WASM)Generate Synthetic Data using Sparkov Data Generation techniqueData IngestionCopy Data from URL to Public StoragePinning DataRunning a Job over S3 dataNetworking InstructionsAccessing the Internet from JobsUtilizing NATS.io within BacalhauGPU Workloads SetupAutomatic Update CheckingMarketplace DeploymentsGoogle Cloud MarketplaceGuidesWrite a config.yamlWrite a SpecConfigExamplesData EngineeringUsing Bacalhau with DuckDBEthereum Blockchain Analysis with Ethereum-ETL and BacalhauConvert CSV To Parquet Or AvroSimple Image ProcessingOceanography - Data ConversionVideo ProcessingModel InferenceEasyOCR (Optical Character Recognition) on BacalhauRunning Inference on Dolly 2.0 Model with Hugging FaceSpeech Recognition using WhisperStable Diffusion on a GPUStable Diffusion on a CPUObject Detection with YOLOv5 on BacalhauGenerate Realistic Images using StyleGAN3 and BacalhauStable Diffusion Checkpoint InferenceRunning Inference on a Model stored on S3Model TrainingTraining Pytorch Model with BacalhauTraining Tensorflow ModelStable Diffusion Dreambooth (Finetuning)Molecular DynamicsRunning BIDS Apps on BacalhauCoresets On BacalhauGenomics Data GenerationGromacs for AnalysisMolecular Simulation with OpenMM and BacalhauReferencesJobs GuideJob SpecificationJob TypesTask SpecificationEnginesDocker Engine SpecificationWebAssembly (WASM) Engine SpecificationPublishersIPFS Publisher SpecificationLocal Publisher SpecificationS3 Publisher SpecificationSourcesIPFS Source SpecificationLocal Source SpecificationS3 Source SpecificationURL Source SpecificationNetwork SpecificationInput Source SpecificationResources SpecificationResultPath SpecificationConstraint SpecificationLabels SpecificationMeta SpecificationJob TemplatesQueuing & TimeoutsJob QueuingTimeouts SpecificationJob ResultsStateCLI GuideSingle CLI commandsAgentAgent OverviewAgent AliveAgent NodeAgent VersionConfigConfig OverviewConfig Auto-ResourcesConfig DefaultConfig ListConfig SetJobJob OverviewJob DescribeJob ExecJob ExecutionsJob HistoryJob ListJob LogsJob RunJob StopNodeNode OverviewNode ApproveNode DeleteNode ListNode DescribeNode RejectCLI Commands OverviewCommand MigrationAPI GuideBacalhau API overviewBest PracticesAgent EndpointOrchestrator EndpointMigration APINode ManagementAuthentication & AuthorizationDatabase IntegrationDebuggingDebugging Failed JobsDebugging LocallyOpen Telemetry in BacalhauRunning locally in 'devstack'Setting up Dev EnvironmentHelp & FAQBacalhau FAQsRelease NotesGlossaryIntegrationsApache Airflow Provider for BacalhauLilypadBacalhau Python SDKObservability for WebAssembly WorkloadsCommunitySocial MediaStyle GuideWays to ContributePowered by GitBookObject Detection with YOLOv5 on BacalhauIntroduction​The identification and localization of objects in images and videos is a computer vision task called object detection. Several algorithms have emerged in the past few years to tackle the problem. One of the most popular algorithms to date for real-time object detection isYOLO (You Only Look Once), initially proposedby Redmond et al.Traditionally, models like YOLO required enormous amounts of training data to yield reasonable results. People might not have access to such high-quality labeled data. Thankfully, open-source communities and researchers have made it possible to utilize pre-trained models to perform inference. In other words, you can use models that have already been trained on large datasets to perform object detection on your own data.Bacalhau is a highly scalable decentralized computing platform and is well suited to running massive object detection jobs. In this example, you can take advantage of the GPUs available on the Bacalhau Network and perform an end-to-end object detection inference, using theYOLOv5 Docker Image developed by Ultralytics.TL;DR​Load your dataset into S3/IPFS, specify it and pre-trained weights via the--inputflags, choose a suitable container, specify the command and path to save the results - done!Prerequisite​To get started, you need to install the Bacalhau client, see more informationhereTest Run with Sample Data​To get started, let's run a test job with a small sample dataset that is included in the YOLOv5 Docker Image. This will give you a chance to familiarise yourself with the process of running a job on Bacalhau.In addition to the usual Bacalhau flags, you will also see example of using the--gpu 1flag in order to specify the use of a GPU.Remember that by default Bacalhau does not provide any network connectivity when running a job. So you need to either provide all assets at job submission time, or use the--network=fullor--network=httpflags to access the data at task time. See theInternet Accesspage for more detailsThe model requires pre-trained weights to run and by default downloads them from within the container. Bacalhau jobs don't have network access so we will pass in the weights at submission time, saving them to/usr/src/app/yolov5s.pt. You may also provide your own weights here.The container has its own options that we must specify:--inputto select which pre-trained weights you desire with details on theyolov5 release page--projectspecifies the output volume that the model will save its results to. Bacalhau defaults to using/outputsas the output directory, so we save it there.For more container flags refer to theyolov5/detect.pyfile in theYOLO repository.One final additional hack that we have to do is move the weights file to a location with the standard name. As of writing this, Bacalhau downloads the file to a UUID-named file, which the model is not expecting. This is because GitHub 302 redirects the request to a random file in its backend.Structure of the command​Some of the jobs presented in the Examples section may require more resources than are currently available on the demo network. Considerstarting your own networkor running less resource-intensive jobs on the demo networkexport JOB_ID=$( ... )exports the job ID as environment variableThe--gpu 1flag is set to specify hardware requirements, a GPU is needed to run such a jobThe--timeoutflag is set to make sure that if the job is not completed in the specified time, it will be terminatedThe--waitflag is set to wait for the job to complete before returnThe--wait-timeout-secsflag is set together with--waitto define how long should app wait for the job to completeThe--id-onlyflag is set to print only job idThe--inputflags are used to specify the sources of input data-- /bin/bash -c 'find /inputs -type f -exec cp {} /outputs/yolov5s.pt \; ; python detect.py --weights /outputs/yolov5s.pt --source $(pwd)/data/images --project /outputs'tells the model where to find input data and where to write outputCopyexportJOB_ID=$(bacalhaudockerrun\--gpu1\--timeout3600\--wait \--wait-timeout-secs3600\--id-only \--inputhttps://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt\ultralytics/yolov5:v6.2 \-- /bin/bash -c 'find /inputs -type f -exec cp {} /outputs/yolov5s.pt \; ; python detect.py --weights /outputs/yolov5s.pt --source $(pwd)/data/images --project /outputs')This should output a UUID (like59c59bfb-4ef8-45ac-9f4b-f0e9afd26e70), which will be stored in the environment variableJOB_ID. This is the ID of the job that was created. You can check the status of the job using the commands below.Declarative job description​The same job can be presented in thedeclarativeformat. In this case, the description will look like this:Copyname:Object Detection with YOLOv5type:batchcount:1tasks:-name:My main taskEngine:type:dockerparams:Image:ultralytics/yolov5:v6.2Entrypoint:-/bin/bashParameters:--c- "find /inputs -type f -exec cp {} /outputs/yolov5s.pt \\; ; python detect.py --weights /outputs/yolov5s.pt --source $(pwd)/data/images --project /outputs"Publisher:Type:ipfsResultPaths:-Name:outputsPath:/outputsInputSources:-Source:Type:"urlDownload"Params:URL:"https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt"Target:"/inputs"Checking the State of your Jobs​Job status: You can check the status of the job usingbacalhau job list:Copybacalhaujoblist--id-filter${JOB_ID}When it saysCompleted, that means the job is done, and we can get the results.Job information: You can find out more information about your job by usingbacalhau job describe:Copybacalhaujobdescribe${JOB_ID}Job download: You can download your job results directly by usingbacalhau job get. Alternatively, you can choose to create a directory to store your results. In the command below, we created a directory and downloaded our job output to be stored in that directory.Copyrm-rfresults&&mkdirresultsbacalhaujobget${JOB_ID}--output-dirresultsViewing Output​After the download has finished we can see the results in theresults/outputs/expfolder.Using Custom Images as an Input​Now let's use some custom images. First, you will need to ingest your images onto IPFS or S3 storage. For more information about how to do that see thedata ingestionsection.This example will use theCyclist Dataset for Object Detection | Kaggledataset.We have already uploaded this dataset to the IPFS storage under the CID:bafybeicyuddgg4iliqzkx57twgshjluo2jtmlovovlx5lmgp5uoh3zrvpm. You can browse to this dataset viaa HTTP IPFS proxy.Let's run a the same job again, but this time use the images above.CopyexportJOB_ID=$(bacalhaudockerrun\--gpu1\--timeout3600\--wait \--wait-timeout-secs3600\--id-only \--inputhttps://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt\--inputipfs://bafybeicyuddgg4iliqzkx57twgshjluo2jtmlovovlx5lmgp5uoh3zrvpm:/datasets\ultralytics/yolov5:v6.2 \-- /bin/bash -c 'find /inputs -type f -exec cp {} /outputs/yolov5s.pt \; ; python detect.py --weights /outputs/yolov5s.pt --source /datasets --project /outputs')Just as in the example above, this should output a UUID, which will be stored in the environment variableJOB_ID. You can check the status of the job using the commands below.To check the state of the job and view job output refer to theinstructions above.Support​If you have questions or need support or guidance, please reach out to theBacalhau team via Slack(#generalchannel).PreviousStable Diffusion on a CPUNextGenerate Realistic Images using StyleGAN3 and BacalhauLast updated1 month agoOn this pageIntroduction​TL;DR​Prerequisite​Test Run with Sample Data​Structure of the command​Declarative job description​Checking the State of your Jobs​Viewing Output​Using Custom Images as an Input​Support​Was this helpful?Edit on GitHubExport as PDFGet SupportExpansoSupportUse CasesDistributed ETLEdge MLDistributed Data WarehousingFlett ManagementAbout UsWho we areWhat we valueNews & BlogBlogNewsExpanso (2024). All Rights Reserved.