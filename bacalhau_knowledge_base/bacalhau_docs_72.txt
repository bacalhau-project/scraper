Source: bacalhau_docs
URL: https://docs.bacalhau.org/examples/data-engineering/convert-csv-to-parquet-or-avro

Converting from CSV to parquet or avro reduces the size of the file and allows for faster read and write speeds. With Bacalhau, you can convert your CSV files stored on ipfs or on the web without the need to download files and install dependencies locally.
In this example tutorial we will convert a CSV file from a URL to parquet format and save the converted parquet file to IPFS
Prerequisites
To get started, you need to install the Bacalhau client, see more information here
-i ipfs://QmTAQMGiSv9xocaB4PUCT5nSBHrf9HZrYj21BAZ5nMTY2W: CIDs to use on the job. Mounts them at '/inputs' in the execution.
jsacex/csv-to-arrow-or-parque: the name and the tag of the docker image we are using
../inputs/transactions.csv : path to input dataset
/outputs/transactions.parquet parquet: path to the output
python3 src/converter.py: execute the script
When a job is submitted, Bacalhau prints out the related job_id. We store that in an environment variable so that we can reuse it later on.
Declarative job description
The same job can be presented in the declarative format. In this case, the description will look like this:
name:Convert CSV To Parquet Or Avrotype:batchcount:1tasks: - name:My main taskEngine:type:dockerparams:Image:jsacex/csv-to-arrow-or-parquetEntrypoint: - /bin/bashParameters: - -c - python3 src/converter.py ../inputs/transactions.csv ../outputs/transactions.parquet parquetPublisher:Type:ipfsResultPaths: - Name:outputsPath:/outputsInputSources: - Target:"/inputs"Source:Type:"ipfs"Params:CID:"QmTAQMGiSv9xocaB4PUCT5nSBHrf9HZrYj21BAZ5nMTY2W"
The job description should be saved in .yaml format, e.g. convertcsv.yaml, and then run with the command:
bacalhaujobrunconvertcsv.yaml
Checking the State of your Jobs
Job status: You can check the status of the job using bacalhau job list.
bacalhaujoblist--id-filter ${JOB_ID}
When it says Published or Completed, that means the job is done, and we can get the results.
Job information: You can find out more information about your job by using bacalhau job describe.
bacalhaujobdescribe ${JOB_ID}
Job download: You can download your job results directly by using bacalhau job get. Alternatively, you can choose to create a directory to store your results. In the command below, we created a directory (results) and downloaded our job output to be stored in that directory.
rm-rfresults&&mkdir-presults# Temporary directory to store the resultsbacalhaujobget ${JOB_ID} --output-dirresults# Download the results
Viewing your Job Output
To view the file, run the following command:
lsresults/outputstransactions.parquet
Alternatively, you can do this:
import pandas as pdimport ospd.read_parquet('results/outputs/transactions.parquet')
Support
If you have questions or need support or guidance, please reach out to the Bacalhau team via Slack (#general channel).