URL: https://docs.bacalhau.org/examples/model-inference/stable-diffusion-on-a-cpu

Bacalhau Docsv.1.4.0v.1.3.0v.1.3.1v.1.3.2v.1.4.0GitHubSlackContactMoreGitHubSlackContactAsk or SearchCtrl+ KWelcomeGetting StartedHow Bacalhau WorksInstallationCreate NetworkHardware SetupContainer OnboardingDocker WorkloadsWebAssembly (Wasm) WorkloadsSetting UpRunning NodesNode OnboardingGPU InstallationJob selection policyAccess ManagementNode persistenceConnect StorageConfiguration ManagementConfiguring Transport Level SecurityLimits and TimeoutsTest Network LocallyBacalhau WebUIWorkload OnboardingContainerDocker Workload OnboardingWebAssembly (Wasm) WorkloadsBacalhau Docker ImageHow To Work With Custom Containers in BacalhauPythonBuilding and Running Custom Python ContainerRunning Pandas on BacalhauRunning a Python ScriptRunning Jupyter Notebooks on BacalhauScripting Bacalhau with PythonR (language)Building and Running your Custom R Containers on BacalhauRunning a Simple R Script on BacalhauRun CUDA programs on BacalhauRunning a Prolog ScriptReading Data from Multiple S3 Buckets using BacalhauRunning Rust programs as WebAssembly (WASM)Generate Synthetic Data using Sparkov Data Generation techniqueData IngestionCopy Data from URL to Public StoragePinning DataRunning a Job over S3 dataNetworking InstructionsAccessing the Internet from JobsUtilizing NATS.io within BacalhauGPU Workloads SetupAutomatic Update CheckingMarketplace DeploymentsGoogle Cloud MarketplaceGuidesWrite a config.yamlWrite a SpecConfigExamplesData EngineeringUsing Bacalhau with DuckDBEthereum Blockchain Analysis with Ethereum-ETL and BacalhauConvert CSV To Parquet Or AvroSimple Image ProcessingOceanography - Data ConversionVideo ProcessingModel InferenceEasyOCR (Optical Character Recognition) on BacalhauRunning Inference on Dolly 2.0 Model with Hugging FaceSpeech Recognition using WhisperStable Diffusion on a GPUStable Diffusion on a CPUObject Detection with YOLOv5 on BacalhauGenerate Realistic Images using StyleGAN3 and BacalhauStable Diffusion Checkpoint InferenceRunning Inference on a Model stored on S3Model TrainingTraining Pytorch Model with BacalhauTraining Tensorflow ModelStable Diffusion Dreambooth (Finetuning)Molecular DynamicsRunning BIDS Apps on BacalhauCoresets On BacalhauGenomics Data GenerationGromacs for AnalysisMolecular Simulation with OpenMM and BacalhauReferencesJobs GuideJob SpecificationJob TypesTask SpecificationEnginesDocker Engine SpecificationWebAssembly (WASM) Engine SpecificationPublishersIPFS Publisher SpecificationLocal Publisher SpecificationS3 Publisher SpecificationSourcesIPFS Source SpecificationLocal Source SpecificationS3 Source SpecificationURL Source SpecificationNetwork SpecificationInput Source SpecificationResources SpecificationResultPath SpecificationConstraint SpecificationLabels SpecificationMeta SpecificationJob TemplatesQueuing & TimeoutsJob QueuingTimeouts SpecificationJob ResultsStateCLI GuideSingle CLI commandsAgentAgent OverviewAgent AliveAgent NodeAgent VersionConfigConfig OverviewConfig Auto-ResourcesConfig DefaultConfig ListConfig SetJobJob OverviewJob DescribeJob ExecJob ExecutionsJob HistoryJob ListJob LogsJob RunJob StopNodeNode OverviewNode ApproveNode DeleteNode ListNode DescribeNode RejectCLI Commands OverviewCommand MigrationAPI GuideBacalhau API overviewBest PracticesAgent EndpointOrchestrator EndpointMigration APINode ManagementAuthentication & AuthorizationDatabase IntegrationDebuggingDebugging Failed JobsDebugging LocallyOpen Telemetry in BacalhauRunning locally in 'devstack'Setting up Dev EnvironmentHelp & FAQBacalhau FAQsRelease NotesGlossaryIntegrationsApache Airflow Provider for BacalhauLilypadBacalhau Python SDKObservability for WebAssembly WorkloadsCommunitySocial MediaStyle GuideWays to ContributePowered by GitBookStable Diffusion on a CPUIntroductionStable Diffusionis an open-source text-to-image model, which generates images from text. It's a cutting-edge alternative toDALL·E 2and uses theDiffusion Probabilistic Modelfor image generation. At the core the model generates graphics from text using aTransformer.This example demonstrates how to use stable diffusion online on a CPU and run it on the Bacalhau demo network. The first section describes the development of the code and the container. The second section demonstrates how to run the job using Bacalhau.This model generated the images presented on this page.TL;DR​Copybacalhaudockerrunghcr.io/bacalhau-project/examples/stable-diffusion-cpu:0.0.1\--pythondemo.py\--prompt"cod in space"\--output../outputs/cod.pngDevelopment​Theoriginaltext-to-image stable diffusion model was trained on a fleet of GPU machines, at great cost. To use this trained model for inference, you also need to run it on a GPU.However, this isn't always desired or possible. One alternative is to use a project calledOpenVINOfrom Intel that allows you to convert and optimize models from a variety of frameworks (and ONNX if your framework isn't directly supported) to run on asupportedIntel CPU. This is what we will do in this example.Heads up! This example takes about 10 minutes to generate an image on an average CPU. Whilst this demonstrates it is possible, it might not be practical.Prerequisites​In order to run this example you need:A Debian-flavoured Linux (although you might be able to get it working on the newest machines)DockerConverting Stable Diffusion to a CPU Model Using OpenVINO​First we convert the trained stable diffusion models so that they work efficiently on a CPU with OpenVINO. Choose the fine tuned version of Stable Diffusion you want to use. The example is quite complex, so we have created aseparate repositoryto host the code. This is a fork from thisGithub repository.In summary, the code downloads apre-optimized OpenVINO versionof theoriginalpre-trained stable diffusion model. This model leverages OpenAI'sCLIP transformerand is wrapped inside an OpenVINO runtime, which executes the model.The core code representing these tasks can be foundin the stable_diffusion_engine.py file. This is a mashup that creates a pipeline necessary to tokenize the text and run the stable diffusion model. This boilerplate could be simplified by leveraging the more recent version of thediffusers library. But let's continue.Install Dependencies​Note that these dependencies are only known to work on Ubuntu-based x64 machines.Copysudoapt-getupdatesudoapt-getinstall-ylibgl1libglib2.0-0git-lfsClone the Repository and Dependencies​The following commands clone the example repository, and other required repositories, and install the Python dependencies.Copygitclonehttps://github.com/js-ts/stable_diffusion.openvinocdstable_diffusion.openvinogitlfsinstallgitclonehttps://huggingface.co/openai/clip-vit-large-patch14gitclonehttps://huggingface.co/bes-dev/stable-diffusion-v1-4-openvinopip3install-rrequirements.txtGenerate an Image​Now that we have all the dependencies installed, we can call thedemo.pywrapper, which is a simple CLI, to generate an image from a prompt.Copycdstable_diffusion.openvino&&\python3demo.py\--prompt"hello"\--outputhello.pngWhen the generation is complete, you can open the generatedhello.pngand see something like this:Lets try another prompt and see what we get:Copycdstable_diffusion.openvino&&\python3demo.py\--prompt"cat driving a car"\--outputcat.pngRunning Stable Diffusion (CPU) on Bacalhau​Now we have a working example, we can convert it into a format that allows us to perform inference in a distributed environment.First we will create aDockerfileto containerize the inference code. The Dockerfilecan be found in the repository, but is presented here to aid understanding.CopyFROMpython:3.9.9-bullseyeWORKDIR/srcRUNapt-get update && \apt-get install -y \libgl1 libglib2.0-0 git-lfsRUNgit lfs installCOPYrequirements.txt /src/RUNpip3 install -r requirements.txtCOPYstable_diffusion_engine.py demo.py demo_web.py /src/COPYdata/ /src/data/RUNgit clone https://huggingface.co/openai/clip-vit-large-patch14RUNgit clone https://huggingface.co/bes-dev/stable-diffusion-v1-4-openvino# download modelsRUNpython3 demo.py --num-inference-steps 1 --prompt"test"--output /tmp/test.jpgThis container is using thepython:3.9.9-bullseyeimage and the working directory is set. Next, the Dockerfile installs the same dependencies from earlier in this notebook. Then we add our custom code and pull the dependent repositories.We've already pushed this image to GHCR, but for posterity, you'd use a command like this to update it:Copydockerbuildxbuild--platformlinux/amd64--push-tghcr.io/bacalhau-project/examples/stable-diffusion-cpu:0.0.1.Prerequisites​To run this example you will needBacalhauinstalled and runningGenerating an Image Using Stable Diffusion on Bacalhau​Bacalhauis a distributed computing platform that allows you to run jobs on a network of computers. It is designed to be easy to use and to run on a variety of hardware. In this example, we will use it to run the stable diffusion model on a CPU.To submit a job, you can use the Bacalhau CLI. The following command passes a prompt to the model and generates an image in the outputs directory.This will take about 10 minutes to complete. Go grab a coffee. Or a beer. Or both. If you want to block and wait for the job to complete, add the--waitflag.Furthermore, the container itself is about 15GB, so it might take a while to download on the node if it isn't cached.Structure of the command​Some of the jobs presented in the Examples section may require more resources than are currently available on the demo network. Considerstarting your own networkor running less resource-intensive jobs on the demo networkexport JOB_ID=$( ... ): Export results of a command execution as environment variablebacalhau docker run: Run a job using docker executor.--id-only: Flag to print out only the job idghcr.io/bacalhau-project/examples/stable-diffusion-cpu:0.0.1: The name and the tag of the Docker image.The command to run inference on the model:python demo.py --prompt "First Humans On Mars" --output ../outputs/mars.png. It consists of:demo.py: The Python script that runs the inference process.--prompt "First Humans On Mars": Specifies the text prompt to be used for the inference.--output ../outputs/mars.png: Specifies the path to the output image.When a job is submitted, Bacalhau prints out the relatedjob_id. We store that in an environment variable so that we can reuse it later on.CopyexportJOB_ID=$(bacalhaudockerrun\ghcr.io/bacalhau-project/examples/stable-diffusion-cpu:0.0.1\--id-only \--pythondemo.py--prompt"First Humans On Mars"--output../outputs/mars.png)Checking the State of your Jobs​Job status: You can check the status of the job usingbacalhau job list:Copybacalhaujoblist--id-filter${JOB_ID}When it saysCompleted, that means the job is done, and we can get the results.Job information: You can find out more information about your job by usingbacalhau job describe:Copybacalhaujobdescribe${JOB_ID}Job download: You can download your job results directly by usingbacalhau job get. Alternatively, you can choose to create a directory to store your results. In the command below, we created a directory and downloaded our job output to be stored in that directory.Copyrm-rfresults&&mkdirresultsbacalhaujobget${JOB_ID}--output-dirresultsViewing your Job Output​After the download has finished we can see the results in theresults/outputsfolder.PreviousStable Diffusion on a GPUNextObject Detection with YOLOv5 on BacalhauLast updated19 days agoOn this pageIntroductionTL;DR​Development​Prerequisites​Converting Stable Diffusion to a CPU Model Using OpenVINO​Install Dependencies​Generate an Image​Running Stable Diffusion (CPU) on Bacalhau​Prerequisites​Generating an Image Using Stable Diffusion on Bacalhau​Structure of the command​Checking the State of your Jobs​Viewing your Job Output​Was this helpful?Edit on GitHubExport as PDFGet SupportExpansoSupportUse CasesDistributed ETLEdge MLDistributed Data WarehousingFlett ManagementAbout UsWho we areWhat we valueNews & BlogBlogNewsExpanso (2024). All Rights Reserved.