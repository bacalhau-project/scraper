Source: bacalhau_docs
URL: https://docs.bacalhau.org/setting-up/running-node/gpu

GPU Installation
How to enable GPU support on your Bacalhau node
Bacalhau supports GPUs out of the box and defaults to allowing execution on all GPUs installed on the node.
Prerequisites
Bacalhau makes the assumption that you have installed all the necessary drivers and tools on your node host and have appropriately configured them for use by Docker.
In general for GPUs from any vendor, the Bacalhau client requires:
Nvidia
Verify installation by
[Running a Sample Workload](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/sample-workload.html)nvidia-smi
installed and functional
AMD
rocm-smi
tool installed and functional
See the [Running ROCm Docker containers](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/how-to/docker.html) for guidance on how to run Docker workloads on AMD GPU.
Intel
xpu-smi
tool installed and functional
See the [Running on GPU under docker](https://github.com/Intel-Media-SDK/MediaSDK/wiki/Running-on-GPU-under-docker) for guidance on how to run Docker workloads on Intel GPU.
GPU Node Configuration
Access to GPUs can be controlled using [resource limits](/setting-up/running-node/resource-limits). To limit the number of GPUs that can be used per job, set a job resource limit. To limit access to GPUs from all jobs, set a total resource limit.