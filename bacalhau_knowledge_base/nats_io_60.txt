URL: https://nats.io/blog/exploring-nats-as-a-backend-for-k3s/

AboutDownloadDocumentationBlogCommunitySupportPrivacyExploring NATS as a backend for k3sByron Ruth— May 9, 2023Back to Blogk3sis a lightweight Kubernetes distribution suitable for IoT and edge computing environments. One component k3s leverages isKINE, which is a shim enabling the replacement ofetcdwith alternate storage backends originally targeting relational databases.In April 2022, thev0.9.0 releaseof KINE introduced native support for NATS as a backend. In June 2022, the k3sv1.23.7+k3s1release included this KINE version making it possible for k3s deployments to connect to an existing NATS system.The KINE backend leverages theKey-Value APIbuilt on top of the NATS persistence subsystem calledJetStream.A minimal example of bootstrapping a k3s server backed by NATS can be done by starting a JetStream-enablenats-serverfollowed by startingk3s serverwith the--datastore-endpointconfigured.# Run in the background or in the foreground in a different shell.nats-server -js&# Point k3s to the default NATS address.k3s server --datastore-endpoint=jetstream://localhost:4222When thek3s serverstarts, it will create a KV bucket (if it does not exist) within NATS. If using with a NATS cluster, the bucket can be configured with multiple replicas for high-availability and fault tolerance of the data.Global, multi-tenant infrastructureWhat does using NATS give you out of the box?During RethinkConn 2022,Caleb LloydpresentedUsing NATS JetStream as a KINE backend for k3swhere he demonstrated the ability to deploy multiple k3s clusters in different regions all connected to a global, multi-cloud deployment of NATS (in this caseSynadia’s NGS).The main takeaways:Each k3s cluster can have their own isolatedaccountand KV bucket to store cluster state on a shared NATS system.Applications running in k3s can leverage the same NATS system for their workloads (within their own accounts) as what k3s does.Cross-region mirrors of the KV buckets can be created for straightforward backup/restore disaster recovery scenarios.Given this is one NATS system, an operator gets end-to-end visibility and management of all of these assets out-of-the-box. Check out thek3s-on-nats demo repoto try it out youself.Embedded NATSLast week (May 2023), thev0.10.0KINE release landed support forembeddingthe NATS server. This is possible because KINE and NATS are both written inGoand the server can beimported as a package.At the time of this writing, k3s with this new version of KINE embedded with NATS has not yet been released. What is discussed below works, but currently requires a manually building k3s.Starting k3s with this version of KINE embedded is now reduced to the following command (without needing to start an external NATS server).k3s server --datastore-endpoint=nats://See a one minute demo of how it works.The minimalnats://endpoint relies on the defaults in the NATS server, listening on all hosts (0.0.0.0) and binding to port4222. Of course, if you don’t want to embed the server, you can add the query parameternoEmbedand it will connect to a remote system.What do we gain with an embedded server?The original motivation was to further reduce the distribution and dependency footprint, resulting in the option of a single k3s binary with KINE and NATS embedded. In addition to the reduced dependency footprint, there are multiple benefits over etcd and SQLite:Thenats://endpoint supports aserverConfigquery param pointing to a local NATS config file. This gives the flexibility of configuring the instance as aLeaf Node, which enables the secure extension of an existing NATS system. Leaf nodes initiate connections to the remote servers, making them friendly for network environments with heavy use of network address translation (NAT).Building on the above example showcased in the RethinkConn talk, embedded NATS makes it possible to extend to the edge and maintain local state if remote connectivity to a NATS cluster is lost, without sacrificing visibility or management capabilities.A single binary provides all of the advantages of NATS combined with a workload scheduler. As a result, your data lives on and traverses one system, unifying design, development and operations.Having a single binary with k3s and NATS is superpower!If you are interested in reading what options are available to configure the KINE datastore endpoint, checkout theNATS examplesdocument in the KINE repo.Future effortsHaving NATS available as KINE/k3s backend was a great start and having the option for embedding NATS is a superpower for edge deployments. However, there are a few other areas the NATS team is exploring including:Native support for NATS in k3s' embedded HA/cluster mode ( join the discussion on theGitHub issue)How NATS may be able to be leveraged withinFleetWhat would it take to setup an agent-less k3smirrorof another instance, leveraging NATS mirror/sourcing capabilityIf you find any of this interesting, have use cases to share, or want to show your support, please join us onSlack!Finally, The NATS team wants to give a BIG thank you and shoutout to the k3s/KINE team for the support and guidance on making NATS available as a backend. ❤️Additional LinksNATS by Example: Key-Value IntroNATS by Example: Embedded Server with mTLSAbout the AuthorByron Ruthis the Director of Developer Relations atSynadiaand a long-time NATS user.Back to BlogCopyright © NATS Authors 2024NATS is aCloud Native Computing Foundationincubating projectThe Linux Foundation has registered trademarks and uses trademarks.For a list of trademarks of The Linux Foundation, please seeTrademark Usage page.