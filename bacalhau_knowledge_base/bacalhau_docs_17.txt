URL: https://docs.bacalhau.org/setting-up/running-node/job-selection

Bacalhau Docsv.1.4.0v.1.3.0v.1.3.1v.1.3.2v.1.4.0GitHubSlackContactMoreGitHubSlackContactAsk or SearchCtrl+â€†KWelcomeGetting StartedHow Bacalhau WorksInstallationCreate NetworkHardware SetupContainer OnboardingDocker WorkloadsWebAssembly (Wasm) WorkloadsSetting UpRunning NodesNode OnboardingGPU InstallationJob selection policyAccess ManagementNode persistenceConnect StorageConfiguration ManagementConfiguring Transport Level SecurityLimits and TimeoutsTest Network LocallyBacalhau WebUIWorkload OnboardingContainerDocker Workload OnboardingWebAssembly (Wasm) WorkloadsBacalhau Docker ImageHow To Work With Custom Containers in BacalhauPythonBuilding and Running Custom Python ContainerRunning Pandas on BacalhauRunning a Python ScriptRunning Jupyter Notebooks on BacalhauScripting Bacalhau with PythonR (language)Building and Running your Custom R Containers on BacalhauRunning a Simple R Script on BacalhauRun CUDA programs on BacalhauRunning a Prolog ScriptReading Data from Multiple S3 Buckets using BacalhauRunning Rust programs as WebAssembly (WASM)Generate Synthetic Data using Sparkov Data Generation techniqueData IngestionCopy Data from URL to Public StoragePinning DataRunning a Job over S3 dataNetworking InstructionsAccessing the Internet from JobsUtilizing NATS.io within BacalhauGPU Workloads SetupAutomatic Update CheckingMarketplace DeploymentsGoogle Cloud MarketplaceGuidesWrite a config.yamlWrite a SpecConfigExamplesData EngineeringUsing Bacalhau with DuckDBEthereum Blockchain Analysis with Ethereum-ETL and BacalhauConvert CSV To Parquet Or AvroSimple Image ProcessingOceanography - Data ConversionVideo ProcessingModel InferenceEasyOCR (Optical Character Recognition) on BacalhauRunning Inference on Dolly 2.0 Model with Hugging FaceSpeech Recognition using WhisperStable Diffusion on a GPUStable Diffusion on a CPUObject Detection with YOLOv5 on BacalhauGenerate Realistic Images using StyleGAN3 and BacalhauStable Diffusion Checkpoint InferenceRunning Inference on a Model stored on S3Model TrainingTraining Pytorch Model with BacalhauTraining Tensorflow ModelStable Diffusion Dreambooth (Finetuning)Molecular DynamicsRunning BIDS Apps on BacalhauCoresets On BacalhauGenomics Data GenerationGromacs for AnalysisMolecular Simulation with OpenMM and BacalhauReferencesJobs GuideJob SpecificationJob TypesTask SpecificationEnginesDocker Engine SpecificationWebAssembly (WASM) Engine SpecificationPublishersIPFS Publisher SpecificationLocal Publisher SpecificationS3 Publisher SpecificationSourcesIPFS Source SpecificationLocal Source SpecificationS3 Source SpecificationURL Source SpecificationNetwork SpecificationInput Source SpecificationResources SpecificationResultPath SpecificationConstraint SpecificationLabels SpecificationMeta SpecificationJob TemplatesQueuing & TimeoutsJob QueuingTimeouts SpecificationJob ResultsStateCLI GuideSingle CLI commandsAgentAgent OverviewAgent AliveAgent NodeAgent VersionConfigConfig OverviewConfig Auto-ResourcesConfig DefaultConfig ListConfig SetJobJob OverviewJob DescribeJob ExecJob ExecutionsJob HistoryJob ListJob LogsJob RunJob StopNodeNode OverviewNode ApproveNode DeleteNode ListNode DescribeNode RejectCLI Commands OverviewCommand MigrationAPI GuideBacalhau API overviewBest PracticesAgent EndpointOrchestrator EndpointMigration APINode ManagementAuthentication & AuthorizationDatabase IntegrationDebuggingDebugging Failed JobsDebugging LocallyOpen Telemetry in BacalhauRunning locally in 'devstack'Setting up Dev EnvironmentHelp & FAQBacalhau FAQsRelease NotesGlossaryIntegrationsApache Airflow Provider for BacalhauLilypadBacalhau Python SDKObservability for WebAssembly WorkloadsCommunitySocial MediaStyle GuideWays to ContributePowered by GitBookJob selection policyWhen running a node, you can choose which jobs you want to run by using configuration options, environment variables or flags to specify a job selection policy.Config propertyserveflagDefault valueMeaningNode.Compute.JobSelection.Locality--job-selection-data-localityAnywhereOnly accept jobs that reference data we have locally ("local") or anywhere ("anywhere").Node.Compute.JobSelection.ProbeExec--job-selection-probe-execunusedUse the result of an external program to decide if we should take on the job.Node.Compute.JobSelection.ProbeHttp--job-selection-probe-httpunusedUse the result of a HTTP POST to decide if we should take on the job.Node.Compute.JobSelection.RejectStatelessJobs--job-selection-reject-statelessFalseReject jobs that don't specify anyinput data.Node.Compute.JobSelection.AcceptNetworkedJobs--job-selection-accept-networkedFalseAccept jobs that requirenetwork connections.Job selection probesIf you want more control over making the decision to take on jobs, you can use the--job-selection-probe-execand--job-selection-probe-httpflags.These are external programs that are passed the following data structure so that they can make a decision about whether or not to take on a job:Copy{"node_id":"XXX","job_id":"XXX","spec":{"engine":"docker","verifier":"ipfs","job_spec_vm":{"image":"ubuntu:latest","entrypoint":["cat","/file.txt"]},"inputs":[{"engine":"ipfs","cid":"XXX","path":"/file.txt"}]}}Theexecprobe is a script to run that will be given the job data onstdin, and must exit with status code 0 if the job should be run.Thehttpprobe is a URL to POST the job data to. The job will be rejected if the HTTP request returns a non-positive status code (e.g. >= 400).If the HTTP response is a JSON blob, it should match thefollowing schemaand will be used to respond to the bid directly:Copy{"$schema":"http://json-schema.org/draft-04/schema#","type":"object","properties":{"shouldBid":{"description":"If the job should be accepted","type":"boolean"},"shouldWait":{"description":"If the node should wait for an async response that will come later. `shouldBid` will be ignored","type":"boolean","default":false,},"reason":{"description": "Human-readable string explaining why the job should be accepted or rejected, or why the wait is required","type":"string"}},"required":["shouldBid","reason"]}For example, the following response will reject the job:Copy{"shouldBid":false,"reason":"The job did not pass this specific validation: ...",}If the HTTP response is not a JSON blob, the content is ignored and any non-error status code will accept the job.PreviousGPU InstallationNextAccess ManagementOn this pageWas this helpful?Edit on GitHubExport as PDFGet SupportExpansoSupportUse CasesDistributed ETLEdge MLDistributed Data WarehousingFlett ManagementAbout UsWho we areWhat we valueNews & BlogBlogNewsExpanso (2024). All Rights Reserved.